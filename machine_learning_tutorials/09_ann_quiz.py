"""
인공신경망 퀴즈

이 퀴즈는 인공신경망의 핵심 개념, 구조 설계, 하이퍼파라미터 조정,
과적합 방지 기법에 대한 이해도를 평가합니다.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.quiz_utils import QuizManager
import numpy as np

def create_ann_quiz():
    """인공신경망 퀴즈 생성"""
    
    quiz_manager = QuizManager("인공신경망(ANN)")
    
    # 1. 개념 이해 문제들
    quiz_manager.add_question(
        "다음 중 인공신경망의 핵심 구성 요소가 아닌 것은?",
        ["가중치(Weight)", "편향(Bias)", "활성화 함수", "결정 경계"],
        3,
        "결정 경계는 모델의 출력 결과이지 신경망의 구성 요소가 아닙니다. "
        "인공신경망의 핵심 구성 요소는 가중치, 편향, 활성화 함수입니다."
    )
    
    quiz_manager.add_question(
        "퍼셉트론이 해결할 수 없는 문제는?",
        ["AND 연산", "OR 연산", "XOR 연산", "NOT 연산"],
        2,
        "단일 퍼셉트론은 선형 분류만 가능하므로 XOR과 같은 비선형 문제를 해결할 수 없습니다. "
        "XOR 문제 해결을 위해서는 다층 퍼셉트론이 필요합니다."
    )
    
    quiz_manager.add_question(
        "역전파 알고리즘의 핵심 원리는?",
        ["순전파만 사용", "연쇄 법칙을 이용한 그래디언트 계산", "가중치 무작위 업데이트", "활성화 함수 변경"],
        1,
        "역전파는 연쇄 법칙(Chain Rule)을 사용하여 출력층부터 입력층까지 "
        "각 가중치에 대한 손실 함수의 그래디언트를 계산하는 알고리즘입니다."
    )
    
    quiz_manager.add_question(
        "다층 퍼셉트론에서 은닉층의 역할은?",
        ["데이터 입력", "최종 출력 생성", "특징 추출 및 변환", "오차 계산"],
        2,
        "은닉층은 입력 데이터로부터 유용한 특징을 추출하고 변환하여 "
        "복잡한 비선형 패턴을 학습할 수 있게 해주는 역할을 합니다."
    )
    
    # 2. 활성화 함수 관련 문제들
    quiz_manager.add_question(
        "ReLU 활성화 함수의 수식은?",
        ["1/(1+e^(-x))", "tanh(x)", "max(0, x)", "x"],
        2,
        "ReLU(Rectified Linear Unit)는 max(0, x)로 정의되며, "
        "음수 입력에 대해서는 0을, 양수 입력에 대해서는 입력값 그대로를 출력합니다."
    )
    
    quiz_manager.add_question(
        "시그모이드 함수의 출력 범위는?",
        ["(-∞, ∞)", "(-1, 1)", "(0, 1)", "[0, 1]"],
        2,
        "시그모이드 함수 σ(x) = 1/(1+e^(-x))의 출력 범위는 (0, 1)입니다. "
        "이 특성으로 인해 이진 분류의 확률 해석이 가능합니다."
    )
    
    quiz_manager.add_question(
        "ReLU 함수의 주요 장점은?",
        ["그래디언트 소실 완화", "계산 효율성", "희소성 유도", "위의 모든 것"],
        3,
        "ReLU는 그래디언트 소실 문제를 완화하고, 계산이 매우 간단하며, "
        "음수 입력에 대해 0을 출력하여 희소한 표현을 만들어내는 장점이 있습니다."
    )
    
    quiz_manager.add_question(
        "소프트맥스 함수가 주로 사용되는 경우는?",
        ["이진 분류", "다중 클래스 분류의 출력층", "은닉층", "회귀 문제"],
        1,
        "소프트맥스 함수는 다중 클래스 분류 문제의 출력층에서 사용되어 "
        "각 클래스에 대한 확률 분포를 생성합니다."
    )
    
    # 3. 손실 함수 및 최적화 문제들
    quiz_manager.add_question(
        "다중 클래스 분류에 적합한 손실 함수는?",
        ["평균 제곱 오차", "교차 엔트로피", "힌지 손실", "허버 손실"],
        1,
        "교차 엔트로피(Cross-Entropy)는 분류 문제에 가장 적합한 손실 함수로, "
        "확률 분포 간의 차이를 측정합니다."
    )
    
    quiz_manager.add_question(
        "Adam 옵티마이저의 특징은?",
        ["고정된 학습률 사용", "모멘텀과 적응적 학습률 결합", "메모리 사용량이 많음", "수렴이 느림"],
        1,
        "Adam은 모멘텀과 적응적 학습률을 결합한 최적화 알고리즘으로, "
        "빠른 수렴과 안정적인 학습을 제공합니다."
    )
    
    quiz_manager.add_question(
        "학습률이 너무 클 때 발생할 수 있는 문제는?",
        ["수렴 속도 저하", "그래디언트 폭발", "지역 최솟값 탈출", "과적합"],
        1,
        "학습률이 너무 크면 가중치 업데이트가 과도하게 이루어져 "
        "그래디언트가 폭발하거나 최적점을 지나쳐 발산할 수 있습니다."
    )
    
    # 4. 네트워크 구조 설계 문제들
    quiz_manager.add_question(
        "은닉층의 뉴런 수를 결정할 때 고려사항이 아닌 것은?",
        ["문제의 복잡도", "데이터셋 크기", "계산 자원", "데이터의 색상"],
        3,
        "은닉층의 뉴런 수는 문제의 복잡도, 데이터셋 크기, 계산 자원을 고려하여 결정합니다. "
        "데이터의 색상과 같은 특정 속성은 직접적인 고려사항이 아닙니다."
    )
    
    quiz_manager.add_question(
        "깊은 신경망에서 발생할 수 있는 문제는?",
        ["그래디언트 소실", "훈련 시간 증가", "과적합 위험 증가", "위의 모든 것"],
        3,
        "깊은 신경망은 그래디언트 소실 문제, 긴 훈련 시간, 과적합 위험 증가 등 "
        "여러 문제를 동시에 가질 수 있습니다."
    )
    
    quiz_manager.add_question(
        "MNIST 손글씨 분류를 위한 적절한 출력층 구조는?",
        ["1개 뉴런, 시그모이드", "10개 뉴런, 소프트맥스", "10개 뉴런, ReLU", "1개 뉴런, 선형"],
        1,
        "MNIST는 10개 클래스(0-9)의 다중 분류 문제이므로 "
        "10개 뉴런과 소프트맥스 활성화 함수를 사용해야 합니다."
    )
    
    # 5. 과적합 방지 기법 문제들
    quiz_manager.add_question(
        "과적합을 방지하는 방법이 아닌 것은?",
        ["조기 종료", "정규화", "더 복잡한 모델 사용", "드롭아웃"],
        2,
        "더 복잡한 모델을 사용하면 과적합이 더 심해집니다. "
        "과적합 방지를 위해서는 모델 복잡도를 적절히 제한해야 합니다."
    )
    
    quiz_manager.add_question(
        "L2 정규화의 효과는?",
        ["가중치 크기 증가", "가중치 크기 감소", "학습 속도 향상", "정확도 향상"],
        1,
        "L2 정규화는 가중치의 제곱합에 페널티를 주어 가중치 크기를 감소시키고, "
        "이를 통해 모델의 복잡도를 제한하여 과적합을 방지합니다."
    )
    
    quiz_manager.add_question(
        "조기 종료(Early Stopping)의 기준은?",
        ["훈련 손실 증가", "검증 손실 증가", "훈련 정확도 감소", "학습률 감소"],
        1,
        "조기 종료는 검증 데이터에서의 성능이 더 이상 개선되지 않을 때 "
        "훈련을 중단하는 기법입니다."
    )
    
    # 6. 실제 적용 시나리오 문제들
    quiz_manager.add_question(
        "이미지 분류 문제에서 입력 데이터 전처리로 가장 중요한 것은?",
        ["색상 변환", "크기 조정", "정규화/표준화", "노이즈 제거"],
        2,
        "신경망 학습에서는 입력 데이터의 정규화/표준화가 가장 중요합니다. "
        "이는 그래디언트 계산을 안정화하고 수렴 속도를 향상시킵니다."
    )
    
    quiz_manager.add_question(
        "배치 크기가 성능에 미치는 영향으로 옳은 것은?",
        ["클수록 항상 좋음", "작을수록 항상 좋음", "적절한 크기가 중요함", "영향 없음"],
        2,
        "배치 크기는 메모리 사용량, 수렴 안정성, 일반화 성능에 영향을 미치므로 "
        "문제와 자원에 맞는 적절한 크기를 선택하는 것이 중요합니다."
    )
    
    quiz_manager.add_question(
        "신경망의 가중치 초기화가 중요한 이유는?",
        ["메모리 절약", "계산 속도 향상", "그래디언트 소실/폭발 방지", "정확도 보장"],
        2,
        "적절한 가중치 초기화는 그래디언트 소실이나 폭발 문제를 방지하고 "
        "안정적인 학습을 가능하게 합니다."
    )
    
    # 7. 성능 평가 및 해석 문제들
    quiz_manager.add_question(
        "신경망 모델의 성능을 평가할 때 사용하지 않는 지표는?",
        ["정확도", "F1-Score", "AUC", "상관계수"],
        3,
        "상관계수는 주로 회귀 문제나 변수 간 관계 분석에 사용되며, "
        "분류 문제의 신경망 성능 평가에는 일반적으로 사용되지 않습니다."
    )
    
    quiz_manager.add_question(
        "혼동 행렬에서 대각선 원소가 의미하는 것은?",
        ["잘못 분류된 샘플 수", "올바르게 분류된 샘플 수", "전체 샘플 수", "클래스 불균형"],
        1,
        "혼동 행렬의 대각선 원소는 각 클래스에서 올바르게 분류된 샘플의 수를 나타냅니다."
    )
    
    # 8. 고급 개념 문제들
    quiz_manager.add_question(
        "Universal Approximation Theorem이 의미하는 것은?",
        ["모든 함수를 정확히 표현 가능", "충분한 은닉 뉴런으로 연속함수 근사 가능", 
         "무한한 데이터로 완벽한 학습 가능", "모든 문제 해결 가능"],
        1,
        "Universal Approximation Theorem은 충분한 수의 은닉 뉴런을 가진 "
        "단일 은닉층 신경망이 임의의 연속함수를 원하는 정확도로 근사할 수 있음을 보장합니다."
    )
    
    quiz_manager.add_question(
        "그래디언트 소실 문제의 주요 원인은?",
        ["큰 학습률", "작은 활성화 함수 도함수", "많은 데이터", "빠른 수렴"],
        1,
        "그래디언트 소실은 주로 시그모이드나 tanh 같은 활성화 함수의 도함수가 "
        "작아서 역전파 과정에서 그래디언트가 점점 작아지는 현상입니다."
    )
    
    return quiz_manager

def run_ann_quiz():
    """인공신경망 퀴즈 실행"""
    print("=" * 60)
    print("인공신경망(ANN) 이해도 평가 퀴즈")
    print("=" * 60)
    print("신경망의 구조, 학습 알고리즘, 하이퍼파라미터 튜닝에 대한")
    print("이해도를 평가하는 퀴즈입니다.")
    print("-" * 60)
    
    quiz_manager = create_ann_quiz()
    results = quiz_manager.run_quiz()
    
    # 상세 분석 제공
    print("\n" + "=" * 60)
    print("퀴즈 결과 분석")
    print("=" * 60)
    
    score_percentage = (results['score'] / results['total']) * 100
    
    if score_percentage >= 90:
        print("🎉 우수! 인공신경망에 대한 깊은 이해를 보여줍니다.")
        print("추천 다음 단계: 딥러닝 프레임워크(TensorFlow, PyTorch) 학습")
    elif score_percentage >= 80:
        print("👍 양호! 기본 개념을 잘 이해하고 있습니다.")
        print("추천 다음 단계: 고급 신경망 구조(CNN, RNN) 학습")
    elif score_percentage >= 70:
        print("📚 보통! 추가 학습이 필요합니다.")
        print("추천 다음 단계: 역전파 알고리즘과 최적화 기법 복습")
    else:
        print("💪 더 노력하세요! 기본 개념부터 다시 학습하시기 바랍니다.")
        print("추천 다음 단계: 퍼셉트론과 다층 퍼셉트론 개념 복습")
    
    # 주제별 성능 분석
    print(f"\n주제별 이해도:")
    print(f"- 기본 개념 (문제 1-4): 기본적인 신경망 구조와 원리")
    print(f"- 활성화 함수 (문제 5-8): 다양한 활성화 함수의 특성")
    print(f"- 최적화 (문제 9-11): 손실 함수와 최적화 알고리즘")
    print(f"- 구조 설계 (문제 12-14): 네트워크 아키텍처 설계")
    print(f"- 정규화 (문제 15-17): 과적합 방지 기법")
    print(f"- 실제 적용 (문제 18-20): 실무 적용 시 고려사항")
    print(f"- 성능 평가 (문제 21-22): 모델 평가 방법")
    print(f"- 고급 개념 (문제 23-24): 이론적 배경과 고급 주제")
    
    print(f"\n학습 권장사항:")
    print(f"1. 틀린 문제들을 다시 검토하고 관련 이론을 복습하세요")
    print(f"2. 실습 코드를 직접 실행하며 하이퍼파라미터 변화를 관찰하세요")
    print(f"3. 다양한 데이터셋으로 신경망을 구현해보세요")
    print(f"4. 딥러닝 프레임워크를 사용한 고급 구현을 시도해보세요")
    
    return results

if __name__ == "__main__":
    run_ann_quiz()