# 유사도와 거리 완전 이론 가이드

## 1. 개요 및 핵심 개념

### 유사도와 거리의 정의
- **거리(Distance)**: 두 객체 간의 차이나 비유사성을 수치로 표현
- **유사도(Similarity)**: 두 객체 간의 닮음이나 공통성을 수치로 표현
- **관계**: 거리가 클수록 유사도는 작아지며, 일반적으로 역의 관계

### 데이터 마이닝에서의 중요성
- **클러스터링**: 유사한 객체들을 그룹화
- **분류**: 새로운 객체를 기존 클래스와 비교
- **추천 시스템**: 사용자나 아이템 간 유사성 측정
- **이상치 탐지**: 정상 데이터와의 거리 기반 탐지

### 측정 척도의 선택 기준
- **데이터 유형**: 수치형, 범주형, 이진형, 텍스트
- **차원의 수**: 고차원에서는 특정 거리 척도가 비효율적
- **스케일**: 속성 간 단위나 범위의 차이
- **분포**: 데이터의 분산과 상관관계 고려

## 2. 거리 척도 (Distance Measures)

### 2.1 유클리드 거리 (Euclidean Distance)
**정의**: 두 점 사이의 직선 거리 (L2 norm)

**수식**: 
```
d(x,y) = √(Σᵢ(xᵢ - yᵢ)²)
```

**특징**:
- 가장 직관적이고 널리 사용되는 거리 척도
- 연속형 수치 데이터에 적합
- 모든 속성이 동일한 중요도를 가진다고 가정
- 속성 간 스케일 차이에 민감

**적용 사례**:
- 2D/3D 공간에서의 물리적 거리
- 이미지 픽셀 간 유사성
- K-평균 클러스터링의 기본 거리

**장점**:
- 계산이 간단하고 직관적
- 기하학적 의미가 명확
- 많은 알고리즘에서 기본값으로 사용

**단점**:
- 고차원에서 차별력 감소 (차원의 저주)
- 속성 스케일에 민감
- 이상치에 민감 (제곱 연산)

### 2.2 맨해튼 거리 (Manhattan Distance)
**정의**: 좌표축을 따라 이동하는 거리의 합 (L1 norm, City Block Distance)

**수식**:
```
d(x,y) = Σᵢ|xᵢ - yᵢ|
```

**특징**:
- 격자 형태의 경로를 따라 측정
- 절댓값 사용으로 이상치에 덜 민감
- 희소 데이터에서 효과적

**적용 사례**:
- 도시 블록 간 이동 거리
- 체스판에서의 룩(Rook) 이동
- 텍스트 마이닝에서 단어 빈도 비교

**장점**:
- 이상치에 상대적으로 강건
- 고차원 데이터에서 유클리드보다 안정적
- 계산 복잡도가 낮음

**단점**:
- 기하학적 직관성이 떨어짐
- 회전에 민감 (좌표축 의존적)

### 2.3 민코프스키 거리 (Minkowski Distance)
**정의**: 유클리드와 맨해튼 거리를 일반화한 거리 척도

**수식**:
```
d(x,y) = (Σᵢ|xᵢ - yᵢ|ᵖ)^(1/p)
```

**파라미터**:
- p = 1: 맨해튼 거리
- p = 2: 유클리드 거리  
- p = ∞: 체비셰프 거리 (최대 차이)

**특징**:
- p 값에 따라 다른 거리 특성
- p가 클수록 최대 차이에 더 민감
- 유연한 거리 측정 가능

**적용 사례**:
- 다양한 p 값 실험을 통한 최적 거리 찾기
- 도메인 특성에 맞는 거리 조정
- 하이퍼파라미터 튜닝

### 2.4 마할라노비스 거리 (Mahalanobis Distance)
**정의**: 데이터의 공분산을 고려한 거리 척도

**수식**:
```
d(x,y) = √((x-y)ᵀ S⁻¹ (x-y))
```
여기서 S는 공분산 행렬

**특징**:
- 속성 간 상관관계 고려
- 데이터 분포의 모양을 반영
- 스케일에 무관 (자동 정규화 효과)

**적용 사례**:
- 다변량 이상치 탐지
- 패턴 인식에서 클래스 간 거리
- 금융 데이터 분석 (리스크 측정)

**장점**:
- 속성 간 상관관계 반영
- 스케일 문제 해결
- 통계적으로 의미 있는 거리

**단점**:
- 공분산 행렬 계산 필요
- 계산 복잡도 높음
- 충분한 데이터 필요

## 3. 유사도 척도 (Similarity Measures)

### 3.1 코사인 유사도 (Cosine Similarity)
**정의**: 두 벡터 간의 각도를 기반으로 한 유사도

**수식**:
```
sim(x,y) = (x·y) / (||x|| ||y||) = Σᵢ(xᵢyᵢ) / (√Σᵢxᵢ² √Σᵢyᵢ²)
```

**특징**:
- 벡터의 크기가 아닌 방향에 집중
- -1 ~ 1 범위의 값 (1: 완전 유사, -1: 완전 반대)
- 고차원 희소 데이터에 효과적

**적용 사례**:
- 텍스트 문서 유사도 (TF-IDF 벡터)
- 추천 시스템 (사용자-아이템 행렬)
- 이미지 검색 (특징 벡터 비교)

**장점**:
- 크기에 무관한 방향성 측정
- 희소 벡터에서 효율적
- 정규화 효과 내장

**단점**:
- 음수 값 해석 주의 필요
- 벡터 크기 정보 손실

### 3.2 이진 데이터 유사도

#### 자카드 계수 (Jaccard Coefficient)
**정의**: 교집합과 합집합의 비율

**수식**:
```
J(A,B) = |A ∩ B| / |A ∪ B| = M₁₁ / (M₀₁ + M₁₀ + M₁₁)
```

**특징**:
- 0 ~ 1 범위 (1: 완전 일치, 0: 완전 불일치)
- 공통으로 없는 속성(M₀₀) 무시
- 비대칭 이진 속성에 적합

**적용 사례**:
- 문서 집합 비교 (공통 단어)
- 고객 구매 패턴 분석
- 유전자 서열 비교

#### 단순 매칭 계수 (Simple Matching Coefficient, SMC)
**정의**: 전체 속성 중 일치하는 속성의 비율

**수식**:
```
SMC(A,B) = (M₁₁ + M₀₀) / (M₀₀ + M₀₁ + M₁₀ + M₁₁)
```

**특징**:
- 0과 1 모두 의미 있는 경우 사용
- 대칭 이진 속성에 적합
- 자카드보다 보수적 측정

**적용 사례**:
- 설문조사 응답 비교 (예/아니오)
- 의료 진단 (증상 유무)
- 품질 검사 (합격/불합격)

### 3.3 상관계수 (Correlation Coefficient)
**정의**: 두 변수 간의 선형 관계 강도

**피어슨 상관계수**:
```
r(x,y) = Σᵢ(xᵢ - x̄)(yᵢ - ȳ) / √(Σᵢ(xᵢ - x̄)² Σᵢ(yᵢ - ȳ)²)
```

**특징**:
- -1 ~ 1 범위 (1: 완전 양의 상관, -1: 완전 음의 상관)
- 선형 관계만 측정
- 평균 중심화된 코사인 유사도와 동일

**적용 사례**:
- 주식 가격 움직임 분석
- 센서 데이터 상관관계
- 사용자 평점 패턴 분석

## 4. 정보 기반 척도 (Information-Based Measures)

### 4.1 엔트로피 (Entropy)
**정의**: 정보의 불확실성이나 무질서도를 측정

**수식**:
```
H(X) = -Σᵢ P(xᵢ) log₂ P(xᵢ)
```

**특징**:
- 0 이상의 값 (0: 완전 확실, 높을수록 불확실)
- 확률 분포의 균등성 측정
- 정보 이론의 기본 개념

**적용 사례**:
- 의사결정나무의 분할 기준
- 특징 선택 (정보 이득)
- 데이터 압축 효율성

### 4.2 상호정보량 (Mutual Information)
**정의**: 두 변수가 공유하는 정보의 양

**수식**:
```
I(X,Y) = H(X) + H(Y) - H(X,Y)
      = ΣᵢΣⱼ P(xᵢ,yⱼ) log₂(P(xᵢ,yⱼ)/(P(xᵢ)P(yⱼ)))
```

**특징**:
- 0 이상의 값 (0: 독립, 높을수록 강한 의존성)
- 비선형 관계도 측정 가능
- 대칭적 측정 (I(X,Y) = I(Y,X))

**적용 사례**:
- 특징 선택 (타겟과의 관련성)
- 클러스터링 품질 평가
- 네트워크 분석 (노드 간 정보 흐름)

### 4.3 조건부 엔트로피 (Conditional Entropy)
**정의**: 한 변수가 주어졌을 때 다른 변수의 불확실성

**수식**:
```
H(Y|X) = H(X,Y) - H(X) = -ΣᵢΣⱼ P(xᵢ,yⱼ) log₂ P(yⱼ|xᵢ)
```

**특징**:
- H(Y) ≥ H(Y|X) (정보는 불확실성을 감소)
- 정보 이득 = H(Y) - H(Y|X)
- 예측 성능과 직결

## 5. 다른 알고리즘과의 비교

### 5.1 클러스터링 알고리즘별 거리 척도
- **K-평균**: 유클리드 거리 (중심점 기반)
- **K-중앙값**: 맨해튼 거리 (중앙값 기반)
- **DBSCAN**: 유클리드/맨해튼 (밀도 기반)
- **계층적**: 다양한 거리 + 연결 기준

### 5.2 분류 알고리즘별 거리 개념
- **KNN**: 직접적 거리 계산 (유클리드, 맨해튼)
- **SVM**: 커널을 통한 암시적 거리
- **나이브 베이즈**: 확률적 거리 (KL 발산)
- **의사결정나무**: 정보 기반 거리 (엔트로피)

### 5.3 차원 축소와 거리 보존
- **PCA**: 유클리드 거리 보존 (분산 최대화)
- **MDS**: 원본 거리 행렬 보존
- **t-SNE**: 확률적 거리 보존 (지역 구조)
- **UMAP**: 토폴로지 기반 거리 보존

## 6. 적용 사례 및 한계

### 6.1 도메인별 적용 사례

#### 텍스트 마이닝
- **코사인 유사도**: TF-IDF 벡터 비교
- **자카드**: 문서 간 공통 단어 비율
- **편집 거리**: 문자열 간 변환 비용

#### 이미지 처리
- **유클리드**: 픽셀 값 직접 비교
- **구조적 유사도**: 지역 패턴 고려
- **히스토그램 교집합**: 색상 분포 비교

#### 추천 시스템
- **코사인**: 사용자-아이템 선호도 벡터
- **피어슨 상관**: 평점 패턴 유사성
- **자카드**: 공통 선호 아이템 비율

#### 생물정보학
- **해밍 거리**: DNA 서열 차이
- **편집 거리**: 단백질 서열 정렬
- **트리 편집 거리**: 계통수 비교

### 6.2 한계점 및 주의사항

#### 차원의 저주 (Curse of Dimensionality)
- 고차원에서 모든 점 간 거리가 비슷해짐
- 유클리드 거리의 차별력 감소
- 맨해튼이나 코사인 유사도 고려

#### 스케일 문제
- 속성별 단위나 범위 차이
- 정규화나 표준화 필요
- 마할라노비스 거리로 해결 가능

#### 데이터 분포 가정
- 대부분 거리 척도는 특정 분포 가정
- 실제 데이터 분포와 불일치 시 성능 저하
- 도메인 지식 기반 척도 선택 필요

#### 계산 복잡도
- 마할라노비스: O(d³) (공분산 행렬 역행렬)
- 코사인: O(d) (희소 벡터에서 효율적)
- 대용량 데이터에서 근사 알고리즘 필요

## 7. 용어 사전

### 기본 용어
- **거리 함수 (Distance Function)**: d(x,y) ≥ 0, d(x,x) = 0, d(x,y) = d(y,x), 삼각부등식
- **메트릭 (Metric)**: 수학적으로 엄밀한 거리 함수
- **유사도 함수 (Similarity Function)**: 0 ≤ sim(x,y) ≤ 1, sim(x,x) = 1
- **비유사도 (Dissimilarity)**: 거리와 유사하지만 메트릭 조건 불만족 가능

### 수학 기호
- **||x||**: 벡터 x의 노름 (크기)
- **x·y**: 벡터 내적 (dot product)
- **S⁻¹**: 공분산 행렬의 역행렬
- **P(x,y)**: 결합 확률 분포
- **H(X)**: 확률변수 X의 엔트로피

### 성능 지표
- **실루엣 계수**: 클러스터링에서 거리 기반 품질 측정
- **정보 이득**: 엔트로피 감소량 (특징 선택)
- **상호정보량**: 두 변수 간 정보 공유 정도
- **조정된 상호정보량**: 우연에 의한 일치 보정

### 개념 간 연관성
- **거리 ↔ 유사도**: 일반적으로 역의 관계
- **코사인 유사도 ↔ 유클리드**: 정규화된 벡터에서 관련성
- **상관계수 ↔ 코사인**: 평균 중심화 시 동일
- **엔트로피 ↔ 정보 이득**: 불확실성 감소 측정