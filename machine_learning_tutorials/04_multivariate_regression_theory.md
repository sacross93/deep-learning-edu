# 다변량 회귀 완전 이론 가이드

## 1. 개요 및 핵심 개념

### 다변량 회귀의 정의
다변량 회귀(Multivariate Regression)는 여러 개의 독립 변수(특성)를 사용하여 연속형 종속 변수를 예측하는 지도학습 알고리즘입니다. 단순 선형 회귀의 확장으로, 실제 세계의 복잡한 관계를 모델링할 수 있습니다.

### 수학적 표현
- **단순 선형 회귀**: y = β₀ + β₁x + ε
- **다변량 선형 회귀**: y = β₀ + β₁x₁ + β₂x₂ + ... + βₚxₚ + ε

여기서:
- y: 종속 변수 (예측하고자 하는 값)
- x₁, x₂, ..., xₚ: 독립 변수들 (특성들)
- β₀: 절편 (intercept)
- β₁, β₂, ..., βₚ: 회귀 계수들 (각 특성의 가중치)
- ε: 오차항 (잔차)

### 행렬 표현
**X** = [1, x₁, x₂, ..., xₚ] (설계 행렬)
**β** = [β₀, β₁, β₂, ..., βₚ]ᵀ (계수 벡터)
**y** = **Xβ** + **ε**

### 핵심 가정
1. **선형성**: 독립변수와 종속변수 간의 관계가 선형
2. **독립성**: 관측값들이 서로 독립
3. **등분산성**: 오차의 분산이 일정 (homoscedasticity)
4. **정규성**: 오차가 정규분포를 따름
5. **다중공선성 없음**: 독립변수들 간에 강한 상관관계가 없음

## 2. 동작 원리

### 최소제곱법 (Ordinary Least Squares, OLS)
다변량 회귀는 최소제곱법을 사용하여 최적의 회귀 계수를 찾습니다.

**목적 함수**: 잔차 제곱합(RSS)을 최소화
RSS = Σᵢ(yᵢ - ŷᵢ)² = Σᵢ(yᵢ - β₀ - β₁x₁ᵢ - ... - βₚxₚᵢ)²

**해석적 해**:
β̂ = (XᵀX)⁻¹Xᵀy

### 단계별 학습 과정
1. **데이터 준비**: 특성 행렬 X와 타겟 벡터 y 구성
2. **정규방정식 계산**: (XᵀX)⁻¹Xᵀy로 최적 계수 계산
3. **예측**: ŷ = Xβ̂로 새로운 데이터 예측
4. **평가**: 다양한 지표로 모델 성능 평가

### 기하학적 해석
- 다변량 회귀는 p차원 공간에서 최적의 초평면(hyperplane)을 찾는 과정
- 각 계수 βᵢ는 해당 특성의 기울기를 나타냄
- 절편 β₀는 모든 특성이 0일 때의 예측값

## 3. 파라미터 구성

### 주요 하이퍼파라미터

#### 정규화 강도 (Regularization)
- **Ridge (L2)**: α‖β‖₂² 추가 → 계수 크기 제한
- **Lasso (L1)**: α‖β‖₁ 추가 → 특성 선택 효과
- **Elastic Net**: α₁‖β‖₁ + α₂‖β‖₂² → 두 방법의 결합

#### 특성 스케일링
- **표준화**: (x - μ)/σ → 평균 0, 표준편차 1
- **정규화**: (x - min)/(max - min) → 0~1 범위
- **로버스트 스케일링**: 중앙값과 IQR 사용

#### 다항식 특성
- **차수 선택**: 1차(선형), 2차(이차), 3차 등
- **교호작용**: x₁ × x₂ 같은 특성 간 곱셈
- **과적합 주의**: 높은 차수는 복잡도 증가

### 파라미터 조정 가이드라인
1. **정규화 강도**: 교차검증으로 최적값 탐색
2. **특성 선택**: 상관관계 분석, 분산 임계값 설정
3. **스케일링**: 특성들의 단위가 다를 때 필수
4. **다항식 차수**: 검증 곡선으로 적절한 복잡도 선택

## 4. 성능 평가 방법

### 회귀 성능 지표

#### 평균 제곱 오차 (MSE)
MSE = (1/n)Σᵢ(yᵢ - ŷᵢ)²
- 큰 오차에 더 큰 페널티
- 단위: 타겟 변수의 제곱

#### 평균 절대 오차 (MAE)
MAE = (1/n)Σᵢ|yᵢ - ŷᵢ|
- 이상치에 덜 민감
- 단위: 타겟 변수와 동일

#### 평균 제곱근 오차 (RMSE)
RMSE = √MSE
- 해석하기 쉬운 단위
- MSE와 유사한 특성

#### 결정계수 (R²)
R² = 1 - (SS_res/SS_tot)
- 0~1 범위 (높을수록 좋음)
- 모델이 설명하는 분산의 비율

#### 조정된 R² (Adjusted R²)
R²_adj = 1 - [(1-R²)(n-1)/(n-p-1)]
- 특성 개수를 고려한 보정
- 과적합 방지에 유용

### 모델 검증 방법
1. **홀드아웃**: 훈련/검증/테스트 분할
2. **교차검증**: k-fold CV로 안정적 평가
3. **학습 곡선**: 데이터 크기별 성능 분석
4. **검증 곡선**: 하이퍼파라미터별 성능 분석

## 5. 다른 알고리즘과의 비교

### 로지스틱 회귀와의 비교
**공통점**:
- 선형 모델 기반
- 해석 가능한 계수
- 빠른 학습 속도

**차이점**:
- **다변량 회귀**: 연속형 출력, 선형 관계
- **로지스틱 회귀**: 범주형 출력, 시그모이드 함수 사용

### 의사결정나무와의 비교
**다변량 회귀 장점**:
- 수학적으로 명확한 해
- 계수 해석 용이
- 계산 효율성

**의사결정나무 장점**:
- 비선형 관계 모델링
- 특성 간 상호작용 자동 포착
- 범주형 변수 직접 처리

### 신경망과의 비교
**다변량 회귀 장점**:
- 단순하고 해석 가능
- 적은 데이터로도 학습 가능
- 과적합 위험 낮음

**신경망 장점**:
- 복잡한 비선형 패턴 학습
- 대용량 데이터 처리
- 자동 특성 추출

### SVM 회귀와의 비교
**공통점**:
- 연속형 예측
- 정규화 기법 사용 가능

**차이점**:
- **다변량 회귀**: 전역 최적해, 빠른 학습
- **SVM**: 서포트 벡터 기반, 비선형 커널 지원

## 6. 적용 사례 및 한계

### 실제 적용 분야
1. **부동산**: 주택 가격 예측 (면적, 위치, 연식 등)
2. **금융**: 주식 가격, 신용 점수 예측
3. **마케팅**: 매출 예측, 고객 생애 가치 추정
4. **의료**: 치료 효과 예측, 생체 지표 분석
5. **제조업**: 품질 관리, 수율 예측

### 알고리즘의 장점
1. **해석 가능성**: 각 특성의 영향도 명확
2. **계산 효율성**: 빠른 학습과 예측
3. **안정성**: 작은 데이터 변화에 robust
4. **이론적 기반**: 통계학적으로 잘 정립됨
5. **기준 모델**: 다른 알고리즘과 비교 기준

### 알고리즘의 한계
1. **선형 가정**: 비선형 관계 모델링 어려움
2. **특성 의존성**: 좋은 특성 엔지니어링 필요
3. **이상치 민감성**: 극값에 크게 영향받음
4. **다중공선성**: 상관된 특성들로 인한 불안정성
5. **차원의 저주**: 특성 수가 샘플 수보다 많으면 문제

### 사용 시 주의사항
1. **가정 검증**: 선형성, 등분산성 등 확인 필수
2. **특성 선택**: 관련 없는 특성 제거
3. **정규화**: 특성 스케일 차이 해결
4. **교차검증**: 과적합 방지
5. **잔차 분석**: 모델 적합성 진단

## 7. 용어 사전

### 핵심 용어
- **회귀 계수 (Regression Coefficient)**: 각 특성의 가중치 βᵢ
- **절편 (Intercept)**: 모든 특성이 0일 때의 예측값 β₀
- **잔차 (Residual)**: 실제값과 예측값의 차이 (yᵢ - ŷᵢ)
- **설계 행렬 (Design Matrix)**: 특성들을 행렬로 구성한 X
- **정규방정식 (Normal Equation)**: 해석적 해를 구하는 공식

### 통계 용어
- **다중공선성 (Multicollinearity)**: 독립변수들 간의 강한 상관관계
- **등분산성 (Homoscedasticity)**: 오차의 분산이 일정한 성질
- **이분산성 (Heteroscedasticity)**: 오차의 분산이 불균등한 상태
- **자기상관 (Autocorrelation)**: 시계열 데이터의 시간적 상관관계
- **더빈-왓슨 통계량**: 자기상관 검정 통계량

### 정규화 용어
- **Ridge 회귀**: L2 정규화를 적용한 선형 회귀
- **Lasso 회귀**: L1 정규화를 적용한 선형 회귀
- **Elastic Net**: L1과 L2 정규화를 결합한 방법
- **정규화 경로**: 정규화 강도에 따른 계수 변화
- **교차검증**: 모델 성능을 안정적으로 평가하는 방법

### 평가 지표
- **MSE (Mean Squared Error)**: 평균 제곱 오차
- **MAE (Mean Absolute Error)**: 평균 절대 오차
- **RMSE (Root Mean Squared Error)**: 평균 제곱근 오차
- **R² (R-squared)**: 결정계수, 설명력
- **조정된 R²**: 특성 개수를 고려한 결정계수

### 수식 기호
- **β (베타)**: 회귀 계수
- **ε (엡실론)**: 오차항
- **ŷ (y-hat)**: 예측값
- **X**: 특성 행렬 (설계 행렬)
- **y**: 타겟 벡터 (종속 변수)
- **n**: 샘플 개수
- **p**: 특성 개수
- **α (알파)**: 정규화 강도 파라미터

### 개념 간 연관성
1. **선형성 → 해석가능성**: 선형 관계로 인한 직관적 이해
2. **최소제곱법 → 정규방정식**: 수학적 최적화의 해석적 해
3. **정규화 → 과적합 방지**: 복잡도 제어를 통한 일반화 성능 향상
4. **다중공선성 → 불안정성**: 상관된 특성들로 인한 계수 추정 문제
5. **잔차 분석 → 모델 진단**: 가정 위반 여부 확인 도구