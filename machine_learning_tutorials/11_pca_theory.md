# 주성분 분석(PCA) 완전 이론 가이드

## 1. 개요 및 핵심 개념

### 주성분 분석(Principal Component Analysis, PCA)이란?
주성분 분석은 고차원 데이터를 저차원으로 축소하면서 원본 데이터의 분산을 최대한 보존하는 차원 축소 기법입니다. 데이터의 주요 패턴을 찾아내어 새로운 좌표계(주성분)로 변환하는 비지도 학습 방법입니다.

### 핵심 목표
- **차원 축소**: 고차원 데이터를 저차원으로 변환
- **분산 최대화**: 변환된 데이터에서 분산을 최대한 보존
- **노이즈 제거**: 주요 패턴만 추출하여 노이즈 감소
- **시각화**: 고차원 데이터를 2D/3D로 시각화 가능

### 주요 응용 분야
- **이미지 압축**: 얼굴 인식, 이미지 처리
- **데이터 시각화**: 고차원 데이터의 2D/3D 표현
- **특징 추출**: 머신러닝 전처리 단계
- **노이즈 제거**: 신호 처리, 데이터 정제

## 2. 수학적 기초 개념

### 공분산 행렬(Covariance Matrix)
공분산 행렬은 변수들 간의 선형 관계를 나타내는 대칭 행렬입니다.

**공분산 정의:**
- Cov(X, Y) = E[(X - μₓ)(Y - μᵧ)]
- 양수: 양의 상관관계
- 음수: 음의 상관관계  
- 0: 선형 무관계

**공분산 행렬 C:**
```
C = [Cov(X₁,X₁)  Cov(X₁,X₂)  ...  Cov(X₁,Xₙ)]
    [Cov(X₂,X₁)  Cov(X₂,X₂)  ...  Cov(X₂,Xₙ)]
    [    ...         ...      ...      ...    ]
    [Cov(Xₙ,X₁)  Cov(Xₙ,X₂)  ...  Cov(Xₙ,Xₙ)]
```

### 고유값과 고유벡터(Eigenvalues & Eigenvectors)
**정의:**
- Av = λv (A: 행렬, v: 고유벡터, λ: 고유값)
- 고유벡터: 행렬 변환 시 방향이 변하지 않는 벡터
- 고유값: 고유벡터 방향으로의 스케일링 정도

**PCA에서의 의미:**
- 고유벡터: 주성분의 방향 (새로운 축)
- 고유값: 해당 방향의 분산 크기
- 고유값이 클수록 더 중요한 주성분

### 분산과 정보 보존
**전체 분산:**
- 모든 고유값의 합 = 원본 데이터의 총 분산
- 각 주성분의 분산 = 해당 고유값

**분산 설명 비율:**
- k번째 주성분의 설명 비율 = λₖ / Σλᵢ
- 누적 설명 비율로 차원 수 결정

## 3. PCA 동작 원리

### 단계별 알고리즘

**1단계: 데이터 중심화(Centering)**
```
X_centered = X - mean(X)
```
- 각 특성의 평균을 0으로 만듦
- 주성분이 원점을 지나도록 보장

**2단계: 공분산 행렬 계산**
```
C = (1/n-1) × X_centered^T × X_centered
```
- 특성 간 선형 관계 파악
- 대칭 행렬 형태

**3단계: 고유값 분해**
```
C = V × Λ × V^T
```
- V: 고유벡터 행렬 (주성분 방향)
- Λ: 고유값 대각행렬 (분산 크기)

**4단계: 주성분 선택**
- 고유값 크기 순으로 정렬
- 상위 k개 주성분 선택
- 누적 분산 비율 기준 (예: 95%)

**5단계: 데이터 변환**
```
Y = X_centered × V_k
```
- 원본 데이터를 주성분 공간으로 투영
- k차원으로 차원 축소 완료

### 기하학적 해석
- **1차원 투영**: 데이터 분산이 최대인 직선 찾기
- **2차원 투영**: 첫 번째 주성분에 수직이면서 분산 최대인 평면
- **직교성**: 모든 주성분은 서로 수직 (독립적)

## 4. 파라미터 구성 및 선택 기준

### 주요 파라미터

**1. 주성분 개수 (n_components)**
- 유지할 차원의 수
- 선택 기준:
  - 누적 분산 비율 (85-95%)
  - 스크리 플롯의 엘보우 지점
  - 교차 검증 성능

**2. 표준화 여부**
- 특성 간 스케일 차이가 클 때 필요
- StandardScaler 적용 후 PCA 수행
- 단위가 다른 변수들의 공정한 비교

### 차원 수 선택 방법

**1. 분산 설명 비율**
```python
cumsum_ratio = np.cumsum(pca.explained_variance_ratio_)
n_components = np.argmax(cumsum_ratio >= 0.95) + 1
```

**2. 스크리 플롯(Scree Plot)**
- 고유값을 크기 순으로 플롯
- 급격한 감소 지점(엘보우) 찾기
- 시각적 판단 방법

**3. 카이저 기준(Kaiser Criterion)**
- 고유값 > 1인 주성분만 선택
- 표준화된 데이터에 적용

## 5. 성능 평가 방법

### 차원 축소 품질 지표

**1. 분산 설명 비율**
- 개별 주성분: explained_variance_ratio_
- 누적 비율: cumulative explained variance
- 높을수록 정보 보존 우수

**2. 재구성 오차(Reconstruction Error)**
```
재구성 오차 = ||X - X_reconstructed||²
```
- 원본과 복원 데이터 간 차이
- 낮을수록 품질 우수

**3. 실루엣 계수 (클러스터링 적용 시)**
- PCA 후 클러스터링 성능 평가
- 차원 축소가 클러스터 구조 보존하는지 확인

### 시각화 평가
- **2D/3D 산점도**: 클래스별 분리도 확인
- **주성분 로딩**: 원본 변수와 주성분 관계
- **바이플롯**: 데이터와 변수를 동시 표시

## 6. 다른 알고리즘과의 비교

### PCA vs 다른 차원 축소 기법

**PCA vs LDA (Linear Discriminant Analysis)**
- **공통점**: 선형 변환, 차원 축소
- **차이점**: 
  - PCA: 분산 최대화 (비지도)
  - LDA: 클래스 분리 최대화 (지도)

**PCA vs t-SNE**
- **공통점**: 차원 축소, 시각화
- **차이점**:
  - PCA: 선형, 전역 구조 보존
  - t-SNE: 비선형, 지역 구조 보존

**PCA vs Autoencoder**
- **공통점**: 차원 축소, 재구성
- **차이점**:
  - PCA: 선형 변환, 해석 가능
  - Autoencoder: 비선형, 복잡한 패턴

### 장단점 비교

**PCA 장점:**
- 수학적으로 명확한 해석
- 계산 효율성 우수
- 노이즈 제거 효과
- 과적합 위험 낮음

**PCA 단점:**
- 선형 관계만 포착
- 모든 원본 변수 필요
- 주성분 해석의 어려움
- 이상치에 민감

## 7. 적용 사례 및 한계

### 실제 적용 분야

**1. 이미지 처리**
- 얼굴 인식: Eigenfaces
- 이미지 압축: JPEG 유사 원리
- 의료 영상: MRI, CT 스캔 분석

**2. 금융 분야**
- 포트폴리오 최적화
- 리스크 팩터 분석
- 신용 평가 모델

**3. 생물정보학**
- 유전자 발현 데이터 분석
- 단백질 구조 분석
- 진화 관계 연구

### 사용 시 주의사항

**1. 데이터 전처리**
- 결측값 처리 필수
- 이상치 제거 고려
- 적절한 표준화 적용

**2. 해석상 주의점**
- 주성분의 물리적 의미 불분명
- 원본 변수와의 관계 복잡
- 도메인 지식과 결합 필요

**3. 성능 한계**
- 비선형 패턴 포착 불가
- 클래스 정보 미활용
- 지역적 구조 손실 가능

## 8. 고급 주제

### 커널 PCA (Kernel PCA)
- 비선형 차원 축소
- 커널 트릭 활용
- 복잡한 매니폴드 구조 포착

### 증분 PCA (Incremental PCA)
- 대용량 데이터 처리
- 메모리 효율적
- 온라인 학습 가능

### 희소 PCA (Sparse PCA)
- 해석 가능성 향상
- 일부 변수만 사용
- 정규화 기법 적용

## 9. 용어 사전

**주성분(Principal Component)**: 데이터 분산을 최대화하는 새로운 축
**로딩(Loading)**: 원본 변수와 주성분 간의 상관계수
**스코어(Score)**: 주성분 공간에서의 데이터 좌표
**고유값 분해**: 행렬을 고유벡터와 고유값으로 분해
**특이값 분해(SVD)**: PCA 계산의 대안적 방법
**바이플롯(Biplot)**: 데이터와 변수를 동시에 표시하는 그래프
**스크리 플롯**: 고유값을 순서대로 나타낸 그래프
**재구성**: 축소된 데이터로부터 원본 차원으로 복원
**직교성**: 주성분들이 서로 수직인 성질
**분산 설명력**: 각 주성분이 설명하는 전체 분산의 비율