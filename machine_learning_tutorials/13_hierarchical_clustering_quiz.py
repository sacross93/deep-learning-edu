"""
계층적 클러스터링 퀴즈

이 퀴즈는 계층적 클러스터링의 핵심 개념, 연결 기준, 덴드로그램 해석,
그리고 다른 클러스터링 알고리즘과의 비교에 대한 이해도를 평가합니다.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.quiz_utils import QuizManager
import numpy as np
import matplotlib.pyplot as plt

def create_hierarchical_clustering_quiz():
    """계층적 클러스터링 퀴즈 생성"""
    
    quiz_manager = QuizManager("계층적 클러스터링")
    
    # 문제 1: 기본 개념 이해
    quiz_manager.add_question(
        question="계층적 클러스터링에 대한 설명으로 옳지 않은 것은?",
        options=[
            "클러스터 개수를 미리 지정할 필요가 없다",
            "덴드로그램을 통해 클러스터링 과정을 시각화할 수 있다",
            "K-평균보다 항상 더 좋은 성능을 보인다",
            "결정론적 알고리즘으로 동일한 입력에 대해 같은 결과를 생성한다"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (K-평균보다 항상 더 좋은 성능을 보인다)

해설:
계층적 클러스터링이 K-평균보다 항상 더 좋은 성능을 보이는 것은 아닙니다.
각 알고리즘은 고유한 장단점이 있으며, 데이터의 특성과 문제 상황에 따라
성능이 달라집니다.

• 계층적 클러스터링의 장점: 클러스터 개수 사전 지정 불필요, 덴드로그램 제공
• K-평균의 장점: 빠른 속도, 대용량 데이터 처리 가능
• 성능은 데이터 특성, 클러스터 형태, 노이즈 정도 등에 따라 달라짐
        """
    )
    
    # 문제 2: 연결 기준 이해
    quiz_manager.add_question(
        question="다음 연결 기준(Linkage Criteria) 중 체인 효과(Chaining Effect)가 가장 심하게 나타나는 것은?",
        options=[
            "단일 연결 (Single Linkage)",
            "완전 연결 (Complete Linkage)", 
            "평균 연결 (Average Linkage)",
            "워드 연결 (Ward Linkage)"
        ],
        correct_answer=0,
        explanation="""
정답: 1번 (단일 연결)

해설:
단일 연결은 두 클러스터에서 가장 가까운 점들 간의 거리를 사용하므로
체인 효과가 가장 심하게 나타납니다.

• 단일 연결: min{d(a,b) : a∈A, b∈B} → 체인 효과 발생
• 완전 연결: max{d(a,b) : a∈A, b∈B} → 컴팩트한 클러스터 생성
• 평균 연결: 모든 점 쌍의 평균 거리 → 균형잡힌 결과
• 워드 연결: 분산 증가량 최소화 → 구형 클러스터 선호

체인 효과는 긴 형태의 클러스터가 형성되는 현상으로, 
실제 데이터 구조를 왜곡할 수 있습니다.
        """
    )
    
    # 문제 3: 덴드로그램 해석
    quiz_manager.add_question(
        question="덴드로그램에서 두 데이터 포인트가 높은 위치에서 병합된다는 것은 무엇을 의미합니까?",
        options=[
            "두 데이터 포인트가 매우 유사하다",
            "두 데이터 포인트가 서로 다르다",
            "두 데이터 포인트가 같은 클러스터에 속한다",
            "두 데이터 포인트가 이상치이다"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (두 데이터 포인트가 서로 다르다)

해설:
덴드로그램에서 병합 높이는 클러스터 간의 거리를 나타냅니다.

• 낮은 높이에서 병합: 유사한 데이터들의 병합 (작은 거리)
• 높은 높이에서 병합: 서로 다른 그룹들의 병합 (큰 거리)
• 병합 높이 = 클러스터 간 거리 (연결 기준에 따라 계산)

따라서 높은 위치에서 병합되는 것은 두 데이터 포인트(또는 클러스터)가
서로 많이 다르다는 것을 의미합니다. 이는 자연스러운 클러스터 경계를
나타내는 중요한 정보입니다.
        """
    )
    
    # 문제 4: 클러스터 개수 결정
    quiz_manager.add_question(
        question="덴드로그램을 이용하여 최적의 클러스터 개수를 결정할 때 주로 사용하는 방법은?",
        options=[
            "가장 낮은 병합 높이를 찾는다",
            "병합 높이의 급격한 증가가 일어나는 지점을 찾는다",
            "가장 많은 데이터 포인트가 포함된 클러스터를 찾는다",
            "무작위로 절단선을 그어서 결정한다"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (병합 높이의 급격한 증가가 일어나는 지점을 찾는다)

해설:
덴드로그램에서 최적 클러스터 개수를 결정하는 주요 방법:

1. **엘보우 방법**: 병합 높이가 급격히 증가하는 지점
   - 높이 증가율이 크게 변하는 지점 = 자연스러운 클러스터 경계
   
2. **시각적 판단**: 덴드로그램에서 명확한 분리가 보이는 지점
   - 큰 높이 차이 = 서로 다른 그룹들의 병합
   
3. **도메인 지식**: 문제 영역의 특성을 고려한 결정

급격한 높이 증가는 서로 다른 자연스러운 그룹들이 병합되기 시작함을
의미하므로, 그 직전이 적절한 클러스터 개수입니다.
        """
    )
    
    # 문제 5: 워드 연결의 특성
    quiz_manager.add_question(
        question="워드 연결(Ward Linkage)의 특징으로 옳은 것은?",
        options=[
            "클러스터 간 최소 거리를 사용한다",
            "클러스터 간 최대 거리를 사용한다",
            "클러스터 내 분산의 증가량을 최소화한다",
            "모든 거리 척도와 함께 사용할 수 있다"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (클러스터 내 분산의 증가량을 최소화한다)

해설:
워드 연결의 특징:

• **목적**: 클러스터 내 분산(Within-cluster variance) 최소화
• **계산**: 두 클러스터 병합 시 증가하는 분산의 양을 측정
• **수식**: d(A,B) = √[(|A||B|)/(|A|+|B|)] ||μ_A - μ_B||²
• **제약**: 유클리드 거리만 사용 가능 (분산 계산을 위해)

워드 연결의 장점:
- 크기가 비슷한 구형 클러스터 생성
- 클러스터 내 응집도가 높음
- 가장 널리 사용되는 방법 중 하나

다른 연결 기준들과 달리 워드는 분산 기반 접근법을 사용합니다.
        """
    )
    
    # 문제 6: 계산 복잡도
    quiz_manager.add_question(
        question="계층적 클러스터링의 시간 복잡도는?",
        options=[
            "O(n)",
            "O(n log n)",
            "O(n²)",
            "O(n³)"
        ],
        correct_answer=3,
        explanation="""
정답: 4번 (O(n³))

해설:
계층적 클러스터링의 복잡도:

**시간 복잡도: O(n³)**
- n개 데이터 포인트에 대해 n-1번의 병합 수행
- 각 단계에서 O(n²)개의 거리 계산 및 업데이트
- 총 시간: O(n) × O(n²) = O(n³)

**공간 복잡도: O(n²)**
- 거리 행렬 저장: n×n 크기

**K-평균과 비교:**
- K-평균: O(nkt) (k=클러스터 수, t=반복 횟수)
- 일반적으로 k << n, t << n이므로 K-평균이 훨씬 빠름

이러한 높은 복잡도 때문에 계층적 클러스터링은 
대용량 데이터에는 적합하지 않습니다.
        """
    )
    
    # 문제 7: 응집형 vs 분할형
    quiz_manager.add_question(
        question="응집형(Agglomerative) 클러스터링과 분할형(Divisive) 클러스터링의 차이점으로 옳은 것은?",
        options=[
            "응집형은 하향식, 분할형은 상향식 접근법이다",
            "응집형은 상향식, 분할형은 하향식 접근법이다",
            "응집형이 분할형보다 항상 더 정확하다",
            "분할형이 응집형보다 항상 더 빠르다"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (응집형은 상향식, 분할형은 하향식 접근법이다)

해설:

**응집형 클러스터링 (Agglomerative):**
- **상향식(Bottom-up)** 접근법
- 개별 데이터 포인트에서 시작
- 점진적으로 클러스터를 병합
- 더 널리 사용됨

**분할형 클러스터링 (Divisive):**
- **하향식(Top-down)** 접근법  
- 전체 데이터를 하나의 클러스터로 시작
- 점진적으로 클러스터를 분할
- 계산 복잡도가 더 높음

**실제 사용:**
- 응집형이 구현이 쉽고 효율적이어서 더 널리 사용
- 분할형은 이론적으로는 흥미롭지만 실용성이 떨어짐
        """
    )
    
    # 문제 8: 실루엣 계수 해석
    quiz_manager.add_question(
        question="계층적 클러스터링 결과의 실루엣 계수가 0.7이라면, 이는 무엇을 의미합니까?",
        options=[
            "매우 나쁜 클러스터링 결과",
            "보통 수준의 클러스터링 결과",
            "좋은 클러스터링 결과",
            "완벽한 클러스터링 결과"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (좋은 클러스터링 결과)

해설:
실루엣 계수(Silhouette Coefficient) 해석:

**범위**: [-1, 1]
- **1에 가까움**: 매우 좋은 클러스터링 (클러스터가 잘 분리됨)
- **0 근처**: 클러스터가 겹치거나 경계가 모호함
- **-1에 가까움**: 잘못된 클러스터링 (잘못 할당된 데이터 많음)

**일반적인 해석 기준:**
- 0.7 이상: 좋은 클러스터링
- 0.5-0.7: 보통 수준
- 0.25-0.5: 약한 구조
- 0.25 미만: 클러스터 구조 없음

**0.7의 의미:**
- 각 데이터 포인트가 자신의 클러스터에 잘 속해 있음
- 클러스터 간 분리가 명확함
- 실용적으로 만족스러운 결과
        """
    )
    
    # 문제 9: 전처리의 중요성
    quiz_manager.add_question(
        question="계층적 클러스터링을 수행하기 전에 데이터 표준화가 중요한 이유는?",
        options=[
            "알고리즘의 수렴 속도를 높이기 위해",
            "서로 다른 스케일의 특성들이 거리 계산에 미치는 영향을 균등하게 하기 위해",
            "메모리 사용량을 줄이기 위해",
            "덴드로그램을 더 예쁘게 그리기 위해"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (서로 다른 스케일의 특성들이 거리 계산에 미치는 영향을 균등하게 하기 위해)

해설:
데이터 표준화의 중요성:

**문제 상황:**
- 특성들의 스케일이 다름 (예: 나이 0-100, 소득 0-100,000)
- 큰 스케일의 특성이 거리 계산을 지배
- 작은 스케일의 중요한 특성이 무시됨

**표준화 효과:**
- 모든 특성을 동일한 스케일로 변환 (평균=0, 표준편차=1)
- 각 특성이 거리 계산에 공평하게 기여
- 더 의미 있는 클러스터링 결과

**예시:**
표준화 전: 소득 차이 10,000원 >> 나이 차이 10세
표준화 후: 모든 특성이 동등한 가중치

계층적 클러스터링은 거리 기반 알고리즘이므로 
표준화가 특히 중요합니다.
        """
    )
    
    # 문제 10: 실제 적용 시나리오
    quiz_manager.add_question(
        question="다음 중 계층적 클러스터링이 K-평균보다 더 적합한 상황은?",
        options=[
            "100만 개의 고객 데이터를 빠르게 세분화해야 할 때",
            "클러스터 개수를 미리 알 수 없고, 클러스터 간 계층 관계를 파악하고 싶을 때",
            "구형 클러스터만 존재하는 데이터를 처리할 때",
            "실시간으로 새로운 데이터를 클러스터에 할당해야 할 때"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (클러스터 개수를 미리 알 수 없고, 클러스터 간 계층 관계를 파악하고 싶을 때)

해설:
각 상황별 적합한 알고리즘:

**계층적 클러스터링이 적합한 경우:**
- 클러스터 개수를 모를 때
- 계층 구조가 중요할 때 (예: 생물 분류학)
- 덴드로그램을 통한 시각적 해석이 필요할 때
- 소규모 데이터 (< 10,000개)

**K-평균이 적합한 경우:**
- 대용량 데이터 처리 (100만 개 → K-평균)
- 빠른 처리 속도가 필요할 때
- 구형 클러스터가 예상될 때
- 실시간 할당이 필요할 때

**실제 적용 예시:**
- 생물 종 분류: 계층적 (계통 관계 중요)
- 고객 세분화: K-평균 (대용량, 속도 중요)
- 유전자 분석: 계층적 (계층 구조 의미 있음)
        """
    )
    
    return quiz_manager

def main():
    """퀴즈 실행 메인 함수"""
    print("="*60)
    print("계층적 클러스터링 퀴즈")
    print("="*60)
    print()
    print("이 퀴즈는 계층적 클러스터링의 핵심 개념들을 다룹니다:")
    print("• 기본 개념과 특징")
    print("• 연결 기준의 종류와 특성")
    print("• 덴드로그램 해석 방법")
    print("• 클러스터 개수 결정")
    print("• 성능 평가 지표")
    print("• 다른 알고리즘과의 비교")
    print("• 실제 적용 시나리오")
    print()
    
    # 퀴즈 생성 및 실행
    quiz_manager = create_hierarchical_clustering_quiz()
    results = quiz_manager.run_quiz()
    
    # 결과 출력
    print("\n" + "="*60)
    print("퀴즈 결과 분석")
    print("="*60)
    
    score = results['score']
    total = results['total']
    percentage = results['percentage']
    
    print(f"총 점수: {score}/{total} ({percentage:.1f}%)")
    
    if percentage >= 90:
        print("🏆 훌륭합니다! 계층적 클러스터링을 완벽하게 이해하고 있습니다.")
    elif percentage >= 80:
        print("👍 잘했습니다! 계층적 클러스터링의 핵심 개념을 잘 파악하고 있습니다.")
    elif percentage >= 70:
        print("👌 괜찮습니다! 몇 가지 개념을 더 복습해보세요.")
    elif percentage >= 60:
        print("📚 더 공부가 필요합니다. 이론 문서를 다시 읽어보세요.")
    else:
        print("💪 포기하지 마세요! 기초부터 차근차근 다시 학습해보세요.")
    
    # 틀린 문제 분석
    wrong_questions = results['wrong_questions']
    if wrong_questions:
        print(f"\n틀린 문제: {len(wrong_questions)}개")
        print("다음 주제들을 더 공부해보세요:")
        
        topics = {
            1: "계층적 클러스터링 기본 개념",
            2: "연결 기준의 특성",
            3: "덴드로그램 해석",
            4: "클러스터 개수 결정",
            5: "워드 연결의 특징",
            6: "계산 복잡도",
            7: "응집형 vs 분할형",
            8: "성능 평가 지표",
            9: "데이터 전처리",
            10: "실제 적용 시나리오"
        }
        
        for q_num in wrong_questions:
            print(f"  • {topics.get(q_num, f'문제 {q_num}')}")
    
    print("\n" + "="*60)
    print("학습 권장사항")
    print("="*60)
    
    if percentage < 70:
        print("📖 13_hierarchical_clustering_theory.md 문서를 다시 읽어보세요.")
        print("💻 13_hierarchical_clustering_practice.py 실습을 다시 실행해보세요.")
    
    print("🔍 추가 학습 주제:")
    print("  • 다양한 연결 기준의 실제 적용 사례")
    print("  • 대용량 데이터를 위한 근사 계층적 클러스터링")
    print("  • 계층적 클러스터링과 다른 클러스터링 알고리즘의 앙상블")
    print("  • 생물정보학에서의 계층적 클러스터링 활용")
    
    return results

if __name__ == "__main__":
    main()