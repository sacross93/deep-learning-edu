"""
유사도와 거리 퀴즈

이 퀴즈는 유사도와 거리 척도에 대한 이해도를 확인합니다.
거리 척도 선택 기준, 유사도 계산, 해석 방법을 다룹니다.
"""

import numpy as np
import sys
import os

# utils 모듈 경로 추가
sys.path.append(os.path.join(os.path.dirname(__file__), 'utils'))
from quiz_utils import QuizManager

def create_similarity_distance_quiz():
    """유사도와 거리 퀴즈 생성"""
    
    quiz = QuizManager("유사도와 거리 척도 퀴즈")
    
    # 문제 1: 기본 개념 이해
    quiz.add_multiple_choice(
        question="다음 중 거리 함수가 만족해야 하는 메트릭(metric) 조건이 아닌 것은?",
        choices=[
            "d(x,y) ≥ 0 (비음성)",
            "d(x,x) = 0 (동일성)",
            "d(x,y) = d(y,x) (대칭성)",
            "d(x,y) + d(y,z) ≥ d(x,z) (삼각부등식)",
            "d(x,y) = 1 - sim(x,y) (유사도 변환)"
        ],
        correct_answer=4,
        explanation="""
        메트릭 조건은 다음 4가지입니다:
        1. 비음성: d(x,y) ≥ 0
        2. 동일성: d(x,x) = 0
        3. 대칭성: d(x,y) = d(y,x)  
        4. 삼각부등식: d(x,y) + d(y,z) ≥ d(x,z)
        
        'd(x,y) = 1 - sim(x,y)'는 거리와 유사도 간의 일반적인 변환 공식이지만 
        메트릭의 필수 조건은 아닙니다.
        """
    )
    
    # 문제 2: 거리 계산
    quiz.add_calculation(
        question="""
        두 벡터 A = [3, 4], B = [0, 0]에 대해 다음 거리들을 계산하세요:
        1) 유클리드 거리
        2) 맨해튼 거리  
        3) 민코프스키 거리 (p=3)
        """,
        expected_answer={
            "euclidean": 5.0,
            "manhattan": 7.0,
            "minkowski_p3": 4.327
        },
        explanation="""
        계산 과정:
        
        1) 유클리드 거리: √((3-0)² + (4-0)²) = √(9 + 16) = √25 = 5
        
        2) 맨해튼 거리: |3-0| + |4-0| = 3 + 4 = 7
        
        3) 민코프스키 거리 (p=3): (|3-0|³ + |4-0|³)^(1/3) = (27 + 64)^(1/3) = 91^(1/3) ≈ 4.327
        
        p 값이 증가할수록 최대 차이에 더 민감해집니다.
        """
    )
    
    # 문제 3: 코사인 유사도
    quiz.add_calculation(
        question="""
        벡터 X = [1, 2, 3], Y = [2, 4, 6]의 코사인 유사도를 계산하세요.
        (소수점 둘째 자리까지)
        """,
        expected_answer=1.00,
        explanation="""
        코사인 유사도 = (X·Y) / (||X|| ||Y||)
        
        X·Y = 1×2 + 2×4 + 3×6 = 2 + 8 + 18 = 28
        ||X|| = √(1² + 2² + 3²) = √14 ≈ 3.742
        ||Y|| = √(2² + 4² + 6²) = √56 ≈ 7.483
        
        코사인 유사도 = 28 / (3.742 × 7.483) = 28 / 28 = 1.00
        
        Y = 2X이므로 두 벡터는 같은 방향을 가리켜 완전히 유사합니다.
        """
    )
    
    # 문제 4: 거리 척도 선택
    quiz.add_multiple_choice(
        question="""
        다음 상황에서 가장 적절한 거리 척도는?
        
        상황: 고차원 텍스트 데이터(TF-IDF 벡터)에서 문서 간 유사도를 측정하여 
        추천 시스템을 구축하려고 합니다. 문서의 길이보다는 내용의 유사성이 중요합니다.
        """,
        choices=[
            "유클리드 거리",
            "맨해튼 거리", 
            "마할라노비스 거리",
            "코사인 유사도",
            "자카드 유사도"
        ],
        correct_answer=3,
        explanation="""
        코사인 유사도가 가장 적절합니다.
        
        이유:
        1. 문서 길이(벡터 크기)에 무관하게 내용 유사성 측정
        2. 고차원 희소 벡터(TF-IDF)에서 효과적
        3. 텍스트 마이닝과 추천 시스템의 표준 척도
        4. 정규화 효과로 스케일 문제 해결
        
        다른 선택지들의 문제점:
        - 유클리드/맨해튼: 문서 길이에 민감, 고차원에서 성능 저하
        - 마할라노비스: 계산 복잡, 희소 데이터에 부적합
        - 자카드: 이진 데이터용, TF-IDF의 연속값 활용 못함
        """
    )
    
    # 문제 5: 이진 데이터 유사도
    quiz.add_multiple_choice(
        question="""
        두 이진 벡터 A = [1,0,1,1,0], B = [1,1,0,1,0]에 대해
        자카드 유사도와 SMC(Simple Matching Coefficient)를 계산했을 때 올바른 것은?
        """,
        choices=[
            "자카드: 0.5, SMC: 0.6",
            "자카드: 0.4, SMC: 0.6", 
            "자카드: 0.33, SMC: 0.6",
            "자카드: 0.5, SMC: 0.8",
            "자카드: 0.6, SMC: 0.6"
        ],
        correct_answer=2,
        explanation="""
        A = [1,0,1,1,0], B = [1,1,0,1,0]
        
        매칭 테이블:
        - M₁₁ (둘 다 1): 위치 0, 3 → 2개
        - M₀₀ (둘 다 0): 위치 4 → 1개  
        - M₁₀ (A=1, B=0): 위치 2 → 1개
        - M₀₁ (A=0, B=1): 위치 1 → 1개
        
        자카드 = M₁₁ / (M₁₁ + M₁₀ + M₀₁) = 2 / (2 + 1 + 1) = 2/6 = 0.33
        SMC = (M₁₁ + M₀₀) / 전체 = (2 + 1) / 5 = 3/5 = 0.6
        
        자카드는 공통으로 0인 경우를 무시하고, SMC는 모든 일치를 고려합니다.
        """
    )
    
    # 문제 6: 정보 이론
    quiz.add_calculation(
        question="""
        확률 분포 P = [0.5, 0.25, 0.25]의 엔트로피를 계산하세요.
        (log₂ 사용, 소수점 둘째 자리까지)
        """,
        expected_answer=1.50,
        explanation="""
        엔트로피 H(X) = -Σ P(xᵢ) log₂ P(xᵢ)
        
        H(X) = -(0.5 × log₂(0.5) + 0.25 × log₂(0.25) + 0.25 × log₂(0.25))
             = -(0.5 × (-1) + 0.25 × (-2) + 0.25 × (-2))
             = -(-0.5 - 0.5 - 0.5)
             = 1.5
        
        엔트로피가 높을수록 불확실성이 크며, 균등분포일 때 최대가 됩니다.
        """
    )
    
    # 문제 7: 차원의 저주
    quiz.add_multiple_choice(
        question="""
        고차원 데이터에서 발생하는 '차원의 저주(Curse of Dimensionality)'와 
        관련된 설명으로 올바른 것은?
        """,
        choices=[
            "차원이 증가하면 유클리드 거리의 차별력이 향상된다",
            "모든 점 간 거리가 비슷해져서 거리 기반 알고리즘의 성능이 저하된다",
            "맨해튼 거리는 차원의 저주에 영향을 받지 않는다", 
            "코사인 유사도는 고차원에서 사용할 수 없다",
            "차원이 높을수록 데이터 포인트 간 구별이 쉬워진다"
        ],
        correct_answer=1,
        explanation="""
        차원의 저주의 주요 현상:
        
        1. 고차원에서 모든 점 간 거리가 비슷해짐
        2. 최근접 이웃과 최원접 이웃의 거리 차이 감소
        3. 거리 기반 알고리즘(KNN, K-means 등)의 성능 저하
        
        해결 방법:
        - 차원 축소 (PCA, t-SNE 등)
        - 맨해튼 거리나 코사인 유사도 사용
        - 특징 선택을 통한 차원 감소
        
        코사인 유사도는 오히려 고차원 희소 데이터에서 효과적입니다.
        """
    )
    
    # 문제 8: 실제 적용 시나리오
    quiz.add_multiple_choice(
        question="""
        다음 시나리오에서 가장 적절한 거리/유사도 척도의 조합은?
        
        시나리오 1: 고객 구매 이력 (이진 데이터)으로 유사 고객 찾기
        시나리오 2: 센서 데이터 (연속형)에서 이상치 탐지  
        시나리오 3: 이미지 특징 벡터 (고차원)로 유사 이미지 검색
        """,
        choices=[
            "1) 자카드, 2) 유클리드, 3) 코사인",
            "1) SMC, 2) 마할라노비스, 3) 맨해튼",
            "1) 자카드, 2) 마할라노비스, 3) 코사인", 
            "1) 코사인, 2) 유클리드, 3) 자카드",
            "1) SMC, 2) 맨해튼, 3) 유클리드"
        ],
        correct_answer=2,
        explanation="""
        각 시나리오별 최적 척도:
        
        시나리오 1 (고객 구매 이력):
        - 자카드 유사도: 공통 구매 상품에 집중, 구매하지 않은 상품은 무시
        
        시나리오 2 (센서 데이터 이상치 탐지):
        - 마할라노비스 거리: 센서 간 상관관계 고려, 다변량 이상치 탐지에 효과적
        
        시나리오 3 (이미지 특징 벡터):
        - 코사인 유사도: 고차원에서 안정적, 벡터 크기보다 패턴 유사성 중요
        
        이 조합이 각 도메인의 특성과 데이터 유형에 가장 적합합니다.
        """
    )
    
    # 문제 9: 상호정보량 해석
    quiz.add_multiple_choice(
        question="""
        두 변수 X, Y의 상호정보량 I(X,Y) = 0.8이고, 
        H(X) = 1.2, H(Y) = 1.5일 때, 조건부 엔트로피 H(Y|X)는?
        """,
        choices=[
            "0.3",
            "0.7", 
            "1.1",
            "1.9",
            "2.3"
        ],
        correct_answer=1,
        explanation="""
        상호정보량과 엔트로피의 관계:
        I(X,Y) = H(Y) - H(Y|X)
        
        따라서:
        H(Y|X) = H(Y) - I(X,Y) = 1.5 - 0.8 = 0.7
        
        해석:
        - H(Y) = 1.5: Y의 원래 불확실성
        - H(Y|X) = 0.7: X를 알았을 때 Y의 남은 불확실성  
        - I(X,Y) = 0.8: X가 Y에 대해 제공하는 정보량
        
        X를 관찰함으로써 Y의 불확실성이 1.5에서 0.7로 감소했습니다.
        """
    )
    
    # 문제 10: 종합 분석
    quiz.add_essay(
        question="""
        다음 상황에서 적절한 거리/유사도 척도를 선택하고 그 이유를 설명하세요:
        
        상황: 온라인 쇼핑몰에서 상품 추천 시스템을 구축합니다. 
        사용자-상품 평점 행렬이 있으며, 대부분의 값이 0(평점 없음)인 희소 행렬입니다.
        평점 스케일은 1-5점이고, 사용자별로 평점 패턴이 다릅니다 
        (어떤 사용자는 후하게, 어떤 사용자는 박하게 평점).
        
        고려사항:
        1) 적절한 유사도 척도 선택
        2) 희소성 문제 해결 방안  
        3) 평점 패턴 차이 해결 방안
        """,
        sample_answer="""
        추천 시스템을 위한 유사도 척도 선택:
        
        1) 적절한 유사도 척도:
        - 피어슨 상관계수 또는 조정된 코사인 유사도
        - 이유: 평점 패턴 차이(평점 성향)를 자동으로 보정
        
        2) 희소성 문제 해결:
        - 공통 평점 아이템만 고려하는 유사도 계산
        - 최소 공통 아이템 수 임계값 설정
        - 행렬 분해 기법(SVD, NMF) 활용
        
        3) 평점 패턴 차이 해결:
        - 평점 정규화: (평점 - 사용자 평균) / 사용자 표준편차
        - 피어슨 상관계수 사용으로 평균 중심화 효과
        - Z-score 정규화로 스케일 통일
        
        최종 추천: 정규화된 데이터에 피어슨 상관계수 적용
        """,
        explanation="""
        추천 시스템에서는 다음이 중요합니다:
        
        1. 사용자별 평점 성향 차이 보정
        2. 희소 데이터에서의 안정적 유사도 계산  
        3. 공통 선호도 패턴 발견
        
        피어슨 상관계수는 평균 중심화로 평점 성향을 자동 보정하며,
        공통 아이템에 대해서만 계산하여 희소성 문제를 완화합니다.
        """
    )
    
    return quiz

def main():
    """퀴즈 실행 메인 함수"""
    print("=" * 60)
    print("유사도와 거리 척도 퀴즈")
    print("=" * 60)
    print()
    print("이 퀴즈는 유사도와 거리 척도에 대한 이해도를 확인합니다.")
    print("거리 척도 선택 기준, 계산 방법, 실제 적용 사례를 다룹니다.")
    print()
    
    # 퀴즈 생성 및 실행
    quiz = create_similarity_distance_quiz()
    results = quiz.run_quiz()
    
    # 결과 분석
    print("\n" + "=" * 60)
    print("퀴즈 결과 분석")
    print("=" * 60)
    
    total_score = results['total_score']
    max_score = results['max_score']
    percentage = (total_score / max_score) * 100
    
    print(f"총점: {total_score}/{max_score} ({percentage:.1f}%)")
    
    # 성취도별 피드백
    if percentage >= 90:
        print("\n🎉 우수! 유사도와 거리 척도를 매우 잘 이해하고 있습니다.")
        print("다양한 상황에서 적절한 척도를 선택할 수 있는 능력을 갖추었습니다.")
    elif percentage >= 80:
        print("\n👍 양호! 기본 개념을 잘 이해하고 있습니다.")
        print("실제 적용 시나리오에서의 척도 선택 능력을 더 기르면 좋겠습니다.")
    elif percentage >= 70:
        print("\n📚 보통! 기본 개념은 이해했지만 더 학습이 필요합니다.")
        print("각 척도의 특성과 적용 사례를 다시 복습해보세요.")
    else:
        print("\n💪 더 노력! 기본 개념부터 다시 학습하는 것을 권장합니다.")
        print("이론 문서를 다시 읽고 실습 코드를 실행해보세요.")
    
    # 주제별 성취도
    print(f"\n주제별 성취도:")
    topic_scores = results.get('topic_scores', {})
    for topic, score in topic_scores.items():
        print(f"- {topic}: {score['correct']}/{score['total']}")
    
    # 추가 학습 권장사항
    print(f"\n📖 추가 학습 권장사항:")
    if percentage < 80:
        print("- 03_similarity_distance_theory.md 이론 문서 재학습")
        print("- 03_similarity_distance_practice.py 실습 코드 실행")
        print("- 각 거리 척도의 수식과 의미 암기")
    
    if any(topic in ['거리계산', '유사도계산'] for topic in topic_scores.keys() 
           if topic_scores[topic]['correct'] / topic_scores[topic]['total'] < 0.8):
        print("- 거리/유사도 계산 연습 문제 추가 풀이")
        print("- 손으로 직접 계산해보며 공식 익히기")
    
    if any(topic in ['적용사례', '척도선택'] for topic in topic_scores.keys()
           if topic_scores[topic]['correct'] / topic_scores[topic]['total'] < 0.8):
        print("- 실제 데이터셋으로 다양한 척도 비교 실험")
        print("- 도메인별 최적 척도 선택 사례 연구")
    
    print(f"\n다음 학습 주제: 다변량 회귀 (04_multivariate_regression)")
    print("=" * 60)

if __name__ == "__main__":
    main()