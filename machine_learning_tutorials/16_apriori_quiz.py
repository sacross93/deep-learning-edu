"""
Apriori 연관 규칙 마이닝 퀴즈

이 퀴즈는 Apriori 알고리즘의 핵심 개념, 연관 규칙 평가 지표,
그리고 실제 비즈니스 적용에 대한 이해도를 평가합니다.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.quiz_utils import QuizManager
import numpy as np
import matplotlib.pyplot as plt

def create_apriori_quiz():
    """Apriori 연관 규칙 마이닝 퀴즈 생성"""
    
    quiz_manager = QuizManager("Apriori 연관 규칙 마이닝")
    
    # 문제 1: 기본 개념 이해
    quiz_manager.add_question(
        question="연관 규칙 마이닝에서 '지지도(Support)'의 정의로 올바른 것은?",
        options=[
            "규칙이 얼마나 자주 맞는지를 나타내는 지표",
            "전체 트랜잭션 중 특정 항목집합이 나타나는 비율",
            "두 항목 간의 상관관계 강도",
            "규칙의 예외가 얼마나 드문지를 나타내는 지표"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (전체 트랜잭션 중 특정 항목집합이 나타나는 비율)

해설:
연관 규칙 마이닝의 핵심 지표들:

**지지도 (Support):**
- Support(X) = |X가 포함된 트랜잭션 수| / |전체 트랜잭션 수|
- 특정 항목집합이 얼마나 자주 나타나는지 측정
- 0과 1 사이의 값 (또는 백분율로 표현)

**다른 지표들:**
- **신뢰도**: 조건부 확률 P(Y|X)
- **리프트**: 독립성 대비 연관성 강도
- **확신도**: 규칙 예외의 희소성

**예시:**
1000개 트랜잭션 중 {우유, 빵}이 200번 나타나면
Support({우유, 빵}) = 200/1000 = 0.2 (20%)

지지도는 패턴의 빈도를 나타내는 가장 기본적인 지표입니다.
        """
    )
    
    # 문제 2: 신뢰도 계산
    quiz_manager.add_question(
        question="""다음 트랜잭션 데이터에서 규칙 {우유} → {빵}의 신뢰도는?

트랜잭션:
T1: {우유, 빵, 버터}
T2: {우유, 치즈}  
T3: {빵, 잼}
T4: {우유, 빵}
T5: {우유, 빵, 치즈}""",
        options=[
            "0.4 (40%)",
            "0.6 (60%)",
            "0.75 (75%)",
            "0.8 (80%)"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (0.75, 75%)

해설:
신뢰도 계산 과정:

**1단계: 각 항목집합의 지지도 계산**
- {우유}가 포함된 트랜잭션: T1, T2, T4, T5 → 4개
- {우유, 빵}이 포함된 트랜잭션: T1, T4, T5 → 3개
- 전체 트랜잭션: 5개

**2단계: 지지도 계산**
- Support({우유}) = 4/5 = 0.8
- Support({우유, 빵}) = 3/5 = 0.6

**3단계: 신뢰도 계산**
- Confidence({우유} → {빵}) = Support({우유, 빵}) / Support({우유})
- = 0.6 / 0.8 = 0.75 (75%)

**해석:**
우유를 구매한 고객의 75%가 빵도 함께 구매합니다.
        """
    )
    
    # 문제 3: Apriori 원리
    quiz_manager.add_question(
        question="Apriori 원리에 대한 설명으로 옳은 것은?",
        options=[
            "빈발한 항목집합의 모든 부분집합도 빈발하다",
            "빈발하지 않은 항목집합의 모든 상위집합도 빈발하지 않다",
            "항목집합의 크기가 클수록 지지도가 높다",
            "모든 항목집합은 동일한 지지도를 가진다"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (빈발하지 않은 항목집합의 모든 상위집합도 빈발하지 않다)

해설:
Apriori 원리의 핵심 개념:

**Apriori 원리 (Downward Closure Property):**
- 만약 항목집합 X가 빈발하지 않다면, X를 포함하는 모든 상위집합도 빈발하지 않다
- 수학적 표현: Support(X) < min_support ⟹ Support(X ∪ Y) < min_support

**논리적 근거:**
- 상위집합이 나타나려면 모든 부분집합이 함께 나타나야 함
- 부분집합이 드물면 상위집합은 더 드물 수밖에 없음

**알고리즘 효율성:**
- 빈발하지 않은 항목집합의 확장을 조기에 중단
- 후보 생성 시 불필요한 계산 제거
- 지수적 탐색 공간을 크게 축소

**예시:**
{A}가 빈발하지 않으면 {A,B}, {A,C}, {A,B,C} 등도 모두 빈발하지 않음
        """
    )
    
    # 문제 4: 리프트 해석
    quiz_manager.add_question(
        question="연관 규칙의 리프트(Lift) 값이 2.5라면, 이는 무엇을 의미합니까?",
        options=[
            "규칙의 신뢰도가 250%이다",
            "후행부가 선행부보다 2.5배 더 자주 나타난다",
            "선행부가 있을 때 후행부가 나타날 확률이 독립적일 때보다 2.5배 높다",
            "규칙이 2.5번 중 1번 틀린다"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (선행부가 있을 때 후행부가 나타날 확률이 독립적일 때보다 2.5배 높다)

해설:
리프트(Lift)의 의미와 해석:

**리프트 공식:**
Lift(X → Y) = Confidence(X → Y) / Support(Y)
            = P(Y|X) / P(Y)

**리프트 해석:**
- **Lift = 1**: X와 Y는 독립적 (연관성 없음)
- **Lift > 1**: 양의 연관성 (함께 나타날 가능성 높음)
- **Lift < 1**: 음의 연관성 (함께 나타날 가능성 낮음)

**Lift = 2.5의 의미:**
- X가 주어졌을 때 Y가 나타날 확률이 Y의 전체 확률보다 2.5배 높음
- 강한 양의 연관성을 의미
- 실용적으로 매우 유용한 규칙

**비즈니스 해석:**
고객이 X를 구매할 때 Y도 구매할 가능성이 평소보다 2.5배 높아짐
→ 효과적인 추천이나 교차 판매 기회
        """
    )
    
    # 문제 5: 후보 생성 과정
    quiz_manager.add_question(
        question="Apriori 알고리즘에서 빈발 2-항목집합 {A,B}, {A,C}, {B,C}가 주어졌을 때, 생성되는 3-항목집합 후보는?",
        options=[
            "{A,B,C}만 생성됨",
            "{A,B,C}, {A,B,D}, {A,C,D} 생성됨",
            "후보가 생성되지 않음",
            "{A,B}, {A,C}, {B,C}의 모든 조합"
        ],
        correct_answer=0,
        explanation="""
정답: 1번 ({A,B,C}만 생성됨)

해설:
Apriori 후보 생성 과정:

**후보 생성 규칙:**
1. 두 (k-1)-항목집합을 결합하여 k-항목집합 후보 생성
2. 결합 조건: 첫 (k-2)개 항목이 동일해야 함
3. 생성된 후보의 모든 (k-1) 부분집합이 빈발해야 함

**3-항목집합 후보 생성:**
- {A,B}와 {A,C} 결합 → {A,B,C}
- {A,B}와 {B,C} 결합 → {A,B,C}  
- {A,C}와 {B,C} 결합 → {A,B,C}

**부분집합 검증:**
{A,B,C}의 2-부분집합: {A,B}, {A,C}, {B,C}
→ 모두 빈발 2-항목집합이므로 유효한 후보

**결과:**
{A,B,C}만이 유일한 3-항목집합 후보로 생성됨

이 과정이 Apriori의 효율성을 보장하는 핵심 메커니즘입니다.
        """
    )
    
    # 문제 6: 확신도 개념
    quiz_manager.add_question(
        question="확신도(Conviction)가 무한대(∞)인 연관 규칙의 특징은?",
        options=[
            "규칙이 전혀 의미가 없다",
            "선행부와 후행부가 독립적이다",
            "규칙에 예외가 전혀 없다 (완벽한 규칙)",
            "후행부의 지지도가 0이다"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (규칙에 예외가 전혀 없다)

해설:
확신도(Conviction)의 개념과 해석:

**확신도 공식:**
Conviction(X → Y) = (1 - Support(Y)) / (1 - Confidence(X → Y))

**확신도 해석:**
- **Conviction = 1**: X와 Y는 독립적
- **Conviction > 1**: 규칙이 의미 있음
- **Conviction = ∞**: 완벽한 규칙 (예외 없음)

**무한대가 되는 조건:**
- Confidence(X → Y) = 1 (100% 신뢰도)
- 즉, X가 나타나면 Y가 항상 함께 나타남
- 분모가 0이 되어 확신도가 무한대

**실제 의미:**
- X를 구매한 모든 고객이 예외 없이 Y도 구매
- 매우 강력하고 신뢰할 수 있는 규칙
- 비즈니스에서 확실한 패턴으로 활용 가능

**예시:**
"스마트폰을 구매하면 100% 충전기도 구매" → Conviction = ∞
        """
    )
    
    # 문제 7: 최소 지지도 영향
    quiz_manager.add_question(
        question="Apriori 알고리즘에서 최소 지지도를 낮추면 어떤 일이 발생합니까?",
        options=[
            "더 적은 수의 빈발 항목집합이 발견된다",
            "알고리즘 실행 시간이 단축된다",
            "더 많은 빈발 항목집합과 연관 규칙이 발견되지만 계산 시간이 증가한다",
            "연관 규칙의 품질이 향상된다"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (더 많은 빈발 항목집합과 연관 규칙이 발견되지만 계산 시간이 증가한다)

해설:
최소 지지도 임계값의 영향:

**최소 지지도를 낮출 때:**
- **빈발 항목집합 증가**: 더 많은 패턴이 빈발 기준을 만족
- **연관 규칙 증가**: 더 많은 규칙 생성 가능
- **계산 시간 증가**: 더 많은 후보 생성 및 검증 필요
- **메모리 사용량 증가**: 더 많은 후보 저장 필요

**최소 지지도를 높일 때:**
- **빈발 항목집합 감소**: 엄격한 기준으로 적은 패턴만 선택
- **계산 효율성 향상**: 빠른 실행 시간
- **중요 패턴 놓칠 위험**: 의미 있는 희소 패턴 제외

**적절한 임계값 선택:**
- 도메인 특성 고려
- 계산 자원과 품질의 트레이드오프
- 일반적으로 0.01-0.1 범위에서 시작

**실무 권장사항:**
여러 임계값으로 실험하여 최적값 찾기
        """
    )
    
    # 문제 8: 알고리즘 복잡도
    quiz_manager.add_question(
        question="Apriori 알고리즘의 주요 성능 병목점은?",
        options=[
            "메모리 부족",
            "후보 항목집합 생성과 지지도 계산을 위한 다중 데이터베이스 스캔",
            "연관 규칙 생성 과정",
            "결과 정렬 과정"
        ],
        correct_answer=1,
        explanation="""
정답: 2번 (후보 항목집합 생성과 지지도 계산을 위한 다중 데이터베이스 스캔)

해설:
Apriori 알고리즘의 성능 이슈:

**주요 병목점:**
1. **다중 데이터베이스 스캔**: 각 k-항목집합마다 전체 DB 스캔
2. **대량의 후보 생성**: 조합 폭발로 인한 후보 급증
3. **지지도 계산 비용**: 각 후보마다 전체 트랜잭션 검사

**성능 문제의 원인:**
- **I/O 비용**: 반복적인 디스크 접근
- **메모리 사용**: 대량의 후보 항목집합 저장
- **계산 복잡도**: 최악의 경우 O(2^n)

**개선 방법:**
- **FP-Growth**: 트리 구조로 압축, 단일 스캔
- **해시 기법**: 후보 수 조기 축소
- **트랜잭션 축소**: 불필요한 항목 제거
- **병렬 처리**: 분산 컴퓨팅 활용

**실제 영향:**
대용량 데이터에서는 FP-Growth 등 대안 알고리즘 선호
        """
    )
    
    # 문제 9: 실제 적용 시나리오
    quiz_manager.add_question(
        question="다음 중 연관 규칙 마이닝이 가장 효과적으로 활용될 수 있는 분야는?",
        options=[
            "이미지 분류",
            "시계열 예측",
            "온라인 쇼핑몰의 상품 추천 시스템",
            "자연어 번역"
        ],
        correct_answer=2,
        explanation="""
정답: 3번 (온라인 쇼핑몰의 상품 추천 시스템)

해설:
연관 규칙 마이닝의 최적 적용 분야:

**쇼핑몰 추천 시스템:**
- **자연스러운 트랜잭션 구조**: 구매 기록이 트랜잭션
- **명확한 비즈니스 가치**: 교차 판매, 매출 증대
- **실시간 적용 가능**: "이 상품을 구매한 고객들이 함께 구매한 상품"
- **해석 가능성**: 추천 이유를 고객에게 설명 가능

**다른 효과적인 적용 분야:**
- **소매업**: 매장 레이아웃, 상품 배치
- **웹 분석**: 페이지 방문 패턴, 사이트 구조 개선
- **의료**: 증상-질병 연관성, 약물 상호작용
- **금융**: 사기 패턴 탐지, 상품 번들링

**부적합한 분야:**
- **이미지 분류**: 픽셀 간 공간적 관계가 중요
- **시계열 예측**: 시간적 순서와 연속성이 핵심
- **자연어 번역**: 문법과 의미 구조가 중요

연관 규칙은 이산적 항목 간의 공출현 패턴에 최적화되어 있습니다.
        """
    )
    
    # 문제 10: 비즈니스 인사이트
    quiz_manager.add_question(
        question="""다음 연관 규칙 중 마케팅 전략 수립에 가장 유용한 것은?

규칙 A: {기저귀} → {맥주} (지지도: 0.02, 신뢰도: 0.6, 리프트: 3.2)
규칙 B: {우유} → {빵} (지지도: 0.15, 신뢰도: 0.7, 리프트: 1.1)
규칙 C: {노트북} → {마우스} (지지도: 0.08, 신뢰도: 0.9, 리프트: 2.8)""",
        options=[
            "규칙 A - 가장 높은 리프트 값",
            "규칙 B - 가장 높은 지지도 값",
            "규칙 C - 가장 높은 신뢰도 값",
            "규칙 A와 C 모두 - 높은 리프트와 실용적 신뢰도"
        ],
        correct_answer=3,
        explanation="""
정답: 4번 (규칙 A와 C 모두 - 높은 리프트와 실용적 신뢰도)

해설:
연관 규칙의 비즈니스 가치 평가:

**각 규칙 분석:**

**규칙 A: {기저귀} → {맥주}**
- 리프트 3.2: 매우 강한 연관성
- 신뢰도 0.6: 실용적 수준
- 지지도 0.02: 낮지만 틈새 시장 가능성

**규칙 B: {우유} → {빵}**
- 리프트 1.1: 약한 연관성 (거의 독립적)
- 높은 지지도: 일반적 패턴이지만 특별한 인사이트 부족

**규칙 C: {노트북} → {마우스}**
- 리프트 2.8: 강한 연관성
- 신뢰도 0.9: 매우 높은 예측력
- 명확한 비즈니스 로직 (보완재 관계)

**마케팅 전략 관점:**
- **높은 리프트**: 의외의 연관성 발견, 새로운 기회
- **높은 신뢰도**: 확실한 추천 가능
- **적절한 지지도**: 실행 가능한 규모

**결론:**
규칙 A와 C는 모두 강한 연관성(리프트)과 실용적 신뢰도를 가져 
효과적인 마케팅 전략 수립에 활용 가능합니다.
        """
    )
    
    return quiz_manager

def main():
    """퀴즈 실행 메인 함수"""
    print("="*60)
    print("Apriori 연관 규칙 마이닝 퀴즈")
    print("="*60)
    print()
    print("이 퀴즈는 Apriori 알고리즘의 핵심 개념들을 다룹니다:")
    print("• 기본 개념 (지지도, 신뢰도, 리프트)")
    print("• Apriori 원리와 알고리즘 과정")
    print("• 연관 규칙 평가 지표")
    print("• 성능 최적화 방법")
    print("• 실제 비즈니스 적용")
    print("• 결과 해석 및 인사이트 도출")
    print()
    
    # 퀴즈 생성 및 실행
    quiz_manager = create_apriori_quiz()
    results = quiz_manager.run_quiz()
    
    # 결과 출력
    print("\n" + "="*60)
    print("퀴즈 결과 분석")
    print("="*60)
    
    score = results['score']
    total = results['total']
    percentage = results['percentage']
    
    print(f"총 점수: {score}/{total} ({percentage:.1f}%)")
    
    if percentage >= 90:
        print("🏆 훌륭합니다! Apriori 알고리즘을 완벽하게 이해하고 있습니다.")
    elif percentage >= 80:
        print("👍 잘했습니다! 연관 규칙 마이닝의 핵심 개념을 잘 파악하고 있습니다.")
    elif percentage >= 70:
        print("👌 괜찮습니다! 몇 가지 개념을 더 복습해보세요.")
    elif percentage >= 60:
        print("📚 더 공부가 필요합니다. 이론 문서를 다시 읽어보세요.")
    else:
        print("💪 포기하지 마세요! 기초부터 차근차근 다시 학습해보세요.")
    
    # 틀린 문제 분석
    wrong_questions = results['wrong_questions']
    if wrong_questions:
        print(f"\n틀린 문제: {len(wrong_questions)}개")
        print("다음 주제들을 더 공부해보세요:")
        
        topics = {
            1: "지지도 기본 개념",
            2: "신뢰도 계산 방법",
            3: "Apriori 원리",
            4: "리프트 해석",
            5: "후보 생성 과정",
            6: "확신도 개념",
            7: "파라미터 영향 분석",
            8: "알고리즘 성능 이슈",
            9: "실제 적용 분야",
            10: "비즈니스 인사이트 도출"
        }
        
        for q_num in wrong_questions:
            print(f"  • {topics.get(q_num, f'문제 {q_num}')}")
    
    print("\n" + "="*60)
    print("학습 권장사항")
    print("="*60)
    
    if percentage < 70:
        print("📖 16_apriori_theory.md 문서를 다시 읽어보세요.")
        print("💻 16_apriori_practice.py 실습을 다시 실행해보세요.")
    
    print("🔍 추가 학습 주제:")
    print("  • FP-Growth와 다른 연관 규칙 마이닝 알고리즘")
    print("  • 대용량 데이터를 위한 분산 처리 방법")
    print("  • 순차 패턴 마이닝과의 차이점")
    print("  • 실시간 추천 시스템 구현 방법")
    
    return results

if __name__ == "__main__":
    main()