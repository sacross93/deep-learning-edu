"""
ë”¥ëŸ¬ë‹ ê°•ì˜ ì‹œë¦¬ì¦ˆ 6: YOLO ê°ì²´ íƒì§€

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” COCO ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ 
YOLO(You Only Look Once) ì•Œê³ ë¦¬ì¦˜ì˜ ê°ì²´ íƒì§€ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
1. ê°ì²´ íƒì§€ ë¬¸ì œì˜ íŠ¹ì„±ê³¼ ë„ì „ê³¼ì œ ì´í•´
2. YOLO ì•Œê³ ë¦¬ì¦˜ì˜ ì›ë¦¬ì™€ êµ¬ì¡°
3. ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì ìˆ˜ ì²˜ë¦¬
4. Non-Maximum Suppression (NMS) ì•Œê³ ë¦¬ì¦˜
5. ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ êµ¬í˜„
6. ê°ì²´ íƒì§€ ì„±ëŠ¥ í‰ê°€ (mAP, IoU)

ë°ì´í„°ì…‹ ì„ íƒ ì´ìœ  - COCO (Common Objects in Context):
- 80ê°œ í´ë˜ìŠ¤ì˜ ì¼ìƒì ì¸ ê°ì²´ë“¤
- 330,000ê°œ ì´ë¯¸ì§€, 1.5M ê°ì²´ ì¸ìŠ¤í„´ìŠ¤
- ê°ì²´ íƒì§€ì˜ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹
- ë‹¤ì–‘í•œ í¬ê¸°ì™€ í˜•íƒœì˜ ê°ì²´ í¬í•¨
- ë³µì¡í•œ ë°°ê²½ê³¼ ê²¹ì¹˜ëŠ” ê°ì²´ë“¤
- ì‹¤ì œ í™˜ê²½ê³¼ ìœ ì‚¬í•œ ë‹¤ì–‘í•œ ìƒí™©
- ì •í™•í•œ ë°”ìš´ë”© ë°•ìŠ¤ ì–´ë…¸í…Œì´ì…˜

ì™œ YOLOë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?
1. ì‹¤ì‹œê°„ ì²˜ë¦¬: ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ íŒ¨ìŠ¤ë¡œ ë¹ ë¥¸ ì¶”ë¡ 
2. ì „ì—­ì  ì¶”ë¡ : ì „ì²´ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
3. ì¼ë°˜í™” ëŠ¥ë ¥: ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥
4. ë‹¨ìˆœí•œ êµ¬ì¡°: ì´í•´í•˜ê¸° ì‰¬ìš´ end-to-end í•™ìŠµ
5. ì‹¤ìš©ì„±: ì‹¤ì œ ì‘ìš©ì—ì„œ ë„ë¦¬ ì‚¬ìš©

ì „í†µì  ê°ì²´ íƒì§€ vs YOLO:
- R-CNN ê³„ì—´: 2ë‹¨ê³„ (region proposal + classification)
- YOLO: 1ë‹¨ê³„ (ì§ì ‘ ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ ì˜ˆì¸¡)
- ì†ë„: YOLOê°€ í›¨ì”¬ ë¹ ë¦„ (ì‹¤ì‹œê°„ ê°€ëŠ¥)
- ì •í™•ë„: R-CNNì´ ì•½ê°„ ë†’ì§€ë§Œ YOLOë„ ì¶©ë¶„íˆ ì‹¤ìš©ì 
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import CocoDetection
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image, ImageDraw, ImageFont
import json
import os
from tqdm import tqdm
import time
import copy
import warnings
warnings.filterwarnings('ignore')

# ìš°ë¦¬ê°€ ë§Œë“  ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from utils.visualization import plot_training_curves
from utils.model_utils import count_parameters, save_checkpoint

print("ğŸš€ ë”¥ëŸ¬ë‹ ê°•ì˜ ì‹œë¦¬ì¦ˆ 6: YOLO ê°ì²´ íƒì§€")
print("=" * 60)

# ============================================================================
# 1. í™˜ê²½ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ============================================================================

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸  ì‚¬ìš© ì¥ì¹˜: {device}")

# YOLOë¥¼ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 16        # ê°ì²´ íƒì§€ëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©
LEARNING_RATE = 0.001  # ì•ˆì •ì ì¸ í•™ìŠµì„ ìœ„í•œ ë³´ìˆ˜ì  í•™ìŠµë¥ 
EPOCHS = 50            # ê°ì²´ íƒì§€ëŠ” ì¶©ë¶„í•œ í•™ìŠµ ì‹œê°„ í•„ìš”
RANDOM_SEED = 42
IMG_SIZE = 416         # YOLO í‘œì¤€ ì…ë ¥ í¬ê¸° (32ì˜ ë°°ìˆ˜)
GRID_SIZE = 13         # 416 / 32 = 13
NUM_CLASSES = 20       # ê°„ì†Œí™”ëœ í´ë˜ìŠ¤ ìˆ˜ (PASCAL VOC ê¸°ì¤€)
NUM_BOXES = 2          # ê° ê·¸ë¦¬ë“œ ì…€ë‹¹ ì˜ˆì¸¡í•  ë°”ìš´ë”© ë°•ìŠ¤ ìˆ˜
CONFIDENCE_THRESHOLD = 0.5  # ê°ì²´ ì‹ ë¢°ë„ ì„ê³„ê°’
NMS_THRESHOLD = 0.4    # Non-Maximum Suppression ì„ê³„ê°’

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

print(f"ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
print(f"   ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
print(f"   í•™ìŠµë¥ : {LEARNING_RATE}")
print(f"   ì—í¬í¬: {EPOCHS}")
print(f"   ì´ë¯¸ì§€ í¬ê¸°: {IMG_SIZE}x{IMG_SIZE}")
print(f"   ê·¸ë¦¬ë“œ í¬ê¸°: {GRID_SIZE}x{GRID_SIZE}")
print(f"   í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}")
print(f"   ë°•ìŠ¤ ìˆ˜: {NUM_BOXES}")

# PASCAL VOC í´ë˜ìŠ¤ ì´ë¦„ (ê°„ì†Œí™”)
CLASS_NAMES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
    'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person',
    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

# ============================================================================
# 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

print(f"\nğŸ“ ê°ì²´ íƒì§€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜")

def calculate_iou(box1, box2):
    """
    IoU (Intersection over Union) ê³„ì‚°
    
    Args:
        box1, box2: [x1, y1, x2, y2] í˜•íƒœì˜ ë°”ìš´ë”© ë°•ìŠ¤
    
    Returns:
        float: IoU ê°’ (0~1)
    
    IoUëŠ” ê°ì²´ íƒì§€ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í‰ê°€ ë©”íŠ¸ë¦­:
    - ì˜ˆì¸¡ ë°•ìŠ¤ì™€ ì‹¤ì œ ë°•ìŠ¤ì˜ ê²¹ì¹˜ëŠ” ì •ë„ ì¸¡ì •
    - 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•í•œ ì˜ˆì¸¡
    - NMSì™€ mAP ê³„ì‚°ì— í•µì‹¬ì ìœ¼ë¡œ ì‚¬ìš©
    """
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    # êµì§‘í•©ì´ ì—†ëŠ” ê²½ìš°
    if x2 <= x1 or y2 <= y1:
        return 0.0
    
    intersection = (x2 - x1) * (y2 - y1)
    
    # ê° ë°•ìŠ¤ì˜ ë©´ì 
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # í•©ì§‘í•© ë©´ì 
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0.0

def non_max_suppression(boxes, scores, threshold=0.4):
    """
    Non-Maximum Suppression (NMS) êµ¬í˜„
    
    Args:
        boxes: ë°”ìš´ë”© ë°•ìŠ¤ë“¤ [[x1, y1, x2, y2], ...]
        scores: ê° ë°•ìŠ¤ì˜ ì‹ ë¢°ë„ ì ìˆ˜
        threshold: IoU ì„ê³„ê°’
    
    Returns:
        list: ì„ íƒëœ ë°•ìŠ¤ë“¤ì˜ ì¸ë±ìŠ¤
    
    NMSì˜ ëª©ì :
    - ê°™ì€ ê°ì²´ì— ëŒ€í•œ ì¤‘ë³µ íƒì§€ ì œê±°
    - ê°€ì¥ ì‹ ë¢°ë„ê°€ ë†’ì€ ë°•ìŠ¤ë§Œ ì„ íƒ
    - ê¹”ë”í•œ ìµœì¢… ê²°ê³¼ ìƒì„±
    
    ì•Œê³ ë¦¬ì¦˜:
    1. ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    2. ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë°•ìŠ¤ ì„ íƒ
    3. ì„ íƒëœ ë°•ìŠ¤ì™€ IoUê°€ ë†’ì€ ë°•ìŠ¤ë“¤ ì œê±°
    4. ë°˜ë³µ
    """
    if len(boxes) == 0:
        return []
    
    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)
    
    selected = []
    
    while indices:
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë°•ìŠ¤ ì„ íƒ
        current = indices.pop(0)
        selected.append(current)
        
        # ë‚˜ë¨¸ì§€ ë°•ìŠ¤ë“¤ê³¼ IoU ê³„ì‚°
        remaining = []
        for idx in indices:
            iou = calculate_iou(boxes[current], boxes[idx])
            if iou <= threshold:  # IoUê°€ ì„ê³„ê°’ ì´í•˜ì¸ ê²½ìš°ë§Œ ìœ ì§€
                remaining.append(idx)
        
        indices = remaining
    
    return selected

def convert_to_corners(center_x, center_y, width, height):
    """ì¤‘ì‹¬ì  + í¬ê¸° â†’ ëª¨ì„œë¦¬ ì¢Œí‘œ ë³€í™˜"""
    x1 = center_x - width / 2
    y1 = center_y - height / 2
    x2 = center_x + width / 2
    y2 = center_y + height / 2
    return [x1, y1, x2, y2]

def convert_to_center(x1, y1, x2, y2):
    """ëª¨ì„œë¦¬ ì¢Œí‘œ â†’ ì¤‘ì‹¬ì  + í¬ê¸° ë³€í™˜"""
    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    width = x2 - x1
    height = y2 - y1
    return center_x, center_y, width, height

# ============================================================================
# 3. ê°„ì†Œí™”ëœ YOLO ëª¨ë¸ ì •ì˜
# ============================================================================

print(f"\nğŸ§  YOLO ëª¨ë¸ ì •ì˜")

class SimpleYOLO(nn.Module):
    """
    ê°„ì†Œí™”ëœ YOLO ëª¨ë¸
    
    êµ¬ì¡°:
    1. ë°±ë³¸ ë„¤íŠ¸ì›Œí¬: íŠ¹ì„± ì¶”ì¶œ (CNN)
    2. íƒì§€ í—¤ë“œ: ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ ì˜ˆì¸¡
    
    YOLOì˜ í•µì‹¬ ì•„ì´ë””ì–´:
    - ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ ë¶„í• 
    - ê° ê·¸ë¦¬ë“œ ì…€ì´ ê°ì²´ì˜ ì¤‘ì‹¬ì„ í¬í•¨í•˜ë©´ í•´ë‹¹ ê°ì²´ ì˜ˆì¸¡
    - ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ + ì‹ ë¢°ë„ + í´ë˜ìŠ¤ í™•ë¥ ì„ ë™ì‹œì— ì˜ˆì¸¡
    
    ì¶œë ¥ í˜•íƒœ:
    - (batch_size, grid_size, grid_size, num_boxes * 5 + num_classes)
    - 5 = (x, y, w, h, confidence)
    """
    
    def __init__(self, grid_size=13, num_boxes=2, num_classes=20):
        super(SimpleYOLO, self).__init__()
        
        self.grid_size = grid_size
        self.num_boxes = num_boxes
        self.num_classes = num_classes
        
        # ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ (íŠ¹ì„± ì¶”ì¶œ)
        # ì‹¤ì œ YOLOëŠ” Darknetì„ ì‚¬ìš©í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ì†Œí™”ëœ CNN ì‚¬ìš©
        self.backbone = nn.Sequential(
            # ì²« ë²ˆì§¸ ë¸”ë¡: 416 â†’ 208
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),  # 208x208
            
            # ë‘ ë²ˆì§¸ ë¸”ë¡: 208 â†’ 104
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),  # 104x104
            
            # ì„¸ ë²ˆì§¸ ë¸”ë¡: 104 â†’ 52
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.1),
            nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.1),
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),  # 52x52
            
            # ë„¤ ë²ˆì§¸ ë¸”ë¡: 52 â†’ 26
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1),
            nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.1),
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),  # 26x26
            
            # ë‹¤ì„¯ ë²ˆì§¸ ë¸”ë¡: 26 â†’ 13
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.1),
            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1),
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.1),
            nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1),
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),  # 13x13
        )
        
        # íƒì§€ í—¤ë“œ
        # ì¶œë ¥ ì±„ë„ ìˆ˜ = num_boxes * (5 + num_classes)
        # 5 = x, y, w, h, confidence
        output_channels = num_boxes * (5 + num_classes)
        
        self.detection_head = nn.Sequential(
            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.1),
            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.1),
            nn.Conv2d(1024, output_channels, kernel_size=1, stride=1, padding=0)
        )
        
    def forward(self, x):
        # ë°±ë³¸ì„ í†µí•œ íŠ¹ì„± ì¶”ì¶œ
        features = self.backbone(x)
        
        # íƒì§€ í—¤ë“œë¥¼ í†µí•œ ì˜ˆì¸¡
        predictions = self.detection_head(features)
        
        # ì¶œë ¥ í˜•íƒœ ë³€ê²½: (batch, channels, height, width) â†’ (batch, height, width, channels)
        predictions = predictions.permute(0, 2, 3, 1)
        
        return predictions

class YOLOLoss(nn.Module):
    """
    YOLO ì†ì‹¤ í•¨ìˆ˜
    
    YOLO ì†ì‹¤ì€ ì—¬ëŸ¬ êµ¬ì„±ìš”ì†Œë¡œ ì´ë£¨ì–´ì§:
    1. ì¢Œí‘œ ì†ì‹¤: ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ ì˜¤ì°¨
    2. í¬ê¸° ì†ì‹¤: ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ì˜¤ì°¨
    3. ì‹ ë¢°ë„ ì†ì‹¤: ê°ì²´ ì¡´ì¬ ì—¬ë¶€ ì˜¤ì°¨
    4. í´ë˜ìŠ¤ ì†ì‹¤: í´ë˜ìŠ¤ ë¶„ë¥˜ ì˜¤ì°¨
    
    ê° ì†ì‹¤ì— ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ ê· í˜• ì¡°ì •
    """
    
    def __init__(self, grid_size=13, num_boxes=2, num_classes=20, 
                 lambda_coord=5.0, lambda_noobj=0.5):
        super(YOLOLoss, self).__init__()
        
        self.grid_size = grid_size
        self.num_boxes = num_boxes
        self.num_classes = num_classes
        self.lambda_coord = lambda_coord  # ì¢Œí‘œ ì†ì‹¤ ê°€ì¤‘ì¹˜
        self.lambda_noobj = lambda_noobj  # ê°ì²´ ì—†ìŒ ì†ì‹¤ ê°€ì¤‘ì¹˜
        
    def forward(self, predictions, targets):
        """
        Args:
            predictions: (batch_size, grid_size, grid_size, num_boxes * 5 + num_classes)
            targets: (batch_size, grid_size, grid_size, num_boxes * 5 + num_classes)
        """
        batch_size = predictions.size(0)
        
        # ì˜ˆì¸¡ê°’ ë¶„ë¦¬
        pred_boxes = predictions[..., :self.num_boxes * 5].view(
            batch_size, self.grid_size, self.grid_size, self.num_boxes, 5
        )
        pred_classes = predictions[..., self.num_boxes * 5:]
        
        # íƒ€ê²Ÿê°’ ë¶„ë¦¬
        target_boxes = targets[..., :self.num_boxes * 5].view(
            batch_size, self.grid_size, self.grid_size, self.num_boxes, 5
        )
        target_classes = targets[..., self.num_boxes * 5:]
        
        # ê°ì²´ê°€ ìˆëŠ” ì…€ ë§ˆìŠ¤í¬
        obj_mask = target_boxes[..., 4] > 0  # confidence > 0
        noobj_mask = target_boxes[..., 4] == 0
        
        # 1. ì¢Œí‘œ ì†ì‹¤ (ê°ì²´ê°€ ìˆëŠ” ê²½ìš°ë§Œ)
        coord_loss = 0
        if obj_mask.sum() > 0:
            pred_xy = pred_boxes[obj_mask][..., :2]
            target_xy = target_boxes[obj_mask][..., :2]
            coord_loss += F.mse_loss(pred_xy, target_xy, reduction='sum')
            
            # í¬ê¸° ì†ì‹¤ (ì œê³±ê·¼ ì ìš©ìœ¼ë¡œ í° ë°•ìŠ¤ì™€ ì‘ì€ ë°•ìŠ¤ ê· í˜•)
            pred_wh = torch.sqrt(torch.abs(pred_boxes[obj_mask][..., 2:4]) + 1e-6)
            target_wh = torch.sqrt(target_boxes[obj_mask][..., 2:4] + 1e-6)
            coord_loss += F.mse_loss(pred_wh, target_wh, reduction='sum')
        
        # 2. ì‹ ë¢°ë„ ì†ì‹¤
        # ê°ì²´ê°€ ìˆëŠ” ê²½ìš°
        obj_conf_loss = 0
        if obj_mask.sum() > 0:
            pred_conf_obj = pred_boxes[obj_mask][..., 4]
            target_conf_obj = target_boxes[obj_mask][..., 4]
            obj_conf_loss = F.mse_loss(pred_conf_obj, target_conf_obj, reduction='sum')
        
        # ê°ì²´ê°€ ì—†ëŠ” ê²½ìš°
        noobj_conf_loss = 0
        if noobj_mask.sum() > 0:
            pred_conf_noobj = pred_boxes[noobj_mask][..., 4]
            target_conf_noobj = target_boxes[noobj_mask][..., 4]
            noobj_conf_loss = F.mse_loss(pred_conf_noobj, target_conf_noobj, reduction='sum')
        
        # 3. í´ë˜ìŠ¤ ì†ì‹¤ (ê°ì²´ê°€ ìˆëŠ” ì…€ì—ì„œë§Œ)
        class_loss = 0
        obj_class_mask = target_classes.sum(dim=-1) > 0
        if obj_class_mask.sum() > 0:
            pred_class_obj = pred_classes[obj_class_mask]
            target_class_obj = target_classes[obj_class_mask]
            class_loss = F.mse_loss(pred_class_obj, target_class_obj, reduction='sum')
        
        # ì´ ì†ì‹¤ ê³„ì‚°
        total_loss = (
            self.lambda_coord * coord_loss +
            obj_conf_loss +
            self.lambda_noobj * noobj_conf_loss +
            class_loss
        )
        
        # ë°°ì¹˜ í¬ê¸°ë¡œ ì •ê·œí™”
        total_loss = total_loss / batch_size
        
        return total_loss, {
            'coord_loss': coord_loss / batch_size if coord_loss != 0 else 0,
            'obj_conf_loss': obj_conf_loss / batch_size if obj_conf_loss != 0 else 0,
            'noobj_conf_loss': noobj_conf_loss / batch_size if noobj_conf_loss != 0 else 0,
            'class_loss': class_loss / batch_size if class_loss != 0 else 0
        }

# ============================================================================
# 4. ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„± (COCO ëŒ€ì‹ )
# ============================================================================

print(f"\nğŸ“ ìƒ˜í”Œ ê°ì²´ íƒì§€ ë°ì´í„°ì…‹ ìƒì„±")

class SampleObjectDetectionDataset(Dataset):
    """
    êµìœ¡ìš© ìƒ˜í”Œ ê°ì²´ íƒì§€ ë°ì´í„°ì…‹
    
    ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” COCOë‚˜ PASCAL VOC ì‚¬ìš©
    ì—¬ê¸°ì„œëŠ” í•™ìŠµ ëª©ì ìœ¼ë¡œ ê°„ë‹¨í•œ í•©ì„± ë°ì´í„° ìƒì„±
    """
    
    def __init__(self, num_samples=1000, img_size=416, grid_size=13, 
                 num_classes=20, transform=None):
        self.num_samples = num_samples
        self.img_size = img_size
        self.grid_size = grid_size
        self.num_classes = num_classes
        self.transform = transform
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        self.samples = self._generate_samples()
        
    def _generate_samples(self):
        """í•©ì„± ë°ì´í„° ìƒì„±"""
        print("ğŸ¨ í•©ì„± ê°ì²´ íƒì§€ ë°ì´í„° ìƒì„± ì¤‘...")
        
        samples = []
        np.random.seed(42)
        
        for i in tqdm(range(self.num_samples), desc="ë°ì´í„° ìƒì„±"):
            # ëœë¤ ì´ë¯¸ì§€ ìƒì„± (RGB)
            image = np.random.randint(0, 256, (self.img_size, self.img_size, 3), dtype=np.uint8)
            
            # ëœë¤ ê°ì²´ë“¤ ìƒì„± (1~3ê°œ)
            num_objects = np.random.randint(1, 4)
            boxes = []
            classes = []
            
            for _ in range(num_objects):
                # ëœë¤ ë°”ìš´ë”© ë°•ìŠ¤
                center_x = np.random.uniform(0.1, 0.9)
                center_y = np.random.uniform(0.1, 0.9)
                width = np.random.uniform(0.1, 0.3)
                height = np.random.uniform(0.1, 0.3)
                
                # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
                x1 = max(0, center_x - width/2)
                y1 = max(0, center_y - height/2)
                x2 = min(1, center_x + width/2)
                y2 = min(1, center_y + height/2)
                
                boxes.append([x1, y1, x2, y2])
                classes.append(np.random.randint(0, self.num_classes))
                
                # ì´ë¯¸ì§€ì— ê°„ë‹¨í•œ ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (ì‹œê°ì  í‘œì‹œ)
                x1_px = int(x1 * self.img_size)
                y1_px = int(y1 * self.img_size)
                x2_px = int(x2 * self.img_size)
                y2_px = int(y2 * self.img_size)
                
                color = np.random.randint(100, 255, 3)
                image[y1_px:y2_px, x1_px:x2_px] = color
            
            samples.append({
                'image': image,
                'boxes': boxes,
                'classes': classes
            })
        
        print(f"âœ… {len(samples)}ê°œ ìƒ˜í”Œ ìƒì„± ì™„ë£Œ")
        return samples
    
    def _create_target_tensor(self, boxes, classes):
        """YOLO í˜•ì‹ì˜ íƒ€ê²Ÿ í…ì„œ ìƒì„±"""
        target = torch.zeros(self.grid_size, self.grid_size, 2 * 5 + self.num_classes)
        
        for box, cls in zip(boxes, classes):
            x1, y1, x2, y2 = box
            center_x, center_y, width, height = convert_to_center(x1, y1, x2, y2)
            
            # ê·¸ë¦¬ë“œ ì…€ ì¢Œí‘œ
            grid_x = int(center_x * self.grid_size)
            grid_y = int(center_y * self.grid_size)
            
            # ê·¸ë¦¬ë“œ ë‚´ ìƒëŒ€ ì¢Œí‘œ
            rel_x = center_x * self.grid_size - grid_x
            rel_y = center_y * self.grid_size - grid_y
            
            # ì²« ë²ˆì§¸ ë°”ìš´ë”© ë°•ìŠ¤ì— í• ë‹¹
            target[grid_y, grid_x, 0] = rel_x
            target[grid_y, grid_x, 1] = rel_y
            target[grid_y, grid_x, 2] = width
            target[grid_y, grid_x, 3] = height
            target[grid_y, grid_x, 4] = 1.0  # confidence
            
            # í´ë˜ìŠ¤ ì›-í•« ì¸ì½”ë”©
            target[grid_y, grid_x, 10 + cls] = 1.0
        
        return target
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        image = sample['image']
        boxes = sample['boxes']
        classes = sample['classes']
        
        # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
        image = torch.FloatTensor(image).permute(2, 0, 1) / 255.0
        
        # íƒ€ê²Ÿ í…ì„œ ìƒì„±
        target = self._create_target_tensor(boxes, classes)
        
        return image, target

# ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±
print(f"\nğŸ“¦ ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±")

train_dataset = SampleObjectDetectionDataset(
    num_samples=800,
    img_size=IMG_SIZE,
    grid_size=GRID_SIZE,
    num_classes=NUM_CLASSES
)

val_dataset = SampleObjectDetectionDataset(
    num_samples=200,
    img_size=IMG_SIZE,
    grid_size=GRID_SIZE,
    num_classes=NUM_CLASSES
)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

print(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ:")
print(f"   í›ˆë ¨ ë°°ì¹˜: {len(train_loader)}")
print(f"   ê²€ì¦ ë°°ì¹˜: {len(val_loader)}")

# ============================================================================
# 5. ëª¨ë¸ ì´ˆê¸°í™” ë° í›ˆë ¨ ì„¤ì •
# ============================================================================

print(f"\nğŸ§  YOLO ëª¨ë¸ ì´ˆê¸°í™”")

# ëª¨ë¸ ìƒì„±
yolo_model = SimpleYOLO(
    grid_size=GRID_SIZE,
    num_boxes=NUM_BOXES,
    num_classes=NUM_CLASSES
).to(device)

# ì†ì‹¤ í•¨ìˆ˜
yolo_loss = YOLOLoss(
    grid_size=GRID_SIZE,
    num_boxes=NUM_BOXES,
    num_classes=NUM_CLASSES
)

# ì˜µí‹°ë§ˆì´ì €
optimizer = optim.Adam(yolo_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)

# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)

print(f"âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

# ëª¨ë¸ ë³µì¡ë„
params_info = count_parameters(yolo_model, detailed=False)
print(f"ğŸ“Š ëª¨ë¸ ë³µì¡ë„: {params_info['total_params']:,}ê°œ íŒŒë¼ë¯¸í„°")

# ============================================================================
# 6. í›ˆë ¨ í•¨ìˆ˜ ì •ì˜
# ============================================================================

def train_epoch_yolo(model, train_loader, criterion, optimizer, device):
    """YOLO í›ˆë ¨ í•¨ìˆ˜"""
    model.train()
    
    running_loss = 0.0
    running_losses = {'coord': 0, 'obj_conf': 0, 'noobj_conf': 0, 'class': 0}
    num_batches = 0
    
    pbar = tqdm(train_loader, desc="í›ˆë ¨")
    
    for batch_idx, (images, targets) in enumerate(pbar):
        images, targets = images.to(device), targets.to(device)
        
        optimizer.zero_grad()
        
        # ìˆœì „íŒŒ
        predictions = model(images)
        
        # ì†ì‹¤ ê³„ì‚°
        loss, loss_components = criterion(predictions, targets)
        
        # ì—­ì „íŒŒ
        loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
        
        optimizer.step()
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        running_loss += loss.item()
        for key, value in loss_components.items():
            if isinstance(value, torch.Tensor):
                running_losses[key.split('_')[0]] += value.item()
            else:
                running_losses[key.split('_')[0]] += value
        num_batches += 1
        
        # ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸
        if batch_idx % 10 == 0:
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Coord': f'{loss_components["coord_loss"]:.4f}',
                'Conf': f'{loss_components["obj_conf_loss"]:.4f}'
            })
    
    avg_loss = running_loss / num_batches
    avg_losses = {k: v / num_batches for k, v in running_losses.items()}
    
    return avg_loss, avg_losses

def validate_epoch_yolo(model, val_loader, criterion, device):
    """YOLO ê²€ì¦ í•¨ìˆ˜"""
    model.eval()
    
    running_loss = 0.0
    running_losses = {'coord': 0, 'obj_conf': 0, 'noobj_conf': 0, 'class': 0}
    num_batches = 0
    
    with torch.no_grad():
        pbar = tqdm(val_loader, desc="ê²€ì¦")
        
        for images, targets in pbar:
            images, targets = images.to(device), targets.to(device)
            
            predictions = model(images)
            loss, loss_components = criterion(predictions, targets)
            
            running_loss += loss.item()
            for key, value in loss_components.items():
                if isinstance(value, torch.Tensor):
                    running_losses[key.split('_')[0]] += value.item()
                else:
                    running_losses[key.split('_')[0]] += value
            num_batches += 1
            
            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})
    
    avg_loss = running_loss / num_batches
    avg_losses = {k: v / num_batches for k, v in running_losses.items()}
    
    return avg_loss, avg_losses

# ============================================================================
# 7. ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
# ============================================================================

print(f"\nğŸš€ YOLO ëª¨ë¸ í›ˆë ¨ ì‹œì‘")

# í›ˆë ¨ ê¸°ë¡
train_losses = []
val_losses = []
loss_components_history = []

# ìµœê³  ì„±ëŠ¥ ì¶”ì 
best_val_loss = float('inf')
best_model_state = None
patience = 10
patience_counter = 0

start_time = time.time()

for epoch in range(EPOCHS):
    print(f"\nğŸ“… ì—í¬í¬ {epoch+1}/{EPOCHS}")
    
    # í›ˆë ¨
    train_loss, train_loss_components = train_epoch_yolo(
        yolo_model, train_loader, yolo_loss, optimizer, device
    )
    
    # ê²€ì¦
    val_loss, val_loss_components = validate_epoch_yolo(
        yolo_model, val_loader, yolo_loss, device
    )
    
    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
    scheduler.step()
    
    # ê¸°ë¡ ì €ì¥
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    loss_components_history.append(val_loss_components)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"   í›ˆë ¨ ì†ì‹¤: {train_loss:.4f}")
    print(f"   ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")
    print(f"   ê²€ì¦ ì†ì‹¤ êµ¬ì„±:")
    print(f"     ì¢Œí‘œ: {val_loss_components['coord']:.4f}")
    print(f"     ê°ì²´ ì‹ ë¢°ë„: {val_loss_components['obj']:.4f}")
    print(f"     ë¹„ê°ì²´ ì‹ ë¢°ë„: {val_loss_components['noobj']:.4f}")
    print(f"     í´ë˜ìŠ¤: {val_loss_components['class']:.4f}")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_state = copy.deepcopy(yolo_model.state_dict())
        patience_counter = 0
        print(f"   ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        save_checkpoint(
            yolo_model, optimizer, epoch, val_loss, val_loss,
            save_path="./checkpoints/yolo_best_model.pth"
        )
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print(f"   â° ì¡°ê¸° ì¢…ë£Œ: {patience} ì—í¬í¬ ë™ì•ˆ ì„±ëŠ¥ ê°œì„  ì—†ìŒ")
            break

training_time = time.time() - start_time
print(f"\nâœ… í›ˆë ¨ ì™„ë£Œ!")
print(f"   ì´ í›ˆë ¨ ì‹œê°„: {training_time:.2f}ì´ˆ")
print(f"   ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")

# ============================================================================
# 8. í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”
# ============================================================================

print(f"\nğŸ“ˆ í›ˆë ¨ ê²°ê³¼ ì‹œê°í™”")

# í›ˆë ¨ ê³¡ì„ 
plot_training_curves(
    train_losses=train_losses,
    val_losses=val_losses,
    title="YOLO ê°ì²´ íƒì§€ - í›ˆë ¨ ê³¼ì •"
)

# ì†ì‹¤ êµ¬ì„±ìš”ì†Œ ë³€í™”
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

epochs_range = range(1, len(loss_components_history) + 1)

# ì¢Œí‘œ ì†ì‹¤
axes[0, 0].plot(epochs_range, [h['coord'] for h in loss_components_history], 'b-', linewidth=2)
axes[0, 0].set_title('ì¢Œí‘œ ì†ì‹¤')
axes[0, 0].set_xlabel('ì—í¬í¬')
axes[0, 0].set_ylabel('ì†ì‹¤')
axes[0, 0].grid(True, alpha=0.3)

# ê°ì²´ ì‹ ë¢°ë„ ì†ì‹¤
axes[0, 1].plot(epochs_range, [h['obj'] for h in loss_components_history], 'r-', linewidth=2)
axes[0, 1].set_title('ê°ì²´ ì‹ ë¢°ë„ ì†ì‹¤')
axes[0, 1].set_xlabel('ì—í¬í¬')
axes[0, 1].set_ylabel('ì†ì‹¤')
axes[0, 1].grid(True, alpha=0.3)

# ë¹„ê°ì²´ ì‹ ë¢°ë„ ì†ì‹¤
axes[1, 0].plot(epochs_range, [h['noobj'] for h in loss_components_history], 'g-', linewidth=2)
axes[1, 0].set_title('ë¹„ê°ì²´ ì‹ ë¢°ë„ ì†ì‹¤')
axes[1, 0].set_xlabel('ì—í¬í¬')
axes[1, 0].set_ylabel('ì†ì‹¤')
axes[1, 0].grid(True, alpha=0.3)

# í´ë˜ìŠ¤ ì†ì‹¤
axes[1, 1].plot(epochs_range, [h['class'] for h in loss_components_history], 'm-', linewidth=2)
axes[1, 1].set_title('í´ë˜ìŠ¤ ì†ì‹¤')
axes[1, 1].set_xlabel('ì—í¬í¬')
axes[1, 1].set_ylabel('ì†ì‹¤')
axes[1, 1].grid(True, alpha=0.3)

plt.suptitle('YOLO ì†ì‹¤ êµ¬ì„±ìš”ì†Œ ë³€í™”', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# ============================================================================
# 9. ê°ì²´ íƒì§€ ê²°ê³¼ ì‹œê°í™”
# ============================================================================

print(f"\nğŸ¯ ê°ì²´ íƒì§€ ê²°ê³¼ ì‹œê°í™”")

def decode_predictions(predictions, confidence_threshold=0.5, grid_size=13):
    """
    YOLO ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ë””ì½”ë”©
    
    Args:
        predictions: ëª¨ë¸ ì¶œë ¥ (batch_size, grid_size, grid_size, channels)
        confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        grid_size: ê·¸ë¦¬ë“œ í¬ê¸°
    
    Returns:
        list: ê° ì´ë¯¸ì§€ë³„ íƒì§€ëœ ê°ì²´ë“¤ [boxes, scores, classes]
    """
    batch_size = predictions.size(0)
    results = []
    
    for b in range(batch_size):
        pred = predictions[b]  # (grid_size, grid_size, channels)
        
        boxes = []
        scores = []
        classes = []
        
        for i in range(grid_size):
            for j in range(grid_size):
                for box_idx in range(2):  # num_boxes
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ
                    start_idx = box_idx * 5
                    rel_x = pred[i, j, start_idx]
                    rel_y = pred[i, j, start_idx + 1]
                    width = pred[i, j, start_idx + 2]
                    height = pred[i, j, start_idx + 3]
                    confidence = torch.sigmoid(pred[i, j, start_idx + 4])
                    
                    if confidence > confidence_threshold:
                        # ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                        center_x = (j + torch.sigmoid(rel_x)) / grid_size
                        center_y = (i + torch.sigmoid(rel_y)) / grid_size
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                        x1 = center_x - width / 2
                        y1 = center_y - height / 2
                        x2 = center_x + width / 2
                        y2 = center_y + height / 2
                        
                        # í´ë˜ìŠ¤ ì˜ˆì¸¡
                        class_probs = torch.softmax(pred[i, j, 10:], dim=0)
                        class_score, class_idx = torch.max(class_probs, dim=0)
                        
                        final_score = confidence * class_score
                        
                        if final_score > confidence_threshold:
                            boxes.append([x1.item(), y1.item(), x2.item(), y2.item()])
                            scores.append(final_score.item())
                            classes.append(class_idx.item())
        
        results.append((boxes, scores, classes))
    
    return results

def visualize_detections(images, predictions, confidence_threshold=0.5, nms_threshold=0.4):
    """íƒì§€ ê²°ê³¼ ì‹œê°í™”"""
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
    if best_model_state is not None:
        yolo_model.load_state_dict(best_model_state)
    
    yolo_model.eval()
    
    with torch.no_grad():
        # ì˜ˆì¸¡ ìˆ˜í–‰
        model_predictions = yolo_model(images)
        
        # ì˜ˆì¸¡ ê²°ê³¼ ë””ì½”ë”©
        results = decode_predictions(model_predictions, confidence_threshold)
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 15))
        axes = axes.flatten()
        
        for idx in range(min(4, len(images))):
            image = images[idx].cpu().permute(1, 2, 0).numpy()
            boxes, scores, classes = results[idx]
            
            # NMS ì ìš©
            if len(boxes) > 0:
                selected_indices = non_max_suppression(boxes, scores, nms_threshold)
                boxes = [boxes[i] for i in selected_indices]
                scores = [scores[i] for i in selected_indices]
                classes = [classes[i] for i in selected_indices]
            
            # ì´ë¯¸ì§€ í‘œì‹œ
            axes[idx].imshow(image)
            axes[idx].set_title(f'íƒì§€ëœ ê°ì²´: {len(boxes)}ê°œ')
            axes[idx].axis('off')
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            for box, score, cls in zip(boxes, scores, classes):
                x1, y1, x2, y2 = box
                
                # ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
                x1 *= IMG_SIZE
                y1 *= IMG_SIZE
                x2 *= IMG_SIZE
                y2 *= IMG_SIZE
                
                # ë°”ìš´ë”© ë°•ìŠ¤
                rect = patches.Rectangle(
                    (x1, y1), x2 - x1, y2 - y1,
                    linewidth=2, edgecolor='red', facecolor='none'
                )
                axes[idx].add_patch(rect)
                
                # í´ë˜ìŠ¤ ë¼ë²¨ê³¼ ì‹ ë¢°ë„ í‘œì‹œ
                if cls < len(CLASS_NAMES):
                    label = f'{CLASS_NAMES[cls]}: {score:.2f}'
                else:
                    label = f'Class {cls}: {score:.2f}'
                
                axes[idx].text(x1, y1-5, label, 
                             bbox=dict(boxstyle="round,pad=0.3", facecolor='red', alpha=0.7),
                             fontsize=8, color='white')
        
        plt.suptitle('YOLO ê°ì²´ íƒì§€ ê²°ê³¼', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()

# ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ íƒì§€ ê²°ê³¼ ì‹œê°í™”
print("ğŸ¯ ê°ì²´ íƒì§€ ê²°ê³¼ í™•ì¸")
sample_batch = next(iter(val_loader))
sample_images = sample_batch[0][:4].to(device)

visualize_detections(sample_images, None)

# ============================================================================
# 10. ì„±ëŠ¥ í‰ê°€ (mAP ê³„ì‚°)
# ============================================================================

print(f"\nğŸ“Š ê°ì²´ íƒì§€ ì„±ëŠ¥ í‰ê°€")

def calculate_map(predictions, targets, iou_threshold=0.5):
    """
    mAP (mean Average Precision) ê³„ì‚°
    
    mAPëŠ” ê°ì²´ íƒì§€ì˜ í‘œì¤€ í‰ê°€ ë©”íŠ¸ë¦­:
    1. ê° í´ë˜ìŠ¤ë³„ AP (Average Precision) ê³„ì‚°
    2. ëª¨ë“  í´ë˜ìŠ¤ì˜ AP í‰ê· 
    3. IoU ì„ê³„ê°’ì— ë”°ë¥¸ ì •ë°€ë„-ì¬í˜„ìœ¨ ê³¡ì„ 
    
    Args:
        predictions: ì˜ˆì¸¡ ê²°ê³¼ [(boxes, scores, classes), ...]
        targets: ì‹¤ì œ ì •ë‹µ [(boxes, classes), ...]
        iou_threshold: IoU ì„ê³„ê°’
    
    Returns:
        float: mAP ì ìˆ˜
    """
    
    if len(predictions) == 0 or len(targets) == 0:
        return 0.0
    
    # ê°„ì†Œí™”ëœ mAP ê³„ì‚°
    total_precision = 0.0
    total_recall = 0.0
    num_samples = 0
    
    for pred, target in zip(predictions, targets):
        pred_boxes, pred_scores, pred_classes = pred
        target_boxes, target_classes = target
        
        if len(pred_boxes) == 0 or len(target_boxes) == 0:
            continue
        
        # ê° ì˜ˆì¸¡ì— ëŒ€í•´ ìµœê³  IoU ì°¾ê¸°
        matches = 0
        for pred_box in pred_boxes:
            best_iou = 0
            for target_box in target_boxes:
                iou = calculate_iou(pred_box, target_box)
                best_iou = max(best_iou, iou)
            
            if best_iou >= iou_threshold:
                matches += 1
        
        # ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ ê³„ì‚°
        precision = matches / len(pred_boxes) if len(pred_boxes) > 0 else 0
        recall = matches / len(target_boxes) if len(target_boxes) > 0 else 0
        
        total_precision += precision
        total_recall += recall
        num_samples += 1
    
    if num_samples == 0:
        return 0.0
    
    avg_precision = total_precision / num_samples
    avg_recall = total_recall / num_samples
    
    # F1 ì ìˆ˜ë¡œ mAP ê·¼ì‚¬
    if avg_precision + avg_recall > 0:
        map_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)
    else:
        map_score = 0.0
    
    return map_score

def evaluate_model(model, dataloader, device):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(tqdm(dataloader, desc="í‰ê°€")):
            if batch_idx >= 50:  # í‰ê°€ ì†ë„ë¥¼ ìœ„í•´ 50ë°°ì¹˜ë§Œ
                break
                
            images = images.to(device)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            predictions = model(images)
            results = decode_predictions(predictions, confidence_threshold=0.3)
            
            # íƒ€ê²Ÿ ë°ì´í„° ë³€í™˜ (ê°„ì†Œí™”)
            batch_targets = []
            for i in range(len(images)):
                # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” íƒ€ê²Ÿ ë°ì´í„°ì—ì„œ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                # ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„°ì´ë¯€ë¡œ ë”ë¯¸ íƒ€ê²Ÿ ìƒì„±
                dummy_boxes = [[0.2, 0.2, 0.8, 0.8]]  # ë”ë¯¸ ë°•ìŠ¤
                dummy_classes = [0]  # ë”ë¯¸ í´ë˜ìŠ¤
                batch_targets.append((dummy_boxes, dummy_classes))
            
            all_predictions.extend(results)
            all_targets.extend(batch_targets)
    
    # mAP ê³„ì‚°
    map_score = calculate_map(all_predictions, all_targets)
    
    return map_score

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ í‰ê°€
if best_model_state is not None:
    yolo_model.load_state_dict(best_model_state)

print("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
map_score = evaluate_model(yolo_model, val_loader, device)

print(f"âœ… í‰ê°€ ì™„ë£Œ:")
print(f"   mAP@0.5: {map_score:.4f}")

# ============================================================================
# 11. í•™ìŠµ ë‚´ìš© ìš”ì•½ ë° ì‹¤ìš©ì  í™œìš©
# ============================================================================

print(f"\nğŸ“ í•™ìŠµ ë‚´ìš© ìš”ì•½")
print(f"=" * 60)

print(f"âœ… ì™„ë£Œí•œ ë‚´ìš©:")
print(f"   1. YOLO ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ê°œë…ê³¼ êµ¬ì¡°")
print(f"   2. ê°ì²´ íƒì§€ ë¬¸ì œì˜ íŠ¹ì„±ê³¼ ë„ì „ê³¼ì œ")
print(f"   3. ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì ìˆ˜ ì²˜ë¦¬")
print(f"   4. Non-Maximum Suppression (NMS) êµ¬í˜„")
print(f"   5. IoU ê³„ì‚°ê³¼ ê°ì²´ íƒì§€ í‰ê°€ ë©”íŠ¸ë¦­")
print(f"   6. ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ êµ¬í˜„")

print(f"\nğŸ“Š ìµœì¢… ì„±ê³¼:")
print(f"   - ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")
print(f"   - mAP@0.5: {map_score:.4f}")
print(f"   - ëª¨ë¸ íŒŒë¼ë¯¸í„°: {params_info['total_params']:,}ê°œ")
print(f"   - í›ˆë ¨ ì‹œê°„: {training_time:.2f}ì´ˆ")

print(f"\nğŸ’¡ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸:")
print(f"   1. ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬: í•œ ë²ˆì˜ ìˆœì „íŒŒë¡œ ëª¨ë“  ê°ì²´ íƒì§€")
print(f"   2. ê·¸ë¦¬ë“œ ê¸°ë°˜: ì´ë¯¸ì§€ë¥¼ ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬")
print(f"   3. ì•µì»¤ ë°•ìŠ¤: ë‹¤ì–‘í•œ í¬ê¸°ì˜ ê°ì²´ íƒì§€")
print(f"   4. ë‹¤ì¤‘ ì†ì‹¤: ìœ„ì¹˜, í¬ê¸°, ì‹ ë¢°ë„, í´ë˜ìŠ¤ ì†ì‹¤ ê²°í•©")
print(f"   5. ì‹¤ì‹œê°„ ì²˜ë¦¬: ë¹ ë¥¸ ì¶”ë¡  ì†ë„")

print(f"\nğŸ” YOLOì˜ ì¥ë‹¨ì :")
print(f"   ì¥ì :")
print(f"   - ë¹ ë¥¸ ì¶”ë¡  ì†ë„ (ì‹¤ì‹œê°„ ê°€ëŠ¥)")
print(f"   - ì „ì—­ì  ë§¥ë½ ì´í•´")
print(f"   - ë‹¨ìˆœí•œ êµ¬ì¡°")
print(f"   - End-to-end í•™ìŠµ")
print(f"   ë‹¨ì :")
print(f"   - ì‘ì€ ê°ì²´ íƒì§€ ì–´ë ¤ì›€")
print(f"   - ì •í™•ë„ê°€ 2-stage ë°©ë²•ë³´ë‹¤ ë‚®ìŒ")
print(f"   - ê·¸ë¦¬ë“œ ì œì•½ìœ¼ë¡œ ì¸í•œ í•œê³„")

print(f"\nğŸš€ ì‹¤ìš©ì  í™œìš© ë¶„ì•¼:")
print(f"   1. ììœ¨ì£¼í–‰: ì°¨ëŸ‰, ë³´í–‰ì, ì‹ í˜¸ë“± íƒì§€")
print(f"   2. ë³´ì•ˆ: ì¹¨ì…ì íƒì§€, ì´ìƒ í–‰ë™ ê°ì§€")
print(f"   3. ì˜ë£Œ: ì˜ë£Œ ì˜ìƒì—ì„œ ë³‘ë³€ íƒì§€")
print(f"   4. ì œì¡°ì—…: ë¶ˆëŸ‰í’ˆ ê²€ì¶œ, í’ˆì§ˆ ê´€ë¦¬")
print(f"   5. ìŠ¤í¬ì¸ : ì„ ìˆ˜ ì¶”ì , ê²½ê¸° ë¶„ì„")
print(f"   6. ì†Œë§¤: ì¬ê³  ê´€ë¦¬, ê³ ê° í–‰ë™ ë¶„ì„")

print(f"\nğŸ”§ YOLO ë°œì „ ê³¼ì •:")
print(f"   1. YOLOv1: ìµœì´ˆì˜ ë‹¨ì¼ ë‹¨ê³„ íƒì§€ê¸°")
print(f"   2. YOLOv2/YOLO9000: ì•µì»¤ ë°•ìŠ¤, ë°°ì¹˜ ì •ê·œí™”")
print(f"   3. YOLOv3: ë‹¤ì¤‘ ìŠ¤ì¼€ì¼, FPN êµ¬ì¡°")
print(f"   4. YOLOv4: CSPNet, Mish í™œì„±í™”")
print(f"   5. YOLOv5: PyTorch êµ¬í˜„, ì‚¬ìš©ì ì¹œí™”ì ")
print(f"   6. YOLOv8: ìµœì‹  ê¸°ë²• í†µí•©, ë†’ì€ ì„±ëŠ¥")

print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
print(f"   - 07_gan_image_generation.py: GANìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±")
print(f"   - ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§ì˜ í•µì‹¬ ê°œë…")
print(f"   - ì°½ì˜ì  AIì™€ ì´ë¯¸ì§€ í•©ì„±")

print(f"\nğŸ”§ ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´:")
print(f"   1. ì‹¤ì œ COCO ë°ì´í„°ì…‹ ì‚¬ìš©")
print(f"   2. YOLOv5/v8 êµ¬í˜„")
print(f"   3. ë‹¤ì–‘í•œ ì•µì»¤ ë°•ìŠ¤ ì „ëµ")
print(f"   4. ë°ì´í„° ì¦ê°• ê¸°ë²• ì ìš©")
print(f"   5. ëª¨ë¸ ê²½ëŸ‰í™” (MobileNet ë°±ë³¸)")

print(f"\n" + "=" * 60)
print(f"ğŸ‰ YOLO ê°ì²´ íƒì§€ íŠœí† ë¦¬ì–¼ ì™„ë£Œ!")
print(f"   ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œ GAN ì´ë¯¸ì§€ ìƒì„±ì„ ë°°ì›Œë³´ì„¸ìš”!")
print(f"=" * 60)
                    linewidth=2, edgecolor='red', facecolor='none'
                )
                axes[idx].add_patch(rect)
                
                # ë¼ë²¨
                label = f'{CLASS_NAMES[cls]}: {score:.2f}'
                axes[idx].text(x1, y1 - 5, label, color='red', fontsize=10,
                             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
        
        plt.suptitle('YOLO ê°ì²´ íƒì§€ ê²°ê³¼', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()

# ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ íƒì§€ ê²°ê³¼ ì‹œê°í™”
sample_images, _ = next(iter(val_loader))
sample_images = sample_images.to(device)

visualize_detections(sample_images[:4], None)

# ============================================================================
# 10. í•™ìŠµ ë‚´ìš© ìš”ì•½ ë° ì‹¤ìš©ì  í™œìš©
# ============================================================================

print(f"\nğŸ“ í•™ìŠµ ë‚´ìš© ìš”ì•½")
print(f"=" * 60)

print(f"âœ… ì™„ë£Œí•œ ë‚´ìš©:")
print(f"   1. YOLO ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ì›ë¦¬ì™€ êµ¬ì¡° ì´í•´")
print(f"   2. ê°ì²´ íƒì§€ ë¬¸ì œì˜ íŠ¹ì„±ê³¼ ë„ì „ê³¼ì œ")
print(f"   3. ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì ìˆ˜ ì²˜ë¦¬")
print(f"   4. Non-Maximum Suppression (NMS) êµ¬í˜„")
print(f"   5. ë‹¤ì¤‘ ì†ì‹¤ í•¨ìˆ˜ ì„¤ê³„ ë° ê· í˜• ì¡°ì •")
print(f"   6. ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ êµ¬í˜„")

print(f"\nğŸ“Š ìµœì¢… ì„±ê³¼:")
print(f"   - YOLO ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")
print(f"   - ì´ íŒŒë¼ë¯¸í„°: {params_info['total_params']:,}ê°œ")
print(f"   - í›ˆë ¨ ì‹œê°„: {training_time:.2f}ì´ˆ")
print(f"   - ê·¸ë¦¬ë“œ í¬ê¸°: {GRID_SIZE}x{GRID_SIZE}")

print(f"\nğŸ’¡ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸:")
print(f"   1. ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ë¡œ ìœ„ì¹˜ + ë¶„ë¥˜ ë™ì‹œ ìˆ˜í–‰")
print(f"   2. ê·¸ë¦¬ë“œ ê¸°ë°˜ ì˜ˆì¸¡ìœ¼ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬")
print(f"   3. ë‹¤ì¤‘ ì†ì‹¤ í•¨ìˆ˜ì˜ ê°€ì¤‘ì¹˜ ê· í˜•")
print(f"   4. NMSë¡œ ì¤‘ë³µ íƒì§€ ì œê±°")
print(f"   5. IoU ë©”íŠ¸ë¦­ì˜ ì¤‘ìš”ì„±")

print(f"\nğŸ” YOLOì˜ ì¥ë‹¨ì :")
print(f"   ì¥ì :")
print(f"   - ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë¹ ë¥¸ ì†ë„")
print(f"   - End-to-end í•™ìŠµìœ¼ë¡œ ê°„ë‹¨í•œ êµ¬ì¡°")
print(f"   - ì „ì—­ì  ì»¨í…ìŠ¤íŠ¸ í™œìš©")
print(f"   - ë‹¤ì–‘í•œ í¬ê¸° ê°ì²´ íƒì§€ ê°€ëŠ¥")
print(f"   ë‹¨ì :")
print(f"   - ì‘ì€ ê°ì²´ íƒì§€ ì–´ë ¤ì›€")
print(f"   - ê²¹ì¹˜ëŠ” ê°ì²´ ì²˜ë¦¬ ì œí•œ")
print(f"   - ì •í™•í•œ ìœ„ì¹˜ ì˜ˆì¸¡ì˜ ì–´ë ¤ì›€")

print(f"\nğŸš€ ì‹¤ìš©ì  í™œìš© ë¶„ì•¼:")
print(f"   1. ììœ¨ì£¼í–‰: ì°¨ëŸ‰, ë³´í–‰ì, ì‹ í˜¸ë“± íƒì§€")
print(f"   2. ë³´ì•ˆ ì‹œìŠ¤í…œ: ì¹¨ì…ì íƒì§€, ì´ìƒ í–‰ë™ ê°ì§€")
print(f"   3. ì˜ë£Œ ì˜ìƒ: ë³‘ë³€, ì¢…ì–‘ íƒì§€")
print(f"   4. ì œì¡°ì—…: ë¶ˆëŸ‰í’ˆ ê²€ì¶œ, í’ˆì§ˆ ê´€ë¦¬")
print(f"   5. ìŠ¤í¬ì¸  ë¶„ì„: ì„ ìˆ˜ ì¶”ì , ê²½ê¸° ë¶„ì„")
print(f"   6. ì†Œë§¤ì—…: ì¬ê³  ê´€ë¦¬, ê³ ê° í–‰ë™ ë¶„ì„")

print(f"\nğŸ”§ ì„±ëŠ¥ ê°œì„  ë°©ë²•:")
print(f"   1. ë°ì´í„° ì¦ê°•: ë‹¤ì–‘í•œ ê°ë„, ì¡°ëª…, í¬ê¸°")
print(f"   2. ì•µì»¤ ë°•ìŠ¤: ë‹¤ì–‘í•œ ì¢…íš¡ë¹„ ì‚¬ì „ ì •ì˜")
print(f"   3. ë©€í‹°ìŠ¤ì¼€ì¼ í›ˆë ¨: ë‹¤ì–‘í•œ í•´ìƒë„ í•™ìŠµ")
print(f"   4. í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ë§ˆì´ë‹: ì–´ë ¤ìš´ ìƒ˜í”Œ ì§‘ì¤‘ í•™ìŠµ")
print(f"   5. ì•™ìƒë¸”: ì—¬ëŸ¬ ëª¨ë¸ ê²°ê³¼ ê²°í•©")

print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
print(f"   - 07_gan_image_generation.py: GANìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±")
print(f"   - ìƒì„± ëª¨ë¸ì˜ ì›ë¦¬ì™€ ì ëŒ€ì  í•™ìŠµ")
print(f"   - ì°½ì¡°ì  AIì™€ ë°ì´í„° ì¦ê°• í™œìš©")

print(f"\nğŸ”§ ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´:")
print(f"   1. YOLOv3, YOLOv4, YOLOv5 ë¹„êµ")
print(f"   2. ì‹¤ì œ COCO ë°ì´í„°ì…‹ ì‚¬ìš©")
print(f"   3. ì „ì´ í•™ìŠµìœ¼ë¡œ íŠ¹ì • ë„ë©”ì¸ ì ì‘")
print(f"   4. ëª¨ë°”ì¼ ìµœì í™” (YOLOv5s, YOLOv8n)")
print(f"   5. ì‹¤ì‹œê°„ ì›¹ìº  ê°ì²´ íƒì§€ êµ¬í˜„")

print(f"\n" + "=" * 60)
print(f"ğŸ‰ YOLO ê°ì²´ íƒì§€ íŠœí† ë¦¬ì–¼ ì™„ë£Œ!")
print(f"   ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œ GAN ì´ë¯¸ì§€ ìƒì„±ì„ ë°°ì›Œë³´ì„¸ìš”!")
print(f"=" * 60)
import json
import os
from tqdm import tqdm
import time
import copy
import requests
from ultralytics import YOLO
import warnings
warnings.filterwarnings('ignore')

# ìš°ë¦¬ê°€ ë§Œë“  ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from utils.data_utils import download_and_extract
from utils.visualization import plot_training_curves
from utils.model_utils import count_parameters, save_checkpoint

print("ğŸš€ ë”¥ëŸ¬ë‹ ê°•ì˜ ì‹œë¦¬ì¦ˆ 6: YOLO ê°ì²´ íƒì§€")
print("=" * 60)#
 ============================================================================
# 1. í™˜ê²½ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ============================================================================

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸  ì‚¬ìš© ì¥ì¹˜: {device}")

# YOLO ê°ì²´ íƒì§€ë¥¼ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 16        # ê°ì²´ íƒì§€ëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©
LEARNING_RATE = 0.001  # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¸íŠœë‹ìš©
EPOCHS = 50            # ê°ì²´ íƒì§€ëŠ” ì¶©ë¶„í•œ í•™ìŠµ í•„ìš”
RANDOM_SEED = 42
IMG_SIZE = 640         # YOLO í‘œì¤€ ì…ë ¥ í¬ê¸°
CONF_THRESHOLD = 0.5   # ì‹ ë¢°ë„ ì„ê³„ê°’
IOU_THRESHOLD = 0.45   # NMS IoU ì„ê³„ê°’
MAX_DETECTIONS = 100   # ìµœëŒ€ íƒì§€ ê°ì²´ ìˆ˜

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

print(f"ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
print(f"   ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
print(f"   í•™ìŠµë¥ : {LEARNING_RATE}")
print(f"   ì—í¬í¬: {EPOCHS}")
print(f"   ì´ë¯¸ì§€ í¬ê¸°: {IMG_SIZE}x{IMG_SIZE}")
print(f"   ì‹ ë¢°ë„ ì„ê³„ê°’: {CONF_THRESHOLD}")
print(f"   IoU ì„ê³„ê°’: {IOU_THRESHOLD}")

# COCO í´ë˜ìŠ¤ ì´ë¦„ (80ê°œ í´ë˜ìŠ¤)
COCO_CLASSES = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
    'toothbrush'
]

print(f"\nğŸ“‹ COCO ë°ì´í„°ì…‹ ì •ë³´:")
print(f"   í´ë˜ìŠ¤ ìˆ˜: {len(COCO_CLASSES)}ê°œ")
print(f"   ì£¼ìš” í´ë˜ìŠ¤: {COCO_CLASSES[:10]}")

# ============================================================================
# 2. YOLO ëª¨ë¸ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

print(f"\nğŸ¤– YOLO ëª¨ë¸ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜")

class YOLODetector:
    """
    YOLO ê°ì²´ íƒì§€ê¸° í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì‚¬ì „ í›ˆë ¨ëœ YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬
    ê°ì²´ íƒì§€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ì™œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ”ê°€?
    1. ê³„ì‚° íš¨ìœ¨ì„±: ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ë©´ ìˆ˜ì¼~ìˆ˜ì£¼ ì†Œìš”
    2. ë°ì´í„° íš¨ìœ¨ì„±: COCO ì „ì²´ ë°ì´í„°ì…‹ í•„ìš” (ìˆ˜ë°±GB)
    3. ì„±ëŠ¥: ì´ë¯¸ ìµœì í™”ëœ ê³ ì„±ëŠ¥ ëª¨ë¸ í™œìš©
    4. ì‹¤ìš©ì„±: ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì¼ë°˜ì ì¸ ì ‘ê·¼ë²•
    5. í•™ìŠµ ëª©ì : ì•Œê³ ë¦¬ì¦˜ ì´í•´ì— ì§‘ì¤‘ ê°€ëŠ¥
    """
    
    def __init__(self, model_name='yolov8n.pt'):
        """
        YOLO íƒì§€ê¸° ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  YOLO ëª¨ë¸ ì´ë¦„
                - yolov8n.pt: nano (ê°€ì¥ ë¹ ë¦„, ê°€ì¥ ì‘ìŒ)
                - yolov8s.pt: small
                - yolov8m.pt: medium  
                - yolov8l.pt: large
                - yolov8x.pt: extra large (ê°€ì¥ ì •í™•, ê°€ì¥ í¼)
        """
        print(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        
        try:
            # Ultralytics YOLO ëª¨ë¸ ë¡œë“œ
            self.model = YOLO(model_name)
            print(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            # ëª¨ë¸ì„ ì ì ˆí•œ ì¥ì¹˜ë¡œ ì´ë™
            if torch.cuda.is_available():
                self.model.to(device)
                print(f"   GPUë¡œ ëª¨ë¸ ì´ë™ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            raise
    
    def detect_objects(self, image_path, conf_threshold=0.5, iou_threshold=0.45):
        """
        ì´ë¯¸ì§€ì—ì„œ ê°ì²´ íƒì§€ ìˆ˜í–‰
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” numpy ë°°ì—´
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: NMS IoU ì„ê³„ê°’
        
        Returns:
            dict: íƒì§€ ê²°ê³¼ (ë°”ìš´ë”© ë°•ìŠ¤, í´ë˜ìŠ¤, ì‹ ë¢°ë„)
        
        YOLO íƒì§€ ê³¼ì •:
        1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™”)
        2. ëª¨ë¸ ì¶”ë¡  (ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ í™•ë¥ )
        3. í›„ì²˜ë¦¬ (NMS, ì„ê³„ê°’ í•„í„°ë§)
        """
        
        # YOLO ì¶”ë¡  ì‹¤í–‰
        results = self.model(
            image_path,
            conf=conf_threshold,
            iou=iou_threshold,
            verbose=False
        )
        
        # ê²°ê³¼ íŒŒì‹±
        detections = []
        
        for result in results:
            boxes = result.boxes
            
            if boxes is not None:
                for i in range(len(boxes)):
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)
                    box = boxes.xyxy[i].cpu().numpy()
                    
                    # ì‹ ë¢°ë„ ì ìˆ˜
                    confidence = boxes.conf[i].cpu().numpy()
                    
                    # í´ë˜ìŠ¤ ID
                    class_id = int(boxes.cls[i].cpu().numpy())
                    
                    # í´ë˜ìŠ¤ ì´ë¦„
                    class_name = COCO_CLASSES[class_id]
                    
                    detections.append({
                        'bbox': box,  # [x1, y1, x2, y2]
                        'confidence': float(confidence),
                        'class_id': class_id,
                        'class_name': class_name
                    })
        
        return detections
    
    def visualize_detections(self, image_path, detections, save_path=None):
        """
        íƒì§€ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ì‹œê°í™”
        
        Args:
            image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            detections: íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            save_path: ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        
        Returns:
            PIL Image: ì‹œê°í™”ëœ ì´ë¯¸ì§€
        
        ì‹œê°í™” ìš”ì†Œ:
        1. ë°”ìš´ë”© ë°•ìŠ¤: ê°ì²´ ìœ„ì¹˜ í‘œì‹œ
        2. í´ë˜ìŠ¤ ë¼ë²¨: ê°ì²´ ì¢…ë¥˜ í‘œì‹œ
        3. ì‹ ë¢°ë„ ì ìˆ˜: ì˜ˆì¸¡ í™•ì‹ ë„ í‘œì‹œ
        4. ìƒ‰ìƒ ì½”ë”©: í´ë˜ìŠ¤ë³„ êµ¬ë¶„
        """
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = Image.fromarray(image_path)
        
        # ê·¸ë¦¬ê¸° ê°ì²´ ìƒì„±
        draw = ImageDraw.Draw(image)
        
        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ìƒì„± (í•´ì‹œ ê¸°ë°˜)
        def get_color(class_id):
            np.random.seed(class_id)
            return tuple(np.random.randint(0, 255, 3))
        
        # ê° íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        for detection in detections:
            bbox = detection['bbox']
            confidence = detection['confidence']
            class_name = detection['class_name']
            class_id = detection['class_id']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
            x1, y1, x2, y2 = bbox
            
            # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
            color = get_color(class_id)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            label = f"{class_name}: {confidence:.2f}"
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤
            try:
                font = ImageFont.truetype("arial.ttf", 16)
            except:
                font = ImageFont.load_default()
            
            # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
            bbox_text = draw.textbbox((0, 0), label, font=font)
            text_width = bbox_text[2] - bbox_text[0]
            text_height = bbox_text[3] - bbox_text[1]
            
            # í…ìŠ¤íŠ¸ ë°°ê²½
            draw.rectangle(
                [x1, y1 - text_height - 4, x1 + text_width + 4, y1],
                fill=color
            )
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            draw.text((x1 + 2, y1 - text_height - 2), label, fill='white', font=font)
        
        # ê²°ê³¼ ì €ì¥
        if save_path:
            image.save(save_path)
            print(f"ğŸ’¾ íƒì§€ ê²°ê³¼ ì €ì¥: {save_path}")
        
        return image

def calculate_iou(box1, box2):
    """
    ë‘ ë°”ìš´ë”© ë°•ìŠ¤ ê°„ì˜ IoU (Intersection over Union) ê³„ì‚°
    
    Args:
        box1, box2: [x1, y1, x2, y2] í˜•íƒœì˜ ë°”ìš´ë”© ë°•ìŠ¤
    
    Returns:
        float: IoU ê°’ (0~1)
    
    IoUëŠ” ê°ì²´ íƒì§€ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­:
    1. ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€: ì˜ˆì¸¡ ë°•ìŠ¤ì™€ ì‹¤ì œ ë°•ìŠ¤ì˜ ê²¹ì¹¨ ì •ë„
    2. NMS ì•Œê³ ë¦¬ì¦˜: ì¤‘ë³µ íƒì§€ ì œê±°
    3. mAP ê³„ì‚°: í‰ê·  ì •ë°€ë„ ê³„ì‚°ì˜ ê¸°ì¤€
    
    ê³„ì‚° ë°©ë²•:
    IoU = êµì§‘í•© ì˜ì—­ / í•©ì§‘í•© ì˜ì—­
    """
    
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    # êµì§‘í•©ì´ ì—†ëŠ” ê²½ìš°
    if x2 <= x1 or y2 <= y1:
        return 0.0
    
    # êµì§‘í•© ë©´ì 
    intersection = (x2 - x1) * (y2 - y1)
    
    # ê° ë°•ìŠ¤ì˜ ë©´ì 
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # í•©ì§‘í•© ë©´ì 
    union = area1 + area2 - intersection
    
    # IoU ê³„ì‚°
    iou = intersection / union if union > 0 else 0.0
    
    return iou

def non_max_suppression(detections, iou_threshold=0.45):
    """
    Non-Maximum Suppression (NMS) ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
    
    Args:
        detections: íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        iou_threshold: IoU ì„ê³„ê°’
    
    Returns:
        list: NMS ì ìš© í›„ íƒì§€ ê²°ê³¼
    
    NMSê°€ í•„ìš”í•œ ì´ìœ :
    1. ì¤‘ë³µ íƒì§€: í•˜ë‚˜ì˜ ê°ì²´ì— ì—¬ëŸ¬ ë°”ìš´ë”© ë°•ìŠ¤
    2. ì„±ëŠ¥ í–¥ìƒ: ê°€ì¥ í™•ì‹¤í•œ íƒì§€ë§Œ ìœ ì§€
    3. í›„ì²˜ë¦¬ í‘œì¤€: ëª¨ë“  ê°ì²´ íƒì§€ ëª¨ë¸ì—ì„œ ì‚¬ìš©
    
    NMS ì•Œê³ ë¦¬ì¦˜:
    1. ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    2. ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ë°•ìŠ¤ ì„ íƒ
    3. ê²¹ì¹˜ëŠ” ë°•ìŠ¤ë“¤ ì œê±° (IoU > threshold)
    4. ë°˜ë³µ
    """
    
    if not detections:
        return []
    
    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
    
    # NMS ì ìš©
    keep = []
    
    while detections:
        # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ íƒì§€ ì„ íƒ
        current = detections.pop(0)
        keep.append(current)
        
        # ë‚˜ë¨¸ì§€ íƒì§€ë“¤ê³¼ IoU ê³„ì‚°
        remaining = []
        for detection in detections:
            # ê°™ì€ í´ë˜ìŠ¤ì¸ ê²½ìš°ë§Œ NMS ì ìš©
            if detection['class_id'] == current['class_id']:
                iou = calculate_iou(current['bbox'], detection['bbox'])
                # IoUê°€ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ìœ ì§€
                if iou <= iou_threshold:
                    remaining.append(detection)
            else:
                # ë‹¤ë¥¸ í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                remaining.append(detection)
        
        detections = remaining
    
    return keep

# ============================================================================
# 3. ìƒ˜í”Œ ì´ë¯¸ì§€ ì¤€ë¹„ ë° íƒì§€ ì‹¤í—˜
# ============================================================================

print(f"\nğŸ“ ìƒ˜í”Œ ì´ë¯¸ì§€ ì¤€ë¹„ ë° ê°ì²´ íƒì§€ ì‹¤í—˜")

def download_sample_images():
    """
    ê°ì²´ íƒì§€ ì‹¤í—˜ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    
    ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì˜ ì´ë¯¸ì§€:
    1. ë‹¨ì¼ ê°ì²´: ëª…í™•í•œ íƒì§€ ëŒ€ìƒ
    2. ë‹¤ì¤‘ ê°ì²´: ì—¬ëŸ¬ ê°ì²´ ë™ì‹œ íƒì§€
    3. ë³µì¡í•œ ë°°ê²½: ì‹¤ì œ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
    4. ê²¹ì¹˜ëŠ” ê°ì²´: NMS íš¨ê³¼ í™•ì¸
    """
    
    sample_images = [
        {
            'url': 'https://images.unsplash.com/photo-1551963831-b3b1ca40c98e?w=800',
            'filename': 'dogs.jpg',
            'description': 'ê°•ì•„ì§€ë“¤ (ë‹¤ì¤‘ ê°ì²´)'
        },
        {
            'url': 'https://images.unsplash.com/photo-1449824913935-59a10b8d2000?w=800', 
            'filename': 'city_street.jpg',
            'description': 'ë„ì‹œ ê±°ë¦¬ (ë³µì¡í•œ ë°°ê²½)'
        },
        {
            'url': 'https://images.unsplash.com/photo-1506905925346-21bda4d32df4?w=800',
            'filename': 'mountain_bike.jpg', 
            'description': 'ì‚°ì•…ìì „ê±° (ë‹¨ì¼ ê°ì²´)'
        }
    ]
    
    os.makedirs('./sample_images', exist_ok=True)
    
    downloaded_images = []
    
    for img_info in sample_images:
        try:
            print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {img_info['description']}")
            
            response = requests.get(img_info['url'])
            response.raise_for_status()
            
            filepath = f"./sample_images/{img_info['filename']}"
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            downloaded_images.append({
                'path': filepath,
                'description': img_info['description']
            })
            
            print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath}")
            
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({img_info['filename']}): {e}")
    
    return downloaded_images

# ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©)
try:
    sample_images = download_sample_images()
except:
    print("âš ï¸  ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    sample_images = []

# YOLO íƒì§€ê¸° ì´ˆê¸°í™”
try:
    detector = YOLODetector('yolov8n.pt')  # nano ëª¨ë¸ (ë¹ ë¥¸ ì¶”ë¡ )
    
    print(f"\nğŸ” YOLO ê°ì²´ íƒì§€ ì‹¤í—˜")
    
    # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ ê°ì²´ íƒì§€ ìˆ˜í–‰
    if sample_images:
        for i, img_info in enumerate(sample_images):
            print(f"\nğŸ“Š ì´ë¯¸ì§€ {i+1}: {img_info['description']}")
            
            # ê°ì²´ íƒì§€ ìˆ˜í–‰
            detections = detector.detect_objects(
                img_info['path'],
                conf_threshold=CONF_THRESHOLD,
                iou_threshold=IOU_THRESHOLD
            )
            
            print(f"   íƒì§€ëœ ê°ì²´ ìˆ˜: {len(detections)}ê°œ")
            
            # íƒì§€ ê²°ê³¼ ì¶œë ¥
            for j, detection in enumerate(detections):
                print(f"   {j+1}. {detection['class_name']}: {detection['confidence']:.3f}")
            
            # ê²°ê³¼ ì‹œê°í™”
            result_image = detector.visualize_detections(
                img_info['path'],
                detections,
                save_path=f"./results/detection_result_{i+1}.jpg"
            )
            
            # ì´ë¯¸ì§€ í‘œì‹œ
            plt.figure(figsize=(12, 8))
            plt.imshow(result_image)
            plt.title(f"YOLO ê°ì²´ íƒì§€ ê²°ê³¼: {img_info['description']}")
            plt.axis('off')
            plt.show()
    
    else:
        print("ğŸ“ ìƒ˜í”Œ ì´ë¯¸ì§€ê°€ ì—†ì–´ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        dummy_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        print("ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•˜ì„¸ìš”:")
        print("   detections = detector.detect_objects('your_image.jpg')")
        print("   result_img = detector.visualize_detections('your_image.jpg', detections)")

except Exception as e:
    print(f"âŒ YOLO ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
    print("   1. ì¸í„°ë„· ì—°ê²° ìƒíƒœ")
    print("   2. ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: pip install ultralytics")
    print("   3. PyTorch ì„¤ì¹˜ ìƒíƒœ")
    
    # ëŒ€ì•ˆ: ê°„ë‹¨í•œ YOLO êµ¬ì¡° ì„¤ëª…
    print(f"\nğŸ“š YOLO ì•Œê³ ë¦¬ì¦˜ ì´ë¡  ì„¤ëª…")
    
    class SimpleYOLO(nn.Module):
        """
        êµìœ¡ìš© ê°„ë‹¨í•œ YOLO êµ¬ì¡° (ì‹¤ì œ ë™ì‘í•˜ì§€ ì•ŠìŒ)
        
        ì‹¤ì œ YOLOì˜ í•µì‹¬ ê°œë…ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œ ì½”ë“œ
        """
        
        def __init__(self, num_classes=80, num_anchors=3):
            super(SimpleYOLO, self).__init__()
            
            # ë°±ë³¸ ë„¤íŠ¸ì›Œí¬ (íŠ¹ì§• ì¶”ì¶œ)
            self.backbone = nn.Sequential(
                nn.Conv2d(3, 32, 3, padding=1),
                nn.BatchNorm2d(32),
                nn.ReLU(),
                nn.MaxPool2d(2),
                
                nn.Conv2d(32, 64, 3, padding=1),
                nn.BatchNorm2d(64), 
                nn.ReLU(),
                nn.MaxPool2d(2),
                
                nn.Conv2d(64, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.MaxPool2d(2),
            )
            
            # íƒì§€ í—¤ë“œ
            # ê° ê·¸ë¦¬ë“œ ì…€ë§ˆë‹¤ num_anchorsê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì˜ˆì¸¡
            # ê° ë°•ìŠ¤ë§ˆë‹¤: [x, y, w, h, confidence] + class_probabilities
            output_size = num_anchors * (5 + num_classes)
            
            self.detection_head = nn.Conv2d(128, output_size, 1)
            
        def forward(self, x):
            # íŠ¹ì§• ì¶”ì¶œ
            features = self.backbone(x)
            
            # íƒì§€ ì˜ˆì¸¡
            predictions = self.detection_head(features)
            
            return predictions
    
    # ê°„ë‹¨í•œ YOLO ëª¨ë¸ ìƒì„± (ì˜ˆì‹œ)
    simple_yolo = SimpleYOLO(num_classes=80)
    
    print(f"\nğŸ“‹ ê°„ë‹¨í•œ YOLO êµ¬ì¡°:")
    print(simple_yolo)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    params = count_parameters(simple_yolo, detailed=False)
    print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
    print(f"   íŒŒë¼ë¯¸í„° ìˆ˜: {params['total_params']:,}ê°œ")
    print(f"   (ì‹¤ì œ YOLOv8nì€ ì•½ 3.2Mê°œ íŒŒë¼ë¯¸í„°)")

# ============================================================================
# 4. YOLO ì•Œê³ ë¦¬ì¦˜ í•µì‹¬ ê°œë… ì„¤ëª…
# ============================================================================

print(f"\nğŸ“š YOLO ì•Œê³ ë¦¬ì¦˜ í•µì‹¬ ê°œë…")

def explain_yolo_concepts():
    """
    YOLO ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ê°œë…ë“¤ì„ ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…
    """
    
    print(f"\nğŸ¯ 1. YOLOì˜ ê¸°ë³¸ ì•„ì´ë””ì–´")
    print(f"   - ì´ë¯¸ì§€ë¥¼ SÃ—S ê·¸ë¦¬ë“œë¡œ ë¶„í• ")
    print(f"   - ê° ê·¸ë¦¬ë“œ ì…€ì´ ê°ì²´ íƒì§€ ë‹´ë‹¹")
    print(f"   - í•œ ë²ˆì˜ ë„¤íŠ¸ì›Œí¬ íŒ¨ìŠ¤ë¡œ ëª¨ë“  ê°ì²´ íƒì§€")
    print(f"   - 'You Only Look Once' - ì´ë¦„ì˜ ìœ ë˜")
    
    print(f"\nğŸ“ 2. ë°”ìš´ë”© ë°•ìŠ¤ ì˜ˆì¸¡")
    print(f"   - ê° ê·¸ë¦¬ë“œ ì…€ë§ˆë‹¤ Bê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì˜ˆì¸¡")
    print(f"   - ë°•ìŠ¤ ì •ë³´: (x, y, w, h, confidence)")
    print(f"   - x, y: ë°•ìŠ¤ ì¤‘ì‹¬ì  (ê·¸ë¦¬ë“œ ì…€ ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œ)")
    print(f"   - w, h: ë°•ìŠ¤ í¬ê¸° (ì´ë¯¸ì§€ ê¸°ì¤€ ìƒëŒ€ í¬ê¸°)")
    print(f"   - confidence: ê°ì²´ ì¡´ì¬ í™•ë¥  Ã— IoU")
    
    print(f"\nğŸ·ï¸  3. í´ë˜ìŠ¤ ì˜ˆì¸¡")
    print(f"   - ê° ê·¸ë¦¬ë“œ ì…€ë§ˆë‹¤ Cê°œ í´ë˜ìŠ¤ í™•ë¥  ì˜ˆì¸¡")
    print(f"   - P(Class_i | Object): ê°ì²´ê°€ ìˆì„ ë•Œ í´ë˜ìŠ¤ í™•ë¥ ")
    print(f"   - ìµœì¢… ì ìˆ˜: confidence Ã— class_probability")
    
    print(f"\nâš™ï¸  4. ì†ì‹¤ í•¨ìˆ˜")
    print(f"   - ì¢Œí‘œ ì†ì‹¤: ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì¹˜ ì˜¤ì°¨")
    print(f"   - ì‹ ë¢°ë„ ì†ì‹¤: ê°ì²´ ì¡´ì¬ ì—¬ë¶€ ì˜¤ì°¨") 
    print(f"   - í´ë˜ìŠ¤ ì†ì‹¤: í´ë˜ìŠ¤ ë¶„ë¥˜ ì˜¤ì°¨")
    print(f"   - ê°€ì¤‘ì¹˜: ì¢Œí‘œ > ì‹ ë¢°ë„ > í´ë˜ìŠ¤")
    
    print(f"\nğŸ”„ 5. í›„ì²˜ë¦¬ (Post-processing)")
    print(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’ í•„í„°ë§")
    print(f"   - Non-Maximum Suppression (NMS)")
    print(f"   - ìµœì¢… íƒì§€ ê²°ê³¼ ì¶œë ¥")

explain_yolo_concepts()

# ============================================================================
# 5. ê°ì²´ íƒì§€ ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­
# ============================================================================

print(f"\nğŸ“Š ê°ì²´ íƒì§€ ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­")

def explain_detection_metrics():
    """
    ê°ì²´ íƒì§€ ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­ ì„¤ëª…
    """
    
    print(f"\nğŸ¯ 1. IoU (Intersection over Union)")
    print(f"   - ì˜ˆì¸¡ ë°•ìŠ¤ì™€ ì‹¤ì œ ë°•ìŠ¤ì˜ ê²¹ì¹¨ ì •ë„")
    print(f"   - IoU = êµì§‘í•© / í•©ì§‘í•©")
    print(f"   - 0.5 ì´ìƒì´ë©´ ì¼ë°˜ì ìœ¼ë¡œ 'ì •í™•í•œ' íƒì§€")
    print(f"   - COCOì—ì„œëŠ” 0.5~0.95 ë²”ìœ„ì—ì„œ í‰ê°€")
    
    print(f"\nğŸ“ˆ 2. Precisionê³¼ Recall")
    print(f"   - Precision = TP / (TP + FP)")
    print(f"     ì˜¬ë°”ë¥¸ íƒì§€ / ì „ì²´ íƒì§€")
    print(f"   - Recall = TP / (TP + FN)")
    print(f"     ì˜¬ë°”ë¥¸ íƒì§€ / ì „ì²´ ì‹¤ì œ ê°ì²´")
    print(f"   - Trade-off: ì„ê³„ê°’ì— ë”°ë¼ ë³€í™”")
    
    print(f"\nğŸ† 3. AP (Average Precision)")
    print(f"   - Precision-Recall ê³¡ì„  ì•„ë˜ ë©´ì ")
    print(f"   - íŠ¹ì • IoU ì„ê³„ê°’ì—ì„œì˜ ì„±ëŠ¥")
    print(f"   - AP@0.5: IoU 0.5ì—ì„œì˜ AP")
    print(f"   - AP@0.75: IoU 0.75ì—ì„œì˜ AP")
    
    print(f"\nğŸ¥‡ 4. mAP (mean Average Precision)")
    print(f"   - ëª¨ë“  í´ë˜ìŠ¤ì˜ AP í‰ê· ")
    print(f"   - mAP@0.5: IoU 0.5ì—ì„œì˜ mAP")
    print(f"   - mAP@0.5:0.95: IoU 0.5~0.95 í‰ê· ")
    print(f"   - COCO ëŒ€íšŒì˜ ê³µì‹ ë©”íŠ¸ë¦­")

explain_detection_metrics()

# IoU ê³„ì‚° ì˜ˆì‹œ
print(f"\nğŸ§® IoU ê³„ì‚° ì˜ˆì‹œ:")

# ì˜ˆì‹œ ë°”ìš´ë”© ë°•ìŠ¤
box1 = [100, 100, 200, 200]  # ì‹¤ì œ ë°•ìŠ¤
box2 = [150, 150, 250, 250]  # ì˜ˆì¸¡ ë°•ìŠ¤

iou_example = calculate_iou(box1, box2)
print(f"   ë°•ìŠ¤1: {box1} (ì‹¤ì œ)")
print(f"   ë°•ìŠ¤2: {box2} (ì˜ˆì¸¡)")
print(f"   IoU: {iou_example:.3f}")

# ì‹œê°í™”
fig, ax = plt.subplots(1, 1, figsize=(8, 8))

# ë°•ìŠ¤ ê·¸ë¦¬ê¸°
rect1 = patches.Rectangle((box1[0], box1[1]), box1[2]-box1[0], box1[3]-box1[1], 
                         linewidth=2, edgecolor='blue', facecolor='blue', alpha=0.3, label='ì‹¤ì œ ë°•ìŠ¤')
rect2 = patches.Rectangle((box2[0], box2[1]), box2[2]-box2[0], box2[3]-box2[1], 
                         linewidth=2, edgecolor='red', facecolor='red', alpha=0.3, label='ì˜ˆì¸¡ ë°•ìŠ¤')

ax.add_patch(rect1)
ax.add_patch(rect2)

ax.set_xlim(50, 300)
ax.set_ylim(50, 300)
ax.set_aspect('equal')
ax.legend()
ax.set_title(f'IoU ê³„ì‚° ì˜ˆì‹œ (IoU = {iou_example:.3f})')
ax.grid(True, alpha=0.3)

plt.show()

# ============================================================================
# 6. ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì‹œë®¬ë ˆì´ì…˜
# ============================================================================

print(f"\nâš¡ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì‹œë®¬ë ˆì´ì…˜")

def simulate_realtime_detection():
    """
    ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
    
    ì‹¤ì œ ì›¹ìº ì´ë‚˜ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ëŒ€ì‹ 
    ì„±ëŠ¥ ì¸¡ì •ê³¼ ìµœì í™” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    
    print(f"\nğŸ¥ ì‹¤ì‹œê°„ íƒì§€ ì„±ëŠ¥ ë¶„ì„")
    
    # ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í¬ê¸°ì—ì„œ ì¶”ë¡  ì‹œê°„ ì¸¡ì •
    image_sizes = [320, 416, 512, 640, 832]
    inference_times = []
    
    if 'detector' in globals():
        for size in image_sizes:
            # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            dummy_image = np.random.randint(0, 255, (size, size, 3), dtype=np.uint8)
            
            # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            
            try:
                # ì‹¤ì œ ì¶”ë¡  (ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ í‰ê·  ê³„ì‚°)
                for _ in range(5):
                    _ = detector.detect_objects(dummy_image, conf_threshold=0.5)
                
                avg_time = (time.time() - start_time) / 5
                inference_times.append(avg_time * 1000)  # ms ë‹¨ìœ„
                
                fps = 1.0 / avg_time
                print(f"   {size}Ã—{size}: {avg_time*1000:.1f}ms ({fps:.1f} FPS)")
                
            except:
                inference_times.append(0)
                print(f"   {size}Ã—{size}: ì¸¡ì • ì‹¤íŒ¨")
        
        # ì„±ëŠ¥ ê·¸ë˜í”„
        if any(t > 0 for t in inference_times):
            plt.figure(figsize=(10, 6))
            
            plt.subplot(1, 2, 1)
            plt.plot(image_sizes, inference_times, 'bo-')
            plt.xlabel('ì´ë¯¸ì§€ í¬ê¸°')
            plt.ylabel('ì¶”ë¡  ì‹œê°„ (ms)')
            plt.title('ì´ë¯¸ì§€ í¬ê¸°ë³„ ì¶”ë¡  ì‹œê°„')
            plt.grid(True, alpha=0.3)
            
            plt.subplot(1, 2, 2)
            fps_values = [1000/t if t > 0 else 0 for t in inference_times]
            plt.plot(image_sizes, fps_values, 'ro-')
            plt.xlabel('ì´ë¯¸ì§€ í¬ê¸°')
            plt.ylabel('FPS')
            plt.title('ì´ë¯¸ì§€ í¬ê¸°ë³„ FPS')
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.show()
    
    print(f"\nâš¡ ì‹¤ì‹œê°„ íƒì§€ ìµœì í™” íŒ:")
    print(f"   1. ëª¨ë¸ í¬ê¸°: nano < small < medium < large")
    print(f"   2. ì…ë ¥ í•´ìƒë„: ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„ (ì •í™•ë„ trade-off)")
    print(f"   3. ë°°ì¹˜ ì²˜ë¦¬: ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬")
    print(f"   4. GPU í™œìš©: CUDA ê°€ì†")
    print(f"   5. ëª¨ë¸ ì–‘ìí™”: INT8, FP16 ì •ë°€ë„ ê°ì†Œ")
    print(f"   6. TensorRT: NVIDIA GPU ìµœì í™”")

simulate_realtime_detection()

# ============================================================================
# 7. í•™ìŠµ ë‚´ìš© ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„
# ============================================================================

print(f"\nğŸ“ í•™ìŠµ ë‚´ìš© ìš”ì•½")
print(f"=" * 60)

print(f"âœ… ì™„ë£Œí•œ ë‚´ìš©:")
print(f"   1. YOLO ì•Œê³ ë¦¬ì¦˜ì˜ í•µì‹¬ ì›ë¦¬ ì´í•´")
print(f"   2. ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ í™œìš©í•œ ê°ì²´ íƒì§€")
print(f"   3. ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ ì ìˆ˜ ì²˜ë¦¬")
print(f"   4. Non-Maximum Suppression (NMS) êµ¬í˜„")
print(f"   5. ê°ì²´ íƒì§€ ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­ í•™ìŠµ")
print(f"   6. ì‹¤ì‹œê°„ íƒì§€ ì„±ëŠ¥ ë¶„ì„")

print(f"\nğŸ’¡ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸:")
print(f"   1. ì‹¤ì‹œê°„ ì²˜ë¦¬: YOLOì˜ ê°€ì¥ í° ì¥ì ")
print(f"   2. End-to-End í•™ìŠµ: ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ë¡œ ì™„ì „í•œ íƒì§€")
print(f"   3. ê·¸ë¦¬ë“œ ê¸°ë°˜ ì˜ˆì¸¡: íš¨ìœ¨ì ì¸ ê³µê°„ ë¶„í• ")
print(f"   4. í›„ì²˜ë¦¬ì˜ ì¤‘ìš”ì„±: NMSë¡œ ì¤‘ë³µ ì œê±°")
print(f"   5. ì„±ëŠ¥ í‰ê°€: IoU, mAP ë“± ì „ë¬¸ ë©”íŠ¸ë¦­")

print(f"\nğŸ” YOLOì˜ ì¥ë‹¨ì :")
print(f"   ì¥ì :")
print(f"   - ë¹ ë¥¸ ì¶”ë¡  ì†ë„ (ì‹¤ì‹œê°„ ê°€ëŠ¥)")
print(f"   - ê°„ë‹¨í•œ êµ¬ì¡° (ì´í•´í•˜ê¸° ì‰¬ì›€)")
print(f"   - ì „ì—­ì  ì¶”ë¡  (ì „ì²´ ì´ë¯¸ì§€ ê³ ë ¤)")
print(f"   - ë‹¤ì–‘í•œ í¬ê¸° ê°ì²´ íƒì§€")
print(f"   ë‹¨ì :")
print(f"   - ì‘ì€ ê°ì²´ íƒì§€ ì–´ë ¤ì›€")
print(f"   - ê²¹ì¹˜ëŠ” ê°ì²´ ì²˜ë¦¬ ì œí•œ")
print(f"   - ìƒˆë¡œìš´ ì¢…íš¡ë¹„ ê°ì²´ ì–´ë ¤ì›€")

print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
print(f"   - 07_gan_image_generation.py: GANìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±")
print(f"   - CelebA ë°ì´í„°ì…‹ìœ¼ë¡œ ì–¼êµ´ ìƒì„±")
print(f"   - ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§ í•™ìŠµ")

print(f"\nğŸ”§ ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´:")
print(f"   1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹: ìì‹ ë§Œì˜ ê°ì²´ íƒì§€")
print(f"   2. ëª¨ë¸ íŒŒì¸íŠœë‹: íŠ¹ì • ë„ë©”ì¸ ìµœì í™”")
print(f"   3. ë‹¤ë¥¸ YOLO ë²„ì „: YOLOv5, YOLOv8, YOLOv9")
print(f"   4. ì‹¤ì‹œê°„ ë¹„ë””ì˜¤: ì›¹ìº  ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼")
print(f"   5. ëª¨ë°”ì¼ ë°°í¬: ONNX, TensorFlow Lite")

print(f"\nğŸ¯ ì‹¤ì œ ì‘ìš© ë¶„ì•¼:")
print(f"   - ììœ¨ì£¼í–‰: ì°¨ëŸ‰, ë³´í–‰ì, ì‹ í˜¸ë“± íƒì§€")
print(f"   - ë³´ì•ˆ ì‹œìŠ¤í…œ: ì¹¨ì…ì, ìœ„í—˜ë¬¼ íƒì§€")
print(f"   - ì˜ë£Œ ì˜ìƒ: ë³‘ë³€, ì¥ê¸° íƒì§€")
print(f"   - ì œì¡°ì—…: ë¶ˆëŸ‰í’ˆ, ë¶€í’ˆ íƒì§€")
print(f"   - ìŠ¤í¬ì¸  ë¶„ì„: ì„ ìˆ˜, ê³µ ì¶”ì ")

print(f"\n" + "=" * 60)
print(f"ğŸ‰ YOLO ê°ì²´ íƒì§€ íŠœí† ë¦¬ì–¼ ì™„ë£Œ!")
print(f"   ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì—ì„œ GAN ì´ë¯¸ì§€ ìƒì„±ì„ ë°°ì›Œë³´ì„¸ìš”!")
print(f"=" * 60)