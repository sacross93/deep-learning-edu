"""
ë°ì´í„° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë”¥ëŸ¬ë‹ íŠœí† ë¦¬ì–¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹ ê´€ë ¨ ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ
- ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´ íƒìƒ‰
- ìƒ˜í”Œ ë°ì´í„° ì‹œê°í™”

ê° í•¨ìˆ˜ëŠ” êµìœ¡ ëª©ì ì— ë§ê²Œ ìƒì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import os
import zipfile
import tarfile
import requests
from urllib.parse import urlparse
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import torch
from torch.utils.data import DataLoader
from typing import Tuple, Optional, Union, Any
from tqdm import tqdm


def download_and_extract(
    url: str, 
    download_path: str = "./data", 
    extract_path: Optional[str] = None,
    force_download: bool = False
) -> str:
    """
    URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤.
    
    Args:
        url: ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì˜ URL
        download_path: íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ (ê¸°ë³¸ê°’: "./data")
        extract_path: ì••ì¶•ì„ í•´ì œí•  ê²½ë¡œ (Noneì´ë©´ download_pathì™€ ë™ì¼)
        force_download: Trueì´ë©´ ê¸°ì¡´ íŒŒì¼ì´ ìˆì–´ë„ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ
    
    Returns:
        str: ì••ì¶• í•´ì œëœ íŒŒì¼ë“¤ì´ ìˆëŠ” ê²½ë¡œ
    
    êµìœ¡ì  ëª©ì :
    - ì‹¤ì œ ë°ì´í„° ê³¼í•™ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë°ì´í„°ë¥¼ ì™¸ë¶€ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê²½ìš°ê°€ ë§ìŒ
    - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, íŒŒì¼ ì†ìƒ ë“±ì˜ ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬ ë°©ë²• í•™ìŠµ
    - ì§„í–‰ë¥  í‘œì‹œë¥¼ í†µí•œ ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
    """
    
    # ê²½ë¡œ ì„¤ì • ë° ë””ë ‰í† ë¦¬ ìƒì„±
    download_path = Path(download_path)
    download_path.mkdir(parents=True, exist_ok=True)
    
    if extract_path is None:
        extract_path = download_path
    else:
        extract_path = Path(extract_path)
        extract_path.mkdir(parents=True, exist_ok=True)
    
    # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
    parsed_url = urlparse(url)
    filename = os.path.basename(parsed_url.path)
    if not filename:
        filename = "downloaded_file"
    
    file_path = download_path / filename
    
    # ê¸°ì¡´ íŒŒì¼ í™•ì¸
    if file_path.exists() and not force_download:
        print(f"íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {file_path}")
    else:
        print(f"ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")
        print(f"ì €ì¥ ìœ„ì¹˜: {file_path}")
        
        try:
            # ìŠ¤íŠ¸ë¦¬ë° ë‹¤ìš´ë¡œë“œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            # íŒŒì¼ í¬ê¸° í™•ì¸ (ì§„í–‰ë¥  í‘œì‹œìš©)
            total_size = int(response.headers.get('content-length', 0))
            
            with open(file_path, 'wb') as file:
                with tqdm(total=total_size, unit='B', unit_scale=True, desc="ë‹¤ìš´ë¡œë“œ") as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            file.write(chunk)
                            pbar.update(len(chunk))
            
            print(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path}")
            
        except requests.RequestException as e:
            print(f"ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return str(download_path)
    
    # ì••ì¶• íŒŒì¼ í™•ì¸ ë° í•´ì œ
    if filename.endswith(('.zip', '.tar', '.tar.gz', '.tgz')):
        print(f"ì••ì¶• í•´ì œ ì‹œì‘: {filename}")
        
        try:
            if filename.endswith('.zip'):
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(extract_path)
            elif filename.endswith(('.tar', '.tar.gz', '.tgz')):
                with tarfile.open(file_path, 'r:*') as tar_ref:
                    tar_ref.extractall(extract_path)
            
            print(f"ì••ì¶• í•´ì œ ì™„ë£Œ: {extract_path}")
            
        except Exception as e:
            print(f"ì••ì¶• í•´ì œ ì˜¤ë¥˜: {e}")
    
    return str(extract_path)


def explore_dataset(
    dataset: Any, 
    dataset_name: str = "Dataset",
    show_samples: int = 5,
    show_distribution: bool = True
) -> None:
    """
    ë°ì´í„°ì…‹ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ íƒìƒ‰í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        dataset: íƒìƒ‰í•  ë°ì´í„°ì…‹ (PyTorch Dataset ê°ì²´)
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„ (ì¶œë ¥ìš©)
        show_samples: ë³´ì—¬ì¤„ ìƒ˜í”Œ ìˆ˜
        show_distribution: í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ë³´ì—¬ì¤„ì§€ ì—¬ë¶€
    
    êµìœ¡ì  ëª©ì :
    - ë°ì´í„° íƒìƒ‰ì€ ëª¨ë“  ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„
    - ë°ì´í„°ì˜ êµ¬ì¡°, í¬ê¸°, ë¶„í¬ë¥¼ ì´í•´í•´ì•¼ ì ì ˆí•œ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ë°©ë²• ì„ íƒ ê°€ëŠ¥
    - í´ë˜ìŠ¤ ë¶ˆê· í˜•, ì´ìƒì¹˜ ë“±ì˜ ë¬¸ì œë¥¼ ë¯¸ë¦¬ íŒŒì•…í•  ìˆ˜ ìˆìŒ
    """
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š {dataset_name} ë°ì´í„°ì…‹ íƒìƒ‰")
    print(f"{'='*50}")
    
    # ê¸°ë³¸ ì •ë³´
    print(f"ğŸ“ˆ ê¸°ë³¸ ì •ë³´:")
    print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset):,}ê°œ")
    
    # ì²« ë²ˆì§¸ ìƒ˜í”Œë¡œ ë°ì´í„° êµ¬ì¡° íŒŒì•…
    try:
        sample = dataset[0]
        if isinstance(sample, tuple):
            data, target = sample
            print(f"  - ë°ì´í„° í˜•íƒœ: {type(data).__name__}")
            print(f"  - íƒ€ê²Ÿ í˜•íƒœ: {type(target).__name__}")
            
            # í…ì„œì¸ ê²½ìš° shape ì •ë³´
            if hasattr(data, 'shape'):
                print(f"  - ë°ì´í„° í¬ê¸°: {data.shape}")
            if hasattr(target, 'shape'):
                print(f"  - íƒ€ê²Ÿ í¬ê¸°: {target.shape}")
                
        else:
            print(f"  - ìƒ˜í”Œ í˜•íƒœ: {type(sample).__name__}")
            if hasattr(sample, 'shape'):
                print(f"  - ìƒ˜í”Œ í¬ê¸°: {sample.shape}")
                
    except Exception as e:
        print(f"  - ìƒ˜í”Œ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ (ë¶„ë¥˜ ë¬¸ì œì¸ ê²½ìš°)
    if show_distribution:
        try:
            print(f"\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„:")
            targets = []
            
            # ì „ì²´ ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ ìƒ˜í”Œë§
            sample_size = min(1000, len(dataset))
            indices = np.random.choice(len(dataset), sample_size, replace=False)
            
            for idx in indices:
                sample = dataset[idx]
                if isinstance(sample, tuple):
                    _, target = sample
                    targets.append(target)
            
            if targets:
                # numpy ë°°ì—´ë¡œ ë³€í™˜
                if hasattr(targets[0], 'item'):  # í…ì„œì¸ ê²½ìš°
                    targets = [t.item() for t in targets]
                
                unique, counts = np.unique(targets, return_counts=True)
                
                print(f"  - í´ë˜ìŠ¤ ìˆ˜: {len(unique)}ê°œ")
                for cls, count in zip(unique, counts):
                    percentage = (count / len(targets)) * 100
                    print(f"  - í´ë˜ìŠ¤ {cls}: {count}ê°œ ({percentage:.1f}%)")
                
                # í´ë˜ìŠ¤ ë¶ˆê· í˜• ê²½ê³ 
                max_ratio = max(counts) / min(counts)
                if max_ratio > 3:
                    print(f"  âš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ê°ì§€ (ìµœëŒ€/ìµœì†Œ ë¹„ìœ¨: {max_ratio:.1f})")
                    print(f"     -> ê°€ì¤‘ì¹˜ ì†ì‹¤í•¨ìˆ˜ë‚˜ ìƒ˜í”Œë§ ê¸°ë²• ê³ ë ¤ í•„ìš”")
                    
        except Exception as e:
            print(f"  - í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    if show_samples > 0:
        print(f"\nğŸ” ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ({show_samples}ê°œ):")
        for i in range(min(show_samples, len(dataset))):
            try:
                sample = dataset[i]
                if isinstance(sample, tuple):
                    data, target = sample
                    print(f"  ìƒ˜í”Œ {i+1}: ë°ì´í„° íƒ€ì…={type(data).__name__}, íƒ€ê²Ÿ={target}")
                else:
                    print(f"  ìƒ˜í”Œ {i+1}: {type(sample).__name__}")
            except Exception as e:
                print(f"  ìƒ˜í”Œ {i+1}: ë¡œë“œ ì‹¤íŒ¨ - {e}")
    
    print(f"{'='*50}\n")


def visualize_samples(
    dataset: Any,
    num_samples: int = 8,
    num_cols: int = 4,
    figsize: Tuple[int, int] = (12, 8),
    title: str = "ë°ì´í„°ì…‹ ìƒ˜í”Œ",
    class_names: Optional[list] = None
) -> None:
    """
    ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œë“¤ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        dataset: ì‹œê°í™”í•  ë°ì´í„°ì…‹
        num_samples: ë³´ì—¬ì¤„ ìƒ˜í”Œ ìˆ˜
        num_cols: í•œ í–‰ì— ë³´ì—¬ì¤„ ì—´ ìˆ˜
        figsize: ê·¸ë¦¼ í¬ê¸°
        title: ê·¸ë¦¼ ì œëª©
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ë¶„ë¥˜ ë¬¸ì œì¸ ê²½ìš°)
    
    êµìœ¡ì  ëª©ì :
    - ì‹œê°í™”ëŠ” ë°ì´í„°ë¥¼ ì´í•´í•˜ëŠ” ê°€ì¥ ì§ê´€ì ì¸ ë°©ë²•
    - ì´ë¯¸ì§€ ë°ì´í„°ì˜ í’ˆì§ˆ, ì „ì²˜ë¦¬ íš¨ê³¼, ë¼ë²¨ë§ ì •í™•ì„± ë“±ì„ í™•ì¸ ê°€ëŠ¥
    - ëª¨ë¸ì´ í•™ìŠµí•  ë°ì´í„°ì˜ íŠ¹ì„±ì„ ë¯¸ë¦¬ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ ì•„í‚¤í…ì²˜ ì„ íƒì— ë„ì›€
    """
    
    print(f"ğŸ–¼ï¸  {title} ì‹œê°í™”")
    
    # ê·¸ë¦¬ë“œ ì„¤ì •
    num_rows = (num_samples + num_cols - 1) // num_cols
    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
    
    # axesë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜ (ë‹¨ì¼ í–‰ì¸ ê²½ìš° ì²˜ë¦¬)
    if num_rows == 1:
        axes = axes.reshape(1, -1)
    elif num_cols == 1:
        axes = axes.reshape(-1, 1)
    
    # ìƒ˜í”Œ ì‹œê°í™”
    for i in range(num_samples):
        row = i // num_cols
        col = i % num_cols
        
        try:
            # ë°ì´í„°ì…‹ì—ì„œ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
            sample = dataset[i]
            
            if isinstance(sample, tuple):
                data, target = sample
            else:
                data = sample
                target = None
            
            # í…ì„œë¥¼ numpyë¡œ ë³€í™˜
            if hasattr(data, 'numpy'):
                img = data.numpy()
            else:
                img = np.array(data)
            
            # ì´ë¯¸ì§€ ì°¨ì› ì¡°ì •
            if len(img.shape) == 3:
                # (C, H, W) -> (H, W, C) ë³€í™˜
                if img.shape[0] in [1, 3]:  # ì±„ë„ì´ ì²« ë²ˆì§¸ ì°¨ì›ì¸ ê²½ìš°
                    img = np.transpose(img, (1, 2, 0))
                
                # ë‹¨ì¼ ì±„ë„ì¸ ê²½ìš° squeeze
                if img.shape[2] == 1:
                    img = img.squeeze(axis=2)
            
            # ì´ë¯¸ì§€ ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)
            if img.max() > 1.0:
                img = img / 255.0
            
            # ìŒìˆ˜ ê°’ì´ ìˆëŠ” ê²½ìš° ì •ê·œí™” (ì˜ˆ: í‘œì¤€í™”ëœ ë°ì´í„°)
            if img.min() < 0:
                img = (img - img.min()) / (img.max() - img.min())
            
            # ì´ë¯¸ì§€ í‘œì‹œ
            if len(img.shape) == 2:  # í‘ë°± ì´ë¯¸ì§€
                axes[row, col].imshow(img, cmap='gray')
            else:  # ì»¬ëŸ¬ ì´ë¯¸ì§€
                axes[row, col].imshow(img)
            
            # ì œëª© ì„¤ì •
            if target is not None:
                if class_names and hasattr(target, 'item'):
                    title_text = f"í´ë˜ìŠ¤: {class_names[target.item()]}"
                else:
                    title_text = f"íƒ€ê²Ÿ: {target}"
            else:
                title_text = f"ìƒ˜í”Œ {i+1}"
            
            axes[row, col].set_title(title_text, fontsize=10)
            axes[row, col].axis('off')
            
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ í”Œë¡¯ í‘œì‹œ
            axes[row, col].text(0.5, 0.5, f"ë¡œë“œ ì‹¤íŒ¨\n{str(e)[:30]}...", 
                               ha='center', va='center', transform=axes[row, col].transAxes)
            axes[row, col].axis('off')
    
    # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
    for i in range(num_samples, num_rows * num_cols):
        row = i // num_cols
        col = i % num_cols
        axes[row, col].axis('off')
    
    plt.suptitle(title, fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    print(f"âœ… {num_samples}ê°œ ìƒ˜í”Œ ì‹œê°í™” ì™„ë£Œ")


def get_data_statistics(dataloader: DataLoader) -> dict:
    """
    ë°ì´í„°ë¡œë”ì—ì„œ ë°ì´í„°ì˜ í†µê³„ ì •ë³´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        dataloader: PyTorch DataLoader ê°ì²´
    
    Returns:
        dict: í‰ê· , í‘œì¤€í¸ì°¨ ë“±ì˜ í†µê³„ ì •ë³´
    
    êµìœ¡ì  ëª©ì :
    - ë°ì´í„° ì •ê·œí™”ë¥¼ ìœ„í•´ì„œëŠ” ì „ì²´ ë°ì´í„°ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì•Œì•„ì•¼ í•¨
    - ë°°ì¹˜ë³„ë¡œ í†µê³„ë¥¼ ê³„ì‚°í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
    - ì±„ë„ë³„ í†µê³„ ì •ë³´ë¡œ ì»¬ëŸ¬ ì´ë¯¸ì§€ì˜ ê° ì±„ë„ íŠ¹ì„± íŒŒì•…
    """
    
    print("ğŸ“Š ë°ì´í„° í†µê³„ ì •ë³´ ê³„ì‚° ì¤‘...")
    
    # í†µê³„ ì •ë³´ ì €ì¥ìš© ë³€ìˆ˜
    mean = 0.0
    std = 0.0
    total_samples = 0
    
    # ë°°ì¹˜ë³„ë¡œ í†µê³„ ê³„ì‚°
    for batch_idx, (data, _) in enumerate(tqdm(dataloader, desc="í†µê³„ ê³„ì‚°")):
        batch_samples = data.size(0)
        
        # ë°°ì¹˜ë¥¼ (batch_size, -1) í˜•íƒœë¡œ reshape
        data = data.view(batch_samples, -1)
        
        # ëˆ„ì  í‰ê·  ê³„ì‚°
        mean += data.mean(1).sum(0)
        std += data.std(1).sum(0)
        total_samples += batch_samples
    
    # ì „ì²´ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
    mean /= total_samples
    std /= total_samples
    
    statistics = {
        'mean': mean.item() if hasattr(mean, 'item') else mean,
        'std': std.item() if hasattr(std, 'item') else std,
        'total_samples': total_samples
    }
    
    print(f"âœ… í†µê³„ ê³„ì‚° ì™„ë£Œ:")
    print(f"  - í‰ê· : {statistics['mean']:.4f}")
    print(f"  - í‘œì¤€í¸ì°¨: {statistics['std']:.4f}")
    print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {statistics['total_samples']:,}ê°œ")
    
    return statistics


def create_data_split(
    dataset: Any, 
    train_ratio: float = 0.8, 
    val_ratio: float = 0.1, 
    test_ratio: float = 0.1,
    random_seed: int = 42
) -> Tuple[Any, Any, Any]:
    """
    ë°ì´í„°ì…‹ì„ í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    
    Args:
        dataset: ë¶„í• í•  ë°ì´í„°ì…‹
        train_ratio: í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨
        val_ratio: ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨  
        test_ratio: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
        random_seed: ëœë¤ ì‹œë“œ
    
    Returns:
        Tuple: (train_dataset, val_dataset, test_dataset)
    
    êµìœ¡ì  ëª©ì :
    - ì ì ˆí•œ ë°ì´í„° ë¶„í• ì€ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€ì— í•„ìˆ˜
    - ê²€ì¦ ì„¸íŠ¸ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì—, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ëŠ” ìµœì¢… ì„±ëŠ¥ í‰ê°€ì— ì‚¬ìš©
    - ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ëœë¤ ì‹œë“œ ì„¤ì • ì¤‘ìš”
    """
    
    # ë¹„ìœ¨ ê²€ì¦
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \
        "í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì˜ í•©ì´ 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    
    # ëœë¤ ì‹œë“œ ì„¤ì •
    torch.manual_seed(random_seed)
    np.random.seed(random_seed)
    
    # ë°ì´í„°ì…‹ í¬ê¸°
    dataset_size = len(dataset)
    
    # ê° ì„¸íŠ¸ í¬ê¸° ê³„ì‚°
    train_size = int(train_ratio * dataset_size)
    val_size = int(val_ratio * dataset_size)
    test_size = dataset_size - train_size - val_size
    
    print(f"ğŸ“Š ë°ì´í„° ë¶„í• :")
    print(f"  - ì „ì²´: {dataset_size:,}ê°œ")
    print(f"  - í›ˆë ¨: {train_size:,}ê°œ ({train_ratio*100:.1f}%)")
    print(f"  - ê²€ì¦: {val_size:,}ê°œ ({val_ratio*100:.1f}%)")
    print(f"  - í…ŒìŠ¤íŠ¸: {test_size:,}ê°œ ({test_ratio*100:.1f}%)")
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size, test_size]
    )
    
    return train_dataset, val_dataset, test_dataset