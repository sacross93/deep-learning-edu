"""
ì‹œê°í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í›ˆë ¨ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
- í›ˆë ¨ ê³¡ì„  (ì†ì‹¤, ì •í™•ë„) ì‹œê°í™”
- í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
- íŠ¹ì„± ë§µ (feature map) ì‹œê°í™”
- ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”

ê° í•¨ìˆ˜ëŠ” êµìœ¡ ëª©ì ì— ë§ê²Œ ìƒì„¸í•œ ì„¤ëª…ê³¼ í•´ì„ ê°€ì´ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import torch
import torch.nn.functional as F
from sklearn.metrics import confusion_matrix, classification_report
from typing import List, Dict, Optional, Tuple, Any
import warnings

# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlibì—ì„œ í•œê¸€ í‘œì‹œë¥¼ ìœ„í•´)
plt.rcParams['font.family'] = ['DejaVu Sans', 'Malgun Gothic', 'AppleGothic']
plt.rcParams['axes.unicode_minus'] = False

# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •
sns.set_style("whitegrid")
plt.style.use('default')


def plot_training_curves(
    train_losses: List[float],
    val_losses: Optional[List[float]] = None,
    train_accuracies: Optional[List[float]] = None,
    val_accuracies: Optional[List[float]] = None,
    title: str = "í›ˆë ¨ ê³¼ì •",
    save_path: Optional[str] = None,
    figsize: Tuple[int, int] = (15, 5)
) -> None:
    """
    ëª¨ë¸ í›ˆë ¨ ê³¼ì •ì˜ ì†ì‹¤ê³¼ ì •í™•ë„ ê³¡ì„ ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        train_losses: ì—í¬í¬ë³„ í›ˆë ¨ ì†ì‹¤ ë¦¬ìŠ¤íŠ¸
        val_losses: ì—í¬í¬ë³„ ê²€ì¦ ì†ì‹¤ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        train_accuracies: ì—í¬í¬ë³„ í›ˆë ¨ ì •í™•ë„ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        val_accuracies: ì—í¬í¬ë³„ ê²€ì¦ ì •í™•ë„ ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        title: ê·¸ë˜í”„ ì œëª©
        save_path: ê·¸ë˜í”„ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        figsize: ê·¸ë˜í”„ í¬ê¸°
    
    êµìœ¡ì  ëª©ì :
    - í›ˆë ¨ ê³¡ì„ ì€ ëª¨ë¸ì˜ í•™ìŠµ ìƒíƒœë¥¼ íŒŒì•…í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ë„êµ¬
    - ê³¼ì í•©(overfitting) ì—¬ë¶€ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥
    - í•™ìŠµë¥ , ì •ê·œí™” ë“± í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì˜ ê·¼ê±° ì œê³µ
    - ì¡°ê¸° ì¢…ë£Œ(early stopping) ì‹œì  ê²°ì •ì— ë„ì›€
    """
    
    print(f"ğŸ“ˆ {title} ì‹œê°í™” ì¤‘...")
    
    # ì„œë¸Œí”Œë¡¯ ê°œìˆ˜ ê²°ì •
    num_plots = 1 if train_accuracies is None else 2
    fig, axes = plt.subplots(1, num_plots, figsize=figsize)
    
    if num_plots == 1:
        axes = [axes]
    
    # ì—í¬í¬ ë²ˆí˜¸ ìƒì„±
    epochs = range(1, len(train_losses) + 1)
    
    # 1. ì†ì‹¤ ê³¡ì„  ê·¸ë¦¬ê¸°
    axes[0].plot(epochs, train_losses, 'b-', label='í›ˆë ¨ ì†ì‹¤', linewidth=2, marker='o', markersize=4)
    
    if val_losses is not None:
        axes[0].plot(epochs, val_losses, 'r-', label='ê²€ì¦ ì†ì‹¤', linewidth=2, marker='s', markersize=4)
        
        # ê³¼ì í•© ê°ì§€ ë° ê²½ê³ 
        if len(val_losses) > 5:  # ì¶©ë¶„í•œ ì—í¬í¬ê°€ ìˆì„ ë•Œë§Œ ê²€ì‚¬
            # ìµœê·¼ 5ê°œ ì—í¬í¬ì—ì„œ ê²€ì¦ ì†ì‹¤ì´ ê³„ì† ì¦ê°€í•˜ëŠ”ì§€ í™•ì¸
            recent_val_trend = np.polyfit(range(5), val_losses[-5:], 1)[0]
            if recent_val_trend > 0.01:  # ê¸°ìš¸ê¸°ê°€ ì–‘ìˆ˜ì´ê³  ì¶©ë¶„íˆ í° ê²½ìš°
                axes[0].axvline(x=len(epochs)-5, color='orange', linestyle='--', alpha=0.7)
                axes[0].text(len(epochs)-5, max(val_losses), 'âš ï¸ ê³¼ì í•© ì˜ì‹¬', 
                           rotation=90, verticalalignment='bottom', fontsize=10)
    
    axes[0].set_xlabel('ì—í¬í¬')
    axes[0].set_ylabel('ì†ì‹¤')
    axes[0].set_title('ì†ì‹¤ ê³¡ì„ ')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # ìµœì†Œ ê²€ì¦ ì†ì‹¤ ì§€ì  í‘œì‹œ
    if val_losses is not None:
        min_val_loss_epoch = np.argmin(val_losses) + 1
        min_val_loss = min(val_losses)
        axes[0].plot(min_val_loss_epoch, min_val_loss, 'g*', markersize=15, 
                    label=f'ìµœì†Œ ê²€ì¦ ì†ì‹¤ (ì—í¬í¬ {min_val_loss_epoch})')
        axes[0].legend()
    
    # 2. ì •í™•ë„ ê³¡ì„  ê·¸ë¦¬ê¸° (ìˆëŠ” ê²½ìš°)
    if train_accuracies is not None:
        axes[1].plot(epochs, train_accuracies, 'b-', label='í›ˆë ¨ ì •í™•ë„', 
                    linewidth=2, marker='o', markersize=4)
        
        if val_accuracies is not None:
            axes[1].plot(epochs, val_accuracies, 'r-', label='ê²€ì¦ ì •í™•ë„', 
                        linewidth=2, marker='s', markersize=4)
            
            # ìµœê³  ê²€ì¦ ì •í™•ë„ ì§€ì  í‘œì‹œ
            max_val_acc_epoch = np.argmax(val_accuracies) + 1
            max_val_acc = max(val_accuracies)
            axes[1].plot(max_val_acc_epoch, max_val_acc, 'g*', markersize=15,
                        label=f'ìµœê³  ê²€ì¦ ì •í™•ë„ (ì—í¬í¬ {max_val_acc_epoch})')
        
        axes[1].set_xlabel('ì—í¬í¬')
        axes[1].set_ylabel('ì •í™•ë„')
        axes[1].set_title('ì •í™•ë„ ê³¡ì„ ')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        axes[1].set_ylim(0, 1)
    
    plt.suptitle(title, fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ê·¸ë˜í”„ ì €ì¥
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ ê·¸ë˜í”„ ì €ì¥ë¨: {save_path}")
    
    plt.show()
    
    # í›ˆë ¨ ê²°ê³¼ ë¶„ì„ ë° ì¡°ì–¸ ì¶œë ¥
    print(f"\nğŸ“Š í›ˆë ¨ ê²°ê³¼ ë¶„ì„:")
    print(f"  - ìµœì¢… í›ˆë ¨ ì†ì‹¤: {train_losses[-1]:.4f}")
    
    if val_losses is not None:
        print(f"  - ìµœì¢… ê²€ì¦ ì†ì‹¤: {val_losses[-1]:.4f}")
        print(f"  - ìµœì†Œ ê²€ì¦ ì†ì‹¤: {min(val_losses):.4f} (ì—í¬í¬ {np.argmin(val_losses)+1})")
        
        # ê³¼ì í•© ë¶„ì„
        final_gap = val_losses[-1] - train_losses[-1]
        if final_gap > 0.5:
            print(f"  âš ï¸  ì‹¬ê°í•œ ê³¼ì í•© ê°ì§€ (ì†ì‹¤ ì°¨ì´: {final_gap:.4f})")
            print(f"     -> ì •ê·œí™” ê°•í™”, ë“œë¡­ì•„ì›ƒ ì¦ê°€, ë°ì´í„° ì¦ê°• ê³ ë ¤")
        elif final_gap > 0.2:
            print(f"  âš ï¸  ê²½ë¯¸í•œ ê³¼ì í•© ê°ì§€ (ì†ì‹¤ ì°¨ì´: {final_gap:.4f})")
            print(f"     -> ì¡°ê¸° ì¢…ë£Œ ë˜ëŠ” ì •ê·œí™” ì ìš© ê³ ë ¤")
    
    if val_accuracies is not None:
        print(f"  - ìµœê³  ê²€ì¦ ì •í™•ë„: {max(val_accuracies):.4f} (ì—í¬í¬ {np.argmax(val_accuracies)+1})")
        
        # ì„±ëŠ¥ ê°œì„  ì—¬ì§€ ë¶„ì„
        if max(val_accuracies) < 0.7:
            print(f"  ğŸ’¡ ì„±ëŠ¥ ê°œì„  ì œì•ˆ:")
            print(f"     -> ëª¨ë¸ ë³µì¡ë„ ì¦ê°€, í•™ìŠµë¥  ì¡°ì •, ë°ì´í„° ì „ì²˜ë¦¬ ê°œì„ ")


def plot_confusion_matrix(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    class_names: Optional[List[str]] = None,
    title: str = "í˜¼ë™ í–‰ë ¬",
    normalize: bool = True,
    save_path: Optional[str] = None,
    figsize: Tuple[int, int] = (10, 8)
) -> None:
    """
    ë¶„ë¥˜ ëª¨ë¸ì˜ í˜¼ë™ í–‰ë ¬ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        y_true: ì‹¤ì œ ë¼ë²¨
        y_pred: ì˜ˆì¸¡ ë¼ë²¨
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        title: ê·¸ë˜í”„ ì œëª©
        normalize: ì •ê·œí™” ì—¬ë¶€ (ë¹„ìœ¨ë¡œ í‘œì‹œ)
        save_path: ì €ì¥ ê²½ë¡œ
        figsize: ê·¸ë˜í”„ í¬ê¸°
    
    êµìœ¡ì  ëª©ì :
    - í˜¼ë™ í–‰ë ¬ì€ ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì„¸ë¶€ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” í•µì‹¬ ë„êµ¬
    - ì–´ë–¤ í´ë˜ìŠ¤ê°€ ì˜ëª» ë¶„ë¥˜ë˜ëŠ”ì§€, ì–´ë–¤ í´ë˜ìŠ¤ë¼ë¦¬ í˜¼ë™ë˜ëŠ”ì§€ íŒŒì•… ê°€ëŠ¥
    - í´ë˜ìŠ¤ë³„ ì •ë°€ë„, ì¬í˜„ìœ¨ ê³„ì‚°ì˜ ê¸°ì´ˆ ìë£Œ
    - ë°ì´í„° ë¶ˆê· í˜•ì´ë‚˜ ëª¨ë¸ì˜ í¸í–¥ì„± ë°œê²¬ì— ë„ì›€
    """
    
    print(f"ğŸ¯ {title} ìƒì„± ì¤‘...")
    
    # í˜¼ë™ í–‰ë ¬ ê³„ì‚°
    cm = confusion_matrix(y_true, y_pred)
    
    if normalize:
        # í–‰ë³„ë¡œ ì •ê·œí™” (ì‹¤ì œ í´ë˜ìŠ¤ë³„ ë¹„ìœ¨)
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm_display = cm_normalized
        fmt = '.2%'
        cbar_label = 'ë¹„ìœ¨'
    else:
        cm_display = cm
        fmt = 'd'
        cbar_label = 'ê°œìˆ˜'
    
    # ê·¸ë˜í”„ ìƒì„±
    plt.figure(figsize=figsize)
    
    # íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
    sns.heatmap(cm_display, 
                annot=True, 
                fmt=fmt,
                cmap='Blues',
                xticklabels=class_names if class_names else range(len(cm)),
                yticklabels=class_names if class_names else range(len(cm)),
                cbar_kws={'label': cbar_label})
    
    plt.title(title, fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('ì˜ˆì¸¡ ë¼ë²¨', fontsize=12)
    plt.ylabel('ì‹¤ì œ ë¼ë²¨', fontsize=12)
    
    # ëŒ€ê°ì„  ê°•ì¡° (ì •í™•í•œ ì˜ˆì¸¡)
    for i in range(len(cm)):
        plt.gca().add_patch(plt.Rectangle((i, i), 1, 1, fill=False, edgecolor='red', lw=3))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ í˜¼ë™ í–‰ë ¬ ì €ì¥ë¨: {save_path}")
    
    plt.show()
    
    # ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì¶œë ¥
    print(f"\nğŸ“Š ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
    report = classification_report(y_true, y_pred, 
                                 target_names=class_names,
                                 output_dict=True)
    
    # ì „ì²´ ì •í™•ë„
    accuracy = report['accuracy']
    print(f"  - ì „ì²´ ì •í™•ë„: {accuracy:.4f}")
    
    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
    print(f"\n  í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
    for class_name in (class_names if class_names else [str(i) for i in range(len(cm))]):
        if class_name in report:
            precision = report[class_name]['precision']
            recall = report[class_name]['recall']
            f1 = report[class_name]['f1-score']
            support = report[class_name]['support']
            
            print(f"    {class_name}:")
            print(f"      ì •ë°€ë„: {precision:.4f}, ì¬í˜„ìœ¨: {recall:.4f}, F1: {f1:.4f} (ìƒ˜í”Œ: {support}ê°œ)")
    
    # ì„±ëŠ¥ ë¶„ì„ ë° ê°œì„  ì œì•ˆ
    print(f"\nğŸ’¡ ì„±ëŠ¥ ë¶„ì„:")
    
    # ê°€ì¥ í˜¼ë™ë˜ëŠ” í´ë˜ìŠ¤ ìŒ ì°¾ê¸°
    max_confusion = 0
    confused_pair = None
    
    for i in range(len(cm)):
        for j in range(len(cm)):
            if i != j and cm[i][j] > max_confusion:
                max_confusion = cm[i][j]
                confused_pair = (i, j)
    
    if confused_pair and max_confusion > 0:
        class_i = class_names[confused_pair[0]] if class_names else f"í´ë˜ìŠ¤ {confused_pair[0]}"
        class_j = class_names[confused_pair[1]] if class_names else f"í´ë˜ìŠ¤ {confused_pair[1]}"
        print(f"  - ê°€ì¥ í˜¼ë™ë˜ëŠ” í´ë˜ìŠ¤: {class_i} â†’ {class_j} ({max_confusion}ê°œ)")
        print(f"    -> ì´ ë‘ í´ë˜ìŠ¤ì˜ íŠ¹ì§•ì„ ë” ì˜ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” íŠ¹ì„± ì¶”ê°€ ê³ ë ¤")
    
    # ì„±ëŠ¥ì´ ë‚®ì€ í´ë˜ìŠ¤ ì‹ë³„
    worst_f1 = 1.0
    worst_class = None
    
    for class_name in (class_names if class_names else [str(i) for i in range(len(cm))]):
        if class_name in report and isinstance(report[class_name], dict):
            f1 = report[class_name]['f1-score']
            if f1 < worst_f1:
                worst_f1 = f1
                worst_class = class_name
    
    if worst_class and worst_f1 < 0.8:
        print(f"  - ì„±ëŠ¥ì´ ë‚®ì€ í´ë˜ìŠ¤: {worst_class} (F1: {worst_f1:.4f})")
        print(f"    -> í•´ë‹¹ í´ë˜ìŠ¤ì˜ ë°ì´í„° ì¦ê°•ì´ë‚˜ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ê³ ë ¤")


def plot_feature_maps(
    model: torch.nn.Module,
    input_tensor: torch.Tensor,
    layer_name: str,
    num_maps: int = 16,
    figsize: Tuple[int, int] = (15, 10),
    title: str = "íŠ¹ì„± ë§µ ì‹œê°í™”"
) -> None:
    """
    CNN ëª¨ë¸ì˜ íŠ¹ì„± ë§µ(feature map)ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        model: ì‹œê°í™”í•  CNN ëª¨ë¸
        input_tensor: ì…ë ¥ í…ì„œ (1ê°œ ìƒ˜í”Œ)
        layer_name: ì‹œê°í™”í•  ë ˆì´ì–´ ì´ë¦„
        num_maps: í‘œì‹œí•  íŠ¹ì„± ë§µ ê°œìˆ˜
        figsize: ê·¸ë˜í”„ í¬ê¸°
        title: ê·¸ë˜í”„ ì œëª©
    
    êµìœ¡ì  ëª©ì :
    - íŠ¹ì„± ë§µ ì‹œê°í™”ëŠ” CNNì´ ë¬´ì—‡ì„ í•™ìŠµí•˜ëŠ”ì§€ ì´í•´í•˜ëŠ” í•µì‹¬ ë°©ë²•
    - ê° ë ˆì´ì–´ê°€ ì–´ë–¤ íŠ¹ì§•(ì—£ì§€, í…ìŠ¤ì²˜, íŒ¨í„´)ì„ ê°ì§€í•˜ëŠ”ì§€ í™•ì¸ ê°€ëŠ¥
    - ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±(interpretability) í–¥ìƒ
    - ë ˆì´ì–´ë³„ íŠ¹ì„± ì¶”ì¶œ ê³¼ì •ì˜ ì‹œê°ì  ì´í•´
    """
    
    print(f"ğŸ” {title} - {layer_name} ë ˆì´ì–´")
    
    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    model.eval()
    
    # íŠ¹ì„± ë§µì„ ì €ì¥í•  ë³€ìˆ˜
    feature_maps = None
    
    # í›…(hook) í•¨ìˆ˜ ì •ì˜
    def hook_fn(module, input, output):
        nonlocal feature_maps
        feature_maps = output.detach()
    
    # ì§€ì •ëœ ë ˆì´ì–´ì— í›… ë“±ë¡
    target_layer = None
    for name, module in model.named_modules():
        if name == layer_name:
            target_layer = module
            break
    
    if target_layer is None:
        print(f"âŒ ë ˆì´ì–´ '{layer_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ë ˆì´ì–´:")
        for name, _ in model.named_modules():
            if name:  # ë¹ˆ ì´ë¦„ ì œì™¸
                print(f"  - {name}")
        return
    
    # í›… ë“±ë¡
    hook = target_layer.register_forward_hook(hook_fn)
    
    try:
        # ìˆœì „íŒŒ ì‹¤í–‰
        with torch.no_grad():
            _ = model(input_tensor.unsqueeze(0))  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        
        if feature_maps is None:
            print(f"âŒ íŠ¹ì„± ë§µì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì²« ë²ˆì§¸ ìƒ˜í”Œì˜ íŠ¹ì„± ë§µë§Œ ì‚¬ìš©
        feature_maps = feature_maps[0]  # (C, H, W)
        
        # í‘œì‹œí•  íŠ¹ì„± ë§µ ê°œìˆ˜ ì¡°ì •
        num_channels = feature_maps.shape[0]
        num_maps = min(num_maps, num_channels)
        
        # ê·¸ë¦¬ë“œ ì„¤ì •
        cols = 4
        rows = (num_maps + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=figsize)
        if rows == 1:
            axes = axes.reshape(1, -1)
        
        print(f"  - íŠ¹ì„± ë§µ í¬ê¸°: {feature_maps.shape}")
        print(f"  - í‘œì‹œí•  ë§µ ê°œìˆ˜: {num_maps}/{num_channels}")
        
        # ê° íŠ¹ì„± ë§µ ì‹œê°í™”
        for i in range(num_maps):
            row = i // cols
            col = i % cols
            
            # íŠ¹ì„± ë§µ ì¶”ì¶œ ë° ì •ê·œí™”
            fmap = feature_maps[i].cpu().numpy()
            
            # ì •ê·œí™” (0-1 ë²”ìœ„)
            fmap_min, fmap_max = fmap.min(), fmap.max()
            if fmap_max > fmap_min:
                fmap = (fmap - fmap_min) / (fmap_max - fmap_min)
            
            # ì‹œê°í™”
            im = axes[row, col].imshow(fmap, cmap='viridis')
            axes[row, col].set_title(f'ë§µ {i+1}', fontsize=10)
            axes[row, col].axis('off')
            
            # ì»¬ëŸ¬ë°” ì¶”ê°€ (ì²« ë²ˆì§¸ í–‰ì—ë§Œ)
            if row == 0:
                plt.colorbar(im, ax=axes[row, col], fraction=0.046, pad=0.04)
        
        # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
        for i in range(num_maps, rows * cols):
            row = i // cols
            col = i % cols
            axes[row, col].axis('off')
        
        plt.suptitle(f"{title} - {layer_name}", fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()
        
        # íŠ¹ì„± ë§µ ë¶„ì„
        print(f"\nğŸ“Š íŠ¹ì„± ë§µ ë¶„ì„:")
        
        # í™œì„±í™” í†µê³„
        activation_mean = feature_maps.mean().item()
        activation_std = feature_maps.std().item()
        activation_max = feature_maps.max().item()
        
        print(f"  - í‰ê·  í™œì„±í™”: {activation_mean:.4f}")
        print(f"  - í™œì„±í™” í‘œì¤€í¸ì°¨: {activation_std:.4f}")
        print(f"  - ìµœëŒ€ í™œì„±í™”: {activation_max:.4f}")
        
        # í™œì„±í™”ëœ ë‰´ëŸ° ë¹„ìœ¨
        active_ratio = (feature_maps > 0).float().mean().item()
        print(f"  - í™œì„±í™”ëœ ë‰´ëŸ° ë¹„ìœ¨: {active_ratio:.2%}")
        
        if active_ratio < 0.1:
            print(f"    âš ï¸ í™œì„±í™” ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ReLU ì£½ìŒ í˜„ìƒ ì˜ì‹¬")
        elif active_ratio > 0.9:
            print(f"    âš ï¸ ëŒ€ë¶€ë¶„ì˜ ë‰´ëŸ°ì´ í™œì„±í™”ë¨. í¬í™” ìƒíƒœ ì˜ì‹¬")
        
    finally:
        # í›… ì œê±°
        hook.remove()


def plot_learning_rate_schedule(
    lr_schedule: List[float],
    title: str = "í•™ìŠµë¥  ìŠ¤ì¼€ì¤„",
    save_path: Optional[str] = None,
    figsize: Tuple[int, int] = (10, 6)
) -> None:
    """
    í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        lr_schedule: ì—í¬í¬ë³„ í•™ìŠµë¥  ë¦¬ìŠ¤íŠ¸
        title: ê·¸ë˜í”„ ì œëª©
        save_path: ì €ì¥ ê²½ë¡œ
        figsize: ê·¸ë˜í”„ í¬ê¸°
    
    êµìœ¡ì  ëª©ì :
    - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ì€ ëª¨ë¸ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ê¸°ë²•
    - ì ì ˆí•œ í•™ìŠµë¥  ê°ì†Œ íŒ¨í„´ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸
    - ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¤„ëŸ¬(StepLR, CosineAnnealingLR ë“±)ì˜ íš¨ê³¼ ë¹„êµ
    """
    
    plt.figure(figsize=figsize)
    
    epochs = range(1, len(lr_schedule) + 1)
    plt.plot(epochs, lr_schedule, 'b-', linewidth=2, marker='o', markersize=4)
    
    plt.xlabel('ì—í¬í¬')
    plt.ylabel('í•™ìŠµë¥ ')
    plt.title(title, fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.yscale('log')  # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ í‘œì‹œ (í•™ìŠµë¥  ë³€í™”ë¥¼ ë” ì˜ ë³´ê¸° ìœ„í•´)
    
    # ì£¼ìš” ë³€í™”ì  í‘œì‹œ
    if len(lr_schedule) > 1:
        lr_changes = []
        for i in range(1, len(lr_schedule)):
            if abs(lr_schedule[i] - lr_schedule[i-1]) / lr_schedule[i-1] > 0.1:  # 10% ì´ìƒ ë³€í™”
                lr_changes.append(i)
        
        for change_point in lr_changes:
            plt.axvline(x=change_point+1, color='red', linestyle='--', alpha=0.7)
            plt.text(change_point+1, lr_schedule[change_point], f'ë³€í™”ì ', 
                    rotation=90, verticalalignment='bottom')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ ì €ì¥ë¨: {save_path}")
    
    plt.show()
    
    print(f"ğŸ“Š í•™ìŠµë¥  ë¶„ì„:")
    print(f"  - ì´ˆê¸° í•™ìŠµë¥ : {lr_schedule[0]:.6f}")
    print(f"  - ìµœì¢… í•™ìŠµë¥ : {lr_schedule[-1]:.6f}")
    print(f"  - ê°ì†Œ ë¹„ìœ¨: {lr_schedule[-1]/lr_schedule[0]:.4f}")


def plot_model_predictions(
    model: torch.nn.Module,
    dataloader: torch.utils.data.DataLoader,
    class_names: Optional[List[str]] = None,
    num_samples: int = 8,
    device: str = 'cpu',
    title: str = "ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼"
) -> None:
    """
    ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        model: ì˜ˆì¸¡í•  ëª¨ë¸
        dataloader: ë°ì´í„° ë¡œë”
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        num_samples: í‘œì‹œí•  ìƒ˜í”Œ ìˆ˜
        device: ì—°ì‚° ì¥ì¹˜
        title: ê·¸ë˜í”„ ì œëª©
    
    êµìœ¡ì  ëª©ì :
    - ëª¨ë¸ì´ ì‹¤ì œë¡œ ì–´ë–¤ ì˜ˆì¸¡ì„ í•˜ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸
    - ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ê³¼ ì˜ëª»ëœ ì˜ˆì¸¡ì˜ íŒ¨í„´ ë¶„ì„
    - ëª¨ë¸ì˜ ì‹ ë¢°ë„ì™€ ì‹¤ì œ ì„±ëŠ¥ ê°„ì˜ ê´€ê³„ íŒŒì•…
    """
    
    model.eval()
    model = model.to(device)
    
    # ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘
    samples = []
    with torch.no_grad():
        for batch_idx, (data, targets) in enumerate(dataloader):
            data, targets = data.to(device), targets.to(device)
            outputs = model(data)
            
            # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©í•˜ì—¬ í™•ë¥  ê³„ì‚°
            probabilities = F.softmax(outputs, dim=1)
            predictions = torch.argmax(outputs, dim=1)
            
            for i in range(len(data)):
                if len(samples) >= num_samples:
                    break
                
                samples.append({
                    'image': data[i].cpu(),
                    'true_label': targets[i].cpu().item(),
                    'pred_label': predictions[i].cpu().item(),
                    'confidence': probabilities[i].max().cpu().item(),
                    'correct': predictions[i].cpu().item() == targets[i].cpu().item()
                })
            
            if len(samples) >= num_samples:
                break
    
    # ì‹œê°í™”
    cols = 4
    rows = (num_samples + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(15, rows * 3))
    
    if rows == 1:
        axes = axes.reshape(1, -1)
    
    for i, sample in enumerate(samples):
        row = i // cols
        col = i % cols
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img = sample['image']
        if len(img.shape) == 3 and img.shape[0] in [1, 3]:
            img = img.permute(1, 2, 0)
        if img.shape[-1] == 1:
            img = img.squeeze(-1)
        
        # ì •ê·œí™”
        if img.max() <= 1.0 and img.min() >= -1.0:
            img = (img - img.min()) / (img.max() - img.min())
        
        # ì´ë¯¸ì§€ í‘œì‹œ
        if len(img.shape) == 2:
            axes[row, col].imshow(img, cmap='gray')
        else:
            axes[row, col].imshow(img)
        
        # ì œëª© ì„¤ì •
        true_name = class_names[sample['true_label']] if class_names else f"í´ë˜ìŠ¤ {sample['true_label']}"
        pred_name = class_names[sample['pred_label']] if class_names else f"í´ë˜ìŠ¤ {sample['pred_label']}"
        
        color = 'green' if sample['correct'] else 'red'
        title_text = f"ì‹¤ì œ: {true_name}\nì˜ˆì¸¡: {pred_name}\nì‹ ë¢°ë„: {sample['confidence']:.2f}"
        
        axes[row, col].set_title(title_text, color=color, fontsize=10)
        axes[row, col].axis('off')
    
    # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
    for i in range(num_samples, rows * cols):
        row = i // cols
        col = i % cols
        axes[row, col].axis('off')
    
    plt.suptitle(title, fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
    correct_count = sum(1 for s in samples if s['correct'])
    accuracy = correct_count / len(samples)
    avg_confidence = np.mean([s['confidence'] for s in samples])
    
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ (ìƒ˜í”Œ {len(samples)}ê°œ):")
    print(f"  - ì •í™•ë„: {accuracy:.2%}")
    print(f"  - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.4f}")
    
    # ì‹ ë¢°ë„ë³„ ì •í™•ë„ ë¶„ì„
    high_conf_samples = [s for s in samples if s['confidence'] > 0.9]
    if high_conf_samples:
        high_conf_accuracy = sum(1 for s in high_conf_samples if s['correct']) / len(high_conf_samples)
        print(f"  - ê³ ì‹ ë¢°ë„(>0.9) ìƒ˜í”Œ ì •í™•ë„: {high_conf_accuracy:.2%} ({len(high_conf_samples)}ê°œ)")
    
    low_conf_samples = [s for s in samples if s['confidence'] < 0.6]
    if low_conf_samples:
        low_conf_accuracy = sum(1 for s in low_conf_samples if s['correct']) / len(low_conf_samples)
        print(f"  - ì €ì‹ ë¢°ë„(<0.6) ìƒ˜í”Œ ì •í™•ë„: {low_conf_accuracy:.2%} ({len(low_conf_samples)}ê°œ)")